# CIFAR-10 cuDNN - Modular CUDA Fortran Training

**High-performance, modular CNN training framework in CUDA Fortran**



https://github.com/user-attachments/assets/2d4ee22e-4a07-47cd-9afe-81e2bfb617fb



## ðŸŽ¯ What's Here

This repository contains the **v28 Baseline** - a production-ready, modular CUDA Fortran framework for training CNNs on GPU.

### Key Features

- âœ… **2Ã— faster than PyTorch** (31s vs 61s on CIFAR-10)
- âœ… **Fully modular** - add new datasets in <2 hours
- âœ… **Validated on 4 datasets** - CIFAR-10, CIFAR-100, SVHN, Fashion-MNIST
- âœ… **Comprehensive documentation** - design, architecture, and adaptation guides

## ðŸ“ Repository Structure

```
v28_baseline/              # Main framework (START HERE!)
â”œâ”€â”€ README.md              # Quick start guide
â”œâ”€â”€ MODULAR_ADAPTATION_GUIDE.md  # How to adapt to new datasets
â”œâ”€â”€ V28_BASELINE_SUMMARY.md      # Project summary
â”œâ”€â”€ FASHION_MNIST_ADAPTATION.md  # Case study
â”‚
â”œâ”€â”€ common/                # Reusable modules (885 lines, 100% reusable)
â”‚   â”œâ”€â”€ random_utils.cuf
â”‚   â”œâ”€â”€ adam_optimizer.cuf
â”‚   â”œâ”€â”€ gpu_batch_extraction.cuf
â”‚   â””â”€â”€ cuda_utils.cuf
â”‚
â”œâ”€â”€ datasets/              # Dataset configs (~150 lines each)
â”‚   â”œâ”€â”€ cifar10/
â”‚   â”œâ”€â”€ cifar100/
â”‚   â”œâ”€â”€ svhn/
â”‚   â”œâ”€â”€ fashion_mnist/
â”‚   â””â”€â”€ oxford_flowers/
â”‚
â””â”€â”€ docs/                  # Technical documentation
    â”œâ”€â”€ ARCHITECTURE.md
    â”œâ”€â”€ MODULARITY_GUIDE.md
    â””â”€â”€ ADDING_NEW_DATASET.md
```

## ðŸš€ Quick Start

```bash
# 1. Navigate to framework
cd v28_baseline

# 2. Read the overview
cat MODULAR_ADAPTATION_GUIDE.md

# 3. Try CIFAR-10
cd datasets/cifar10
python prepare_cifar10.py
./compile_cifar10.sh
./cifar10_train
```

## ðŸ“Š Validated Results

| Dataset | Accuracy | Time (V100) | Lines of Code |
|---------|----------|-------------|---------------|
| CIFAR-10 | 78.92% | 31s | ~150 |
| CIFAR-100 | 46-50% | ~35s | ~150 |
| SVHN | 92-93% | ~40s | ~150 |
| Fashion-MNIST | 92.09% | 28s | ~150 |

## ðŸ“– Documentation

Start with these documents in order:

1. **`v28_baseline/MODULAR_ADAPTATION_GUIDE.md`** - High-level overview
2. **`v28_baseline/README.md`** - Quick start guide
3. **`v28_baseline/docs/ARCHITECTURE.md`** - System design
4. **`v28_baseline/FASHION_MNIST_ADAPTATION.md`** - Real-world case study

## ðŸ† Why v28 Baseline?

**Before**: 12,114 lines of duplicated code across 3 datasets (90% duplication)
**After**: 1,500 lines total (0% duplication, 100% reusable)

**Performance**: Same 2Ã— speedup over PyTorch
**Modularity**: PyTorch-level modularity achieved!

## ðŸŽ“ Learn More

See `v28_baseline/` for complete documentation including:
- How the modularity works
- How to adapt to new datasets
- Design principles and best practices
- Performance characteristics

---

**Repository**: https://github.com/frasertajima/CIFAR-10
**Status**: âœ… Production-ready
**Last Updated**: 2025-11-17
