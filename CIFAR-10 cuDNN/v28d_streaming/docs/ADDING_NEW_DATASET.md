# Adding a New Dataset to v28 Baseline

This guide walks you through adding a new dataset (Fashion-MNIST as example) to the v28 Baseline framework.

**Time estimate**: 1-2 hours for first dataset, <30 minutes for subsequent datasets

## Prerequisites

- v28 Baseline installed and working
- Python 3.x with numpy
- NVIDIA HPC SDK (nvfortran compiler)
- New dataset available (e.g., Fashion-MNIST)

## Step-by-Step Guide

### Step 1: Create Dataset Directory (2 minutes)

```bash
cd v28_baseline/datasets
mkdir fashion_mnist
cd fashion_mnist
```

### Step 2: Copy Template Config (1 minute)

Use CIFAR-10 as the template since it's well-documented:

```bash
cp ../cifar10/cifar10_config.cuf fashion_mnist_config.cuf
```

### Step 3: Edit Dataset Parameters (10 minutes)

Open `fashion_mnist_config.cuf` and modify:

```fortran
!================================================================
! Fashion-MNIST Dataset Configuration - v28 Baseline
!================================================================
module dataset_config
    use cudafor
    use iso_c_binding
    implicit none

    !================================================================
    ! DATASET PARAMETERS - Fashion-MNIST Specific
    !================================================================
    integer, parameter, public :: train_samples = 60000  ! â† Changed!
    integer, parameter, public :: test_samples = 10000
    integer, parameter, public :: num_classes = 10
    integer, parameter, public :: INPUT_CHANNELS = 1     ! â† Grayscale!
    integer, parameter, public :: INPUT_HEIGHT = 28      ! â† Changed!
    integer, parameter, public :: INPUT_WIDTH = 28       ! â† Changed!
    integer, parameter, public :: input_size = 784       ! â† 1*28*28

    ! Data directory
    character(len=*), parameter :: DATA_DIR = 'fashion_mnist_data/'
    character(len=*), parameter, public :: DATASET_NAME = 'Fashion-MNIST'

    !================================================================
    ! CNN ARCHITECTURE PARAMETERS
    !================================================================
    ! Keep these the same or adjust for your dataset
    integer, parameter, public :: CONV1_FILTERS = 32
    integer, parameter, public :: CONV2_FILTERS = 64
    integer, parameter, public :: CONV3_FILTERS = 128
    ! ... rest stays the same ...
```

**Key changes for Fashion-MNIST**:
- `train_samples`: 50000 â†’ 60000
- `INPUT_CHANNELS`: 3 â†’ 1 (RGB â†’ grayscale)
- `INPUT_HEIGHT`: 32 â†’ 28
- `INPUT_WIDTH`: 32 â†’ 28
- `input_size`: 3072 â†’ 784
- `DATA_DIR`: 'cifar10_data/' â†’ 'fashion_mnist_data/'

### Step 4: Update Data Loading (5 minutes)

The `load_dataset()` function stays almost identical. Only change error messages:

```fortran
subroutine load_dataset()
    ! ... allocations stay the same ...

    print *, "Loading Fashion-MNIST Dataset (v28 Baseline)"

    ! ... file loading stays the same ...

    if (stat /= 0) then
        print *, "âŒ ERROR: Cannot open images_train.bin"
        print *, "Run: python prepare_fashion_mnist.py"  ! â† Update message
        stop
    endif

    ! ... rest stays the same ...
end subroutine load_dataset
```

### Step 5: Create Python Preprocessing Script (30 minutes)

Copy and modify the CIFAR-10 preprocessing:

```bash
cp ../cifar10/prepare_cifar10.py prepare_fashion_mnist.py
```

Edit `prepare_fashion_mnist.py`:

```python
#!/usr/bin/env python3
"""
Fashion-MNIST Preprocessing for v28 Baseline
Converts Fashion-MNIST to binary format for CUDA Fortran
"""
import numpy as np
import os

# Try torchvision first, fallback to keras
try:
    from torchvision import datasets, transforms
    USE_TORCH = True
except ImportError:
    from tensorflow import keras
    USE_TORCH = False

def download_and_prepare():
    """Download Fashion-MNIST and convert to binary format"""

    print("=" * 70)
    print("Fashion-MNIST Dataset Preparation")
    print("=" * 70)

    # Create output directory
    os.makedirs('fashion_mnist_data', exist_ok=True)

    if USE_TORCH:
        # Load using torchvision
        train_data = datasets.FashionMNIST(
            root='./data', train=True, download=True
        )
        test_data = datasets.FashionMNIST(
            root='./data', train=False, download=True
        )

        train_images = train_data.data.numpy()  # (60000, 28, 28)
        train_labels = train_data.targets.numpy()  # (60000,)
        test_images = test_data.data.numpy()  # (10000, 28, 28)
        test_labels = test_data.targets.numpy()  # (10000,)
    else:
        # Load using keras
        (train_images, train_labels), (test_images, test_labels) = \
            keras.datasets.fashion_mnist.load_data()

    print(f"âœ… Downloaded Fashion-MNIST")
    print(f"  Train: {train_images.shape}, {train_labels.shape}")
    print(f"  Test:  {test_images.shape}, {test_labels.shape}")

    # Normalize to [0, 1]
    train_images = train_images.astype(np.float32) / 255.0
    test_images = test_images.astype(np.float32) / 255.0

    # Add channel dimension: (N, H, W) â†’ (N, C, H, W)
    train_images = train_images[:, np.newaxis, :, :]  # (60000, 1, 28, 28)
    test_images = test_images[:, np.newaxis, :, :]    # (10000, 1, 28, 28)

    print(f"\nðŸ“Š Data Statistics:")
    print(f"  Train images: min={train_images.min():.3f}, max={train_images.max():.3f}")
    print(f"  Train labels: min={train_labels.min()}, max={train_labels.max()}")

    # Transpose to Fortran order: (N, C, H, W) â†’ (C, H, W, N)
    train_images = np.transpose(train_images, (1, 2, 3, 0))  # (1, 28, 28, 60000)
    test_images = np.transpose(test_images, (1, 2, 3, 0))    # (1, 28, 28, 10000)

    # Flatten to 2D: (C*H*W, N)
    train_images = train_images.reshape(-1, 60000)  # (784, 60000)
    test_images = test_images.reshape(-1, 10000)    # (784, 10000)

    # Transpose for Fortran column-major: (N, features)
    train_images = train_images.T  # (60000, 784)
    test_images = test_images.T    # (10000, 784)

    print(f"\nðŸ’¾ Final shapes (Fortran column-major):")
    print(f"  Train images: {train_images.shape}")
    print(f"  Test images:  {test_images.shape}")

    # Save as binary files
    print(f"\nðŸ“ Saving binary files...")
    train_images.tofile('fashion_mnist_data/images_train.bin')
    train_labels.astype(np.int32).tofile('fashion_mnist_data/labels_train.bin')
    test_images.tofile('fashion_mnist_data/images_test.bin')
    test_labels.astype(np.int32).tofile('fashion_mnist_data/labels_test.bin')

    # Print file sizes
    sizes = {
        'images_train.bin': os.path.getsize('fashion_mnist_data/images_train.bin'),
        'labels_train.bin': os.path.getsize('fashion_mnist_data/labels_train.bin'),
        'images_test.bin': os.path.getsize('fashion_mnist_data/images_test.bin'),
        'labels_test.bin': os.path.getsize('fashion_mnist_data/labels_test.bin'),
    }

    print(f"\nâœ… Binary files created:")
    for name, size in sizes.items():
        print(f"  {name:25s} {size/1024/1024:6.2f} MB")

    print(f"\nðŸŽ‰ Dataset preparation complete!")
    print(f"Total size: {sum(sizes.values())/1024/1024:.2f} MB")

if __name__ == '__main__':
    download_and_prepare()
```

**Key changes from CIFAR-10**:
- Dataset name: CIFAR-10 â†’ Fashion-MNIST
- Data source: `datasets.CIFAR10` â†’ `datasets.FashionMNIST`
- Dimensions: (3, 32, 32) â†’ (1, 28, 28)
- Output directory: `cifar10_data/` â†’ `fashion_mnist_data/`

### Step 6: Prepare the Data (5 minutes)

```bash
python prepare_fashion_mnist.py
```

**Expected output**:
```
======================================================================
Fashion-MNIST Dataset Preparation
======================================================================
âœ… Downloaded Fashion-MNIST
  Train: (60000, 28, 28), (60000,)
  Test:  (10000, 28, 28), (10000,)

ðŸ“Š Data Statistics:
  Train images: min=0.000, max=1.000
  Train labels: min=0, max=9

ðŸ’¾ Final shapes (Fortran column-major):
  Train images: (60000, 784)
  Test images:  (10000, 784)

ðŸ“ Saving binary files...

âœ… Binary files created:
  images_train.bin          179.40 MB
  labels_train.bin            0.23 MB
  images_test.bin            29.90 MB
  labels_test.bin             0.04 MB

ðŸŽ‰ Dataset preparation complete!
Total size: 209.57 MB
```

### Step 7: Create Compilation Script (10 minutes)

Create `compile_fashion_mnist.sh`:

```bash
#!/bin/bash
# Compile Fashion-MNIST training with v28 baseline

echo "Compiling Fashion-MNIST v28 Training..."

# Check for nvfortran
if ! command -v nvfortran &> /dev/null; then
    echo "âŒ nvfortran not found. Please install NVIDIA HPC SDK."
    exit 1
fi

# Compile
nvfortran -O3 -gpu=cc80 -Mcuda \
  ../../common/random_utils.cuf \
  ../../common/adam_optimizer.cuf \
  ../../common/gpu_batch_extraction.cuf \
  ../../common/cuda_utils.cuf \
  fashion_mnist_config.cuf \
  fashion_mnist_main.cuf \
  -o fashion_mnist_train \
  -lcudnn -lcublas -lcurand

if [ $? -eq 0 ]; then
    echo "âœ… Compilation successful!"
    echo "Run: ./fashion_mnist_train"
else
    echo "âŒ Compilation failed"
    exit 1
fi
```

**Note**: You'll need to create `fashion_mnist_main.cuf` next.

### Step 8: Create Main Training File (20 minutes)

This is the only complex part. Copy from CIFAR-10 example (to be created) and change:

```fortran
program fashion_mnist_training
    use dataset_config  ! This imports fashion_mnist_config!
    use curand_wrapper_module
    use apex_adam_kernels
    use gpu_batch_extraction
    use cuda_batch_state

    ! ... rest of training code is IDENTICAL to CIFAR-10 ...
    ! All dataset-specific values come from dataset_config module

end program fashion_mnist_training
```

**Key insight**: The main training program is **100% identical** across datasets!
The only difference is which `dataset_config` module you import.

### Step 9: Compile and Train! (2 minutes)

```bash
chmod +x compile_fashion_mnist.sh
./compile_fashion_mnist.sh
./fashion_mnist_train
```

**Expected output**:
```
======================================================================
Loading Fashion-MNIST Dataset (v28 Baseline)
======================================================================
âœ… Data loaded successfully!
  Training samples: 60000
  Test samples:     10000
  Image size:       28 x 28 x 1
  Classes:          10

...training progress...

ðŸŽ‰ TRAINING COMPLETED!
ðŸ† Best Test Accuracy:  92.5%
â±ï¸  Total Time:    25.0s
```

## Troubleshooting

### Compilation Errors

**Error**: `cannot find module dataset_config`
**Solution**: Make sure `fashion_mnist_config.cuf` is in the compile command

**Error**: `undefined reference to cuDNN functions`
**Solution**: Add `-lcudnn` flag

### Runtime Errors

**Error**: `Cannot open images_train.bin`
**Solution**: Run `python prepare_fashion_mnist.py` first

**Error**: `Shape mismatch`
**Solution**: Check that `input_size` matches `INPUT_CHANNELS * INPUT_HEIGHT * INPUT_WIDTH`

### Performance Issues

**Issue**: Training slower than expected
**Solution**: Check GPU utilization with `nvidia-smi`. Should be >80%

**Issue**: High CPU usage
**Solution**: Make sure blocking sync is enabled: `call set_scheduling_mode(1)`

## Checklist

Use this checklist to ensure you've completed all steps:

- [ ] Created dataset directory
- [ ] Copied and modified config file
- [ ] Updated dataset parameters (samples, channels, height, width)
- [ ] Updated data directory name
- [ ] Created preprocessing script
- [ ] Ran preprocessing script successfully
- [ ] Verified binary files created
- [ ] Created compilation script
- [ ] Created main training file (or copied generic one)
- [ ] Compiled successfully
- [ ] Ran training successfully
- [ ] Achieved reasonable accuracy

## Benchmarks for Common Datasets

| Dataset | Lines Changed | Time to Add | Expected Accuracy |
|---------|---------------|-------------|-------------------|
| **CIFAR-10** | 0 (baseline) | - | 78-79% |
| **CIFAR-100** | 10 | 30 min | 46-50% |
| **SVHN** | 15 | 45 min | 92-93% |
| **Fashion-MNIST** | 20 | 1-2 hours | 90-92% |
| **MNIST** | 15 | 30 min | 99%+ |

**Pattern**: Once you've done one, the rest are trivial!

## Advanced: Custom Architectures

Want to use a different CNN architecture for Fashion-MNIST?

### Option 1: Modify Config Parameters

```fortran
! In fashion_mnist_config.cuf
integer, parameter :: CONV1_FILTERS = 64   ! Bigger model
integer, parameter :: CONV2_FILTERS = 128
integer, parameter :: CONV3_FILTERS = 256
```

### Option 2: Custom Training Code

Create `fashion_mnist_custom_main.cuf` with different architecture while still using common modules for optimizer, batch extraction, etc.

## Next Steps

After adding Fashion-MNIST:

1. **Compare performance**: How does it compare to PyTorch?
2. **Try optimizations**: Adjust learning rate, batch size, etc.
3. **Add augmentation**: Modify preprocessing script
4. **Add another dataset**: Now you're an expert!

## Summary

Adding a new dataset requires:
- **Dataset config**: ~150 lines (mostly copy-paste)
- **Preprocessing**: ~100 lines (modify template)
- **Compilation script**: ~20 lines (copy template)
- **Main training**: 0 lines (reuse generic training!)

**Total new code**: ~270 lines, ~1-2 hours

**The modular architecture pays off!** ðŸš€
