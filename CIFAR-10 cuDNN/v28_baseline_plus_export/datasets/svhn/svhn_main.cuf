
module svhn_data_module
    !================================================================
    ! SVHN Data Module for v27 (Python Preprocessing)
    !================================================================
    ! This module loads SVHN data that has been preprocessed by
    ! prepare_svhn.py (following Oxford Flowers pattern).
    !
    ! Data format (from Python):
    ! - images_train.bin: (3, 32, 32, 50000) float32, normalized [0, 1]
    ! - labels_train.bin: (50000) int32, range [0, 9]
    ! - images_test.bin: (3, 32, 32, 10000) float32
    ! - labels_test.bin: (10000) int32
    !
    ! Much simpler than v26 - Python handles all preprocessing!
    !================================================================
    use cudafor
    use iso_c_binding
    implicit none

    ! Dataset parameters
    integer, parameter :: train_samples = 73257
    integer, parameter :: test_samples = 26032
    integer, parameter :: num_classes = 10
    integer, parameter :: INPUT_CHANNELS = 3
    integer, parameter :: INPUT_HEIGHT = 32, INPUT_WIDTH = 32
    integer, parameter :: input_size = 3072  ! 3*32*32

    ! CNN Architecture Parameters (same as v26)
    integer, parameter :: CONV1_FILTERS = 32, CONV2_FILTERS = 64, CONV3_FILTERS = 128
    integer, parameter :: KERNEL_SIZE = 3, PADDING = 1, STRIDE = 1
    integer, parameter :: POOL_SIZE = 2, POOL_STRIDE = 2

    ! GPU memory for dataset
    real(4), device, allocatable, public :: gpu_train_data(:,:)     ! (50000, 3072)
    integer, device, allocatable, public :: gpu_train_labels(:)     ! (50000)
    real(4), device, allocatable, public :: gpu_test_data(:,:)      ! (10000, 3072)
    integer, device, allocatable, public :: gpu_test_labels(:)      ! (10000)

    logical :: data_loaded = .false.

    public :: load_svhn_data, is_data_loaded
    public :: train_samples, test_samples, input_size, num_classes

contains

    subroutine load_svhn_data()
        !================================================================
        ! Load SVHN from Python-preprocessed binary files
        ! Python writes (3072, N) transposed ‚Üí Fortran reads as (N, 3072)
        !================================================================
        character(len=*), parameter :: DATA_DIR = 'svhn_data/'

        real(4), allocatable :: train_images(:,:)  ! (50000, 3072) - already flattened!
        real(4), allocatable :: test_images(:,:)   ! (10000, 3072)
        integer, allocatable :: train_labels(:)    ! (50000)
        integer, allocatable :: test_labels(:)     ! (10000)

        integer :: stat

        print *, "======================================================================"
        print *, "Loading SVHN (v27 - Python Preprocessing)"
        print *, "======================================================================"

        ! Allocate host arrays - Python already flattened to (N, 3072)
        allocate(train_images(train_samples, input_size))
        allocate(train_labels(train_samples))
        allocate(test_images(test_samples, input_size))
        allocate(test_labels(test_samples))

        ! Load training images
        print *, "Loading training images..."
        open(unit=10, file=DATA_DIR//'images_train.bin', form='unformatted', &
             access='stream', status='old', iostat=stat)
        if (stat /= 0) then
            print *, "ERROR: Cannot open images_train.bin"
            print *, "Run: python prepare_svhn.py"
            stop
        endif
        read(10) train_images
        close(10)

        ! Load training labels
        open(unit=10, file=DATA_DIR//'labels_train.bin', form='unformatted', &
             access='stream', status='old')
        read(10) train_labels
        close(10)

        ! Load test images
        print *, "Loading test images..."
        open(unit=10, file=DATA_DIR//'images_test.bin', form='unformatted', &
             access='stream', status='old')
        read(10) test_images
        close(10)

        ! Load test labels
        open(unit=10, file=DATA_DIR//'labels_test.bin', form='unformatted', &
             access='stream', status='old')
        read(10) test_labels
        close(10)

        print *, "Data loaded successfully!"
        print *, "  Training:   ", train_samples, " samples"
        print *, "  Test:       ", test_samples, " samples"

        ! Verify data ranges
        print *, ""
        print *, "Data Statistics:"
        print *, "  Train images - Min:", minval(train_images), " Max:", maxval(train_images)
        print *, "  Train labels - Min:", minval(train_labels), " Max:", maxval(train_labels)
        print *, "  Test images - Min:", minval(test_images), " Max:", maxval(test_images)
        print *, "  Test labels - Min:", minval(test_labels), " Max:", maxval(test_labels)

        ! Allocate GPU arrays
        print *, ""
        print *, "Transferring to GPU..."
        allocate(gpu_train_data(train_samples, input_size))
        allocate(gpu_train_labels(train_samples))
        allocate(gpu_test_data(test_samples, input_size))
        allocate(gpu_test_labels(test_samples))

        ! Copy to GPU - data is already in correct (N, 3072) format!
        gpu_train_data = train_images
        gpu_train_labels = train_labels
        gpu_test_data = test_images
        gpu_test_labels = test_labels

        ! Cleanup host arrays
        deallocate(train_images, test_images, train_labels, test_labels)

        data_loaded = .true.
        print *, "GPU transfer complete!"
        print *, "======================================================================"
        print *, ""
    end subroutine load_svhn_data

    function is_data_loaded() result(loaded)
        logical :: loaded
        loaded = data_loaded
    end function is_data_loaded

end module svhn_data_module

! SVHN CNN Training using Pure cuDNN Intrinsics
module cudnn_cifar10
    use cudafor
    use iso_c_binding
    use ieee_arithmetic
    use curand_wrapper_module  ! cuRAND for weight initialization
    use apex_adam_kernels      ! NVIDIA Apex FusedAdam optimizer
    implicit none

    ! cuDNN constants
    integer(c_int), parameter :: CUDNN_STATUS_SUCCESS = 0
    integer(c_int), parameter :: CUDNN_TENSOR_NCHW = 0
    integer(c_int), parameter :: CUDNN_DATA_FLOAT = 0
    integer(c_int), parameter :: CUDNN_CROSS_CORRELATION = 0
    integer(c_int), parameter :: CUDNN_POOLING_MAX = 0
    integer(c_int), parameter :: CUDNN_ACTIVATION_RELU = 1
    integer(c_int), parameter :: CUDNN_ACTIVATION_ELU = 4  ! ELU: f(x) = x if x>0, else alpha*(exp(x)-1)
    integer(c_int), parameter :: CUDNN_PROPAGATE_NAN = 0
    integer(c_int), parameter :: CUDNN_SOFTMAX_ACCURATE = 0
    integer(c_int), parameter :: CUDNN_SOFTMAX_MODE_CHANNEL = 1
    integer(c_int), parameter :: CUDNN_BATCHNORM_SPATIAL = 1

    ! Algorithm constants
    integer(c_int), parameter :: CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM = 0
    integer(c_int), parameter :: CUDNN_CONVOLUTION_BWD_DATA_ALGO_1 = 1
    integer(c_int), parameter :: CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1 = 1

    ! Network architecture
    integer, parameter :: BATCH_SIZE = 128
    integer, parameter :: CNN_NUM_CLASSES = 10  ! Renamed to avoid conflict
    integer, parameter :: CNN_INPUT_SIZE = 3 * 32 * 32  ! Renamed to avoid conflict
    integer, parameter :: INPUT_HEIGHT = 32
    integer, parameter :: INPUT_WIDTH = 32

    ! Layer dimensions
    integer, parameter :: CONV1_FILTERS = 32
    integer, parameter :: CONV2_FILTERS = 64
    integer, parameter :: CONV3_FILTERS = 128
    integer, parameter :: FC1_SIZE = 512
    integer, parameter :: FC2_SIZE = 256
    integer, parameter :: FC3_SIZE = 10

    logical, save :: debug_nan_checks = .true.  ! Set to .false. after debugging

    ! Global handles
    type(c_ptr) :: cudnn_handle = c_null_ptr
    type(c_ptr) :: cublas_handle = c_null_ptr

    ! Adam optimizer hyperparameters now provided by apex_adam_kernels module
    ! (adam_beta1, adam_beta2, adam_epsilon, weight_decay)

    ! ========================================================================
    ! CNN Layer Structure - holds everything for one model
    ! ========================================================================
    type :: cnn_model
        ! Descriptors
        type(c_ptr) :: input_desc, conv1_desc, conv2_desc, conv3_desc
        type(c_ptr) :: pool1_desc, pool2_desc, pool3_desc
        type(c_ptr) :: fc1_desc, fc2_desc, fc3_desc, output_desc
        type(c_ptr) :: conv1_filter_desc, conv2_filter_desc, conv3_filter_desc
        type(c_ptr) :: conv1_bias_desc, conv2_bias_desc, conv3_bias_desc
        type(c_ptr) :: conv1_conv_desc, conv2_conv_desc, conv3_conv_desc
        type(c_ptr) :: pooling_desc, activation_desc
        type(c_ptr) :: bn1_desc, bn2_desc, bn3_desc

        ! Layer outputs (forward pass) - V26: (W,H,C,N) layout
        ! Note: allocatable in derived types work with c_loc() (Fortran 2003+)
        real(4), device, allocatable :: input(:,:,:,:)          ! (32,32,3,N)
        real(4), device, allocatable :: conv1_out(:,:,:,:)      ! (32,32,32,N)
        real(4), device, allocatable :: bn1_out(:,:,:,:)        ! (32,32,32,N)
        real(4), device, allocatable :: relu1_out(:,:,:,:)      ! (32,32,32,N)
        real(4), device, allocatable :: pool1_out(:,:,:,:)      ! (16,16,32,N)
        real(4), device, allocatable :: conv2_out(:,:,:,:)      ! (16,16,64,N)
        real(4), device, allocatable :: bn2_out(:,:,:,:)        ! (16,16,64,N)
        real(4), device, allocatable :: relu2_out(:,:,:,:)      ! (16,16,64,N)
        real(4), device, allocatable :: pool2_out(:,:,:,:)      ! (8,8,64,N)
        real(4), device, allocatable :: conv3_out(:,:,:,:)      ! (8,8,128,N)
        real(4), device, allocatable :: bn3_out(:,:,:,:)        ! (8,8,128,N)
        real(4), device, allocatable :: relu3_out(:,:,:,:)      ! (8,8,128,N)
        real(4), device, allocatable :: pool3_out(:,:,:,:)      ! (4,4,128,N)

        ! FC layers - forward pass states
        real(4), device, allocatable :: flatten(:,:)         ! (batch, 2048)
        real(4), device, allocatable :: fc1_out(:,:)         ! (batch, 512)
        real(4), device, allocatable :: fc1_relu(:,:)        ! (batch, 512)
        real(4), device, allocatable :: fc1_dropout(:,:)     ! (batch, 512)
        real(4), device, allocatable :: fc2_out(:,:)         ! (batch, 256)
        real(4), device, allocatable :: fc2_relu(:,:)        ! (batch, 256)
        real(4), device, allocatable :: fc2_dropout(:,:)     ! (batch, 256)
        real(4), device, allocatable :: fc3_out(:,:)         ! (batch, 10)
        real(4), device, allocatable :: softmax_out(:,:)     ! (batch, 10)

        ! Weights and biases
        real(4), device, allocatable :: conv1_weights(:,:,:,:), conv1_bias(:)
        real(4), device, allocatable :: conv2_weights(:,:,:,:), conv2_bias(:)
        real(4), device, allocatable :: conv3_weights(:,:,:,:), conv3_bias(:)
        real(4), device, allocatable :: fc1_weights(:,:), fc1_bias(:)
        real(4), device, allocatable :: fc2_weights(:,:), fc2_bias(:)
        real(4), device, allocatable :: fc3_weights(:,:), fc3_bias(:)

        ! Batch normalization parameters
        real(4), device, allocatable :: bn1_scale(:), bn1_bias(:)
        real(4), device, allocatable :: bn1_running_mean(:), bn1_running_var(:)
        real(4), device, allocatable :: bn1_saved_mean(:), bn1_saved_inv_var(:)
        real(4), device, allocatable :: bn2_scale(:), bn2_bias(:)
        real(4), device, allocatable :: bn2_running_mean(:), bn2_running_var(:)
        real(4), device, allocatable :: bn2_saved_mean(:), bn2_saved_inv_var(:)
        real(4), device, allocatable :: bn3_scale(:), bn3_bias(:)
        real(4), device, allocatable :: bn3_running_mean(:), bn3_running_var(:)
        real(4), device, allocatable :: bn3_saved_mean(:), bn3_saved_inv_var(:)

        ! Conv gradients (backward pass) - V26: (W,H,C,N) layout
        real(4), device, allocatable :: grad_input(:,:,:,:)       ! (32,32,3,N)
        real(4), device, allocatable :: grad_conv1(:,:,:,:)       ! (32,32,32,N)
        real(4), device, allocatable :: grad_bn1(:,:,:,:)         ! (32,32,32,N)
        real(4), device, allocatable :: grad_relu1(:,:,:,:)       ! (32,32,32,N)
        real(4), device, allocatable :: grad_pool1(:,:,:,:)       ! (16,16,32,N)
        real(4), device, allocatable :: grad_conv2(:,:,:,:)       ! (16,16,64,N)
        real(4), device, allocatable :: grad_bn2(:,:,:,:)         ! (16,16,64,N)
        real(4), device, allocatable :: grad_relu2(:,:,:,:)       ! (16,16,64,N)
        real(4), device, allocatable :: grad_pool2(:,:,:,:)       ! (8,8,64,N)
        real(4), device, allocatable :: grad_conv3(:,:,:,:)       ! (8,8,128,N)
        real(4), device, allocatable :: grad_bn3(:,:,:,:)         ! (8,8,128,N)
        real(4), device, allocatable :: grad_relu3(:,:,:,:)       ! (8,8,128,N)
        real(4), device, allocatable :: grad_pool3(:,:,:,:)       ! (4,4,128,N)

        ! ‚úÖ FC gradients - INCLUDING intermediate states for dropout/relu backward
        real(4), device, allocatable :: grad_fc1(:,:)            ! (batch, 512)
        real(4), device, allocatable :: grad_fc1_dropout(:,:)    ! (batch, 512)
        real(4), device, allocatable :: grad_fc1_relu(:,:)       ! (batch, 512)
        real(4), device, allocatable :: grad_fc2(:,:)            ! (batch, 256)
        real(4), device, allocatable :: grad_fc2_dropout(:,:)    ! (batch, 256)
        real(4), device, allocatable :: grad_fc2_relu(:,:)       ! (batch, 256)
        real(4), device, allocatable :: grad_fc3(:,:)            ! (batch, 10)

        ! Weight gradients
        real(4), device, allocatable :: grad_conv1_weights(:,:,:,:), grad_conv1_bias(:)
        real(4), device, allocatable :: grad_conv2_weights(:,:,:,:), grad_conv2_bias(:)
        real(4), device, allocatable :: grad_conv3_weights(:,:,:,:), grad_conv3_bias(:)
        real(4), device, allocatable :: grad_fc1_weights(:,:), grad_fc1_bias(:)
        real(4), device, allocatable :: grad_fc2_weights(:,:), grad_fc2_bias(:)
        real(4), device, allocatable :: grad_fc3_weights(:,:), grad_fc3_bias(:)
        real(4), device, allocatable :: grad_bn1_scale(:), grad_bn1_bias(:)
        real(4), device, allocatable :: grad_bn2_scale(:), grad_bn2_bias(:)
        real(4), device, allocatable :: grad_bn3_scale(:), grad_bn3_bias(:)

        ! Dropout descriptor and states
        type(c_ptr) :: dropout_desc = c_null_ptr
        real(4), device, allocatable :: dropout_states(:)
        integer(c_size_t) :: dropout_state_size = 0

        ! Dropout reserve space (for FC1 and FC2)
        real(4), device, allocatable :: fc1_dropout_reserve(:)
        real(4), device, allocatable :: fc2_dropout_reserve(:)
        integer(c_size_t) :: fc1_reserve_size = 0
        integer(c_size_t) :: fc2_reserve_size = 0

        ! Workspace for convolution algorithms
        real(4), device, allocatable :: workspace(:)
        integer(c_size_t) :: workspace_size = 0

        ! ‚úÖ ADD: Adam optimizer state
        ! First moments (m)
        real(4), device, allocatable :: m_conv1_weights(:,:,:,:), m_conv1_bias(:)
        real(4), device, allocatable :: m_conv2_weights(:,:,:,:), m_conv2_bias(:)
        real(4), device, allocatable :: m_conv3_weights(:,:,:,:), m_conv3_bias(:)
        real(4), device, allocatable :: m_fc1_weights(:,:), m_fc1_bias(:)
        real(4), device, allocatable :: m_fc2_weights(:,:), m_fc2_bias(:)
        real(4), device, allocatable :: m_fc3_weights(:,:), m_fc3_bias(:)
        real(4), device, allocatable :: m_bn1_scale(:), m_bn1_bias(:)
        real(4), device, allocatable :: m_bn2_scale(:), m_bn2_bias(:)
        real(4), device, allocatable :: m_bn3_scale(:), m_bn3_bias(:)

        ! Second moments (v)
        real(4), device, allocatable :: v_conv1_weights(:,:,:,:), v_conv1_bias(:)
        real(4), device, allocatable :: v_conv2_weights(:,:,:,:), v_conv2_bias(:)
        real(4), device, allocatable :: v_conv3_weights(:,:,:,:), v_conv3_bias(:)
        real(4), device, allocatable :: v_fc1_weights(:,:), v_fc1_bias(:)
        real(4), device, allocatable :: v_fc2_weights(:,:), v_fc2_bias(:)
        real(4), device, allocatable :: v_fc3_weights(:,:), v_fc3_bias(:)
        real(4), device, allocatable :: v_bn1_scale(:), v_bn1_bias(:)
        real(4), device, allocatable :: v_bn2_scale(:), v_bn2_bias(:)
        real(4), device, allocatable :: v_bn3_scale(:), v_bn3_bias(:)

        ! Timestep counter
        integer :: adam_timestep = 0
    end type cnn_model

    ! ========================================================================
    ! cuDNN C Interface - Direct bindings
    ! ========================================================================
    interface
        function cudnnCreate(handle) bind(c, name='cudnnCreate')
            import :: c_ptr, c_int
            type(c_ptr), intent(out) :: handle
            integer(c_int) :: cudnnCreate
        end function

        function cudnnDestroy(handle) bind(c, name='cudnnDestroy')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle
            integer(c_int) :: cudnnDestroy
        end function

        function cudnnCreateTensorDescriptor(desc) bind(c, name='cudnnCreateTensorDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), intent(out) :: desc
            integer(c_int) :: cudnnCreateTensorDescriptor
        end function

        function cudnnSetTensor4dDescriptor(desc, format, datatype, n, c, h, w) &
                bind(c, name='cudnnSetTensor4dDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int), value :: format, datatype, n, c, h, w
            integer(c_int) :: cudnnSetTensor4dDescriptor
        end function

        function cudnnSetTensorNdDescriptor(desc, datatype, nbDims, dimA, strideA) &
                bind(c, name='cudnnSetTensorNdDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int), value :: datatype, nbDims
            integer(c_int), intent(in) :: dimA(*), strideA(*)
            integer(c_int) :: cudnnSetTensorNdDescriptor
        end function

        function cudnnDestroyTensorDescriptor(desc) bind(c, name='cudnnDestroyTensorDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int) :: cudnnDestroyTensorDescriptor
        end function

        function cudnnCreateFilterDescriptor(desc) bind(c, name='cudnnCreateFilterDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), intent(out) :: desc
            integer(c_int) :: cudnnCreateFilterDescriptor
        end function

        function cudnnSetFilter4dDescriptor(desc, datatype, format, k, c, h, w) &
                bind(c, name='cudnnSetFilter4dDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int), value :: datatype, format, k, c, h, w
            integer(c_int) :: cudnnSetFilter4dDescriptor
        end function

        function cudnnDestroyFilterDescriptor(desc) bind(c, name='cudnnDestroyFilterDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int) :: cudnnDestroyFilterDescriptor
        end function

        function cudnnCreateConvolutionDescriptor(desc) bind(c, name='cudnnCreateConvolutionDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), intent(out) :: desc
            integer(c_int) :: cudnnCreateConvolutionDescriptor
        end function

        function cudnnSetConvolution2dDescriptor(desc, pad_h, pad_w, u, v, dilation_h, dilation_w, mode, datatype) &
                bind(c, name='cudnnSetConvolution2dDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int), value :: pad_h, pad_w, u, v, dilation_h, dilation_w, mode, datatype
            integer(c_int) :: cudnnSetConvolution2dDescriptor
        end function

        function cudnnDestroyConvolutionDescriptor(desc) bind(c, name='cudnnDestroyConvolutionDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int) :: cudnnDestroyConvolutionDescriptor
        end function

        function cudnnCreatePoolingDescriptor(desc) bind(c, name='cudnnCreatePoolingDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), intent(out) :: desc
            integer(c_int) :: cudnnCreatePoolingDescriptor
        end function

        function cudnnSetPooling2dDescriptor(desc, mode, nan_opt, window_h, window_w, pad_h, pad_w, stride_h, stride_w) &
                bind(c, name='cudnnSetPooling2dDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int), value :: mode, nan_opt, window_h, window_w, pad_h, pad_w, stride_h, stride_w
            integer(c_int) :: cudnnSetPooling2dDescriptor
        end function

        function cudnnDestroyPoolingDescriptor(desc) bind(c, name='cudnnDestroyPoolingDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int) :: cudnnDestroyPoolingDescriptor
        end function

        function cudnnCreateActivationDescriptor(desc) bind(c, name='cudnnCreateActivationDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), intent(out) :: desc
            integer(c_int) :: cudnnCreateActivationDescriptor
        end function

        function cudnnSetActivationDescriptor(desc, mode, relu_nan_opt, coef) &
                bind(c, name='cudnnSetActivationDescriptor')
            import :: c_ptr, c_int, c_double
            type(c_ptr), value :: desc
            integer(c_int), value :: mode, relu_nan_opt
            real(c_double), value :: coef
            integer(c_int) :: cudnnSetActivationDescriptor
        end function

        function cudnnDestroyActivationDescriptor(desc) bind(c, name='cudnnDestroyActivationDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: desc
            integer(c_int) :: cudnnDestroyActivationDescriptor
        end function

        ! Forward operations
        function cudnnConvolutionForward(handle, alpha, x_desc, x, w_desc, w, conv_desc, algo, &
                workspace, workspace_size, beta, y_desc, y) bind(c, name='cudnnConvolutionForward')
            import :: c_ptr, c_int, c_size_t
            type(c_ptr), value :: handle, alpha, x_desc, x, w_desc, w, conv_desc, y_desc, y, workspace, beta
            integer(c_int), value :: algo
            integer(c_size_t), value :: workspace_size
            integer(c_int) :: cudnnConvolutionForward
        end function

        function cudnnAddTensor(handle, alpha, a_desc, a, beta, c_desc, c) bind(c, name='cudnnAddTensor')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, alpha, a_desc, a, beta, c_desc, c
            integer(c_int) :: cudnnAddTensor
        end function

        function cudnnActivationForward(handle, activation_desc, alpha, x_desc, x, beta, y_desc, y) &
                bind(c, name='cudnnActivationForward')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, activation_desc, alpha, x_desc, x, beta, y_desc, y
            integer(c_int) :: cudnnActivationForward
        end function

        function cudnnPoolingForward(handle, pool_desc, alpha, x_desc, x, beta, y_desc, y) &
                bind(c, name='cudnnPoolingForward')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, pool_desc, alpha, x_desc, x, beta, y_desc, y
            integer(c_int) :: cudnnPoolingForward
        end function

        function cudnnBatchNormalizationForwardTraining(handle, mode, alpha, beta, x_desc, x, y_desc, y, &
                bn_scale_bias_mean_var_desc, bn_scale, bn_bias, exponential_average_factor, &
                result_running_mean, result_running_variance, epsilon, result_save_mean, result_save_inv_variance) &
                bind(c, name='cudnnBatchNormalizationForwardTraining')
            import :: c_ptr, c_int, c_double
            type(c_ptr), value :: handle, alpha, beta, x_desc, x, y_desc, y, bn_scale_bias_mean_var_desc
            type(c_ptr), value :: bn_scale, bn_bias, result_running_mean, result_running_variance
            type(c_ptr), value :: result_save_mean, result_save_inv_variance
            integer(c_int), value :: mode
            real(c_double), value :: exponential_average_factor, epsilon
            integer(c_int) :: cudnnBatchNormalizationForwardTraining
        end function

        function cudnnBatchNormalizationForwardInference(handle, mode, alpha, beta, x_desc, x, y_desc, y, &
                bn_scale_bias_mean_var_desc, bn_scale, bn_bias, &
                estimated_mean, estimated_variance, epsilon) &
                bind(c, name='cudnnBatchNormalizationForwardInference')
            import :: c_ptr, c_int, c_double
            type(c_ptr), value :: handle, alpha, beta, x_desc, x, y_desc, y, bn_scale_bias_mean_var_desc
            type(c_ptr), value :: bn_scale, bn_bias, estimated_mean, estimated_variance
            integer(c_int), value :: mode
            real(c_double), value :: epsilon
            integer(c_int) :: cudnnBatchNormalizationForwardInference
        end function

        function cudnnSoftmaxForward(handle, algo, mode, alpha, x_desc, x, beta, y_desc, y) &
                bind(c, name='cudnnSoftmaxForward')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, alpha, x_desc, x, beta, y_desc, y
            integer(c_int), value :: algo, mode
            integer(c_int) :: cudnnSoftmaxForward
        end function

        ! Backward operations
        function cudnnConvolutionBackwardData(handle, alpha, w_desc, w, dy_desc, dy, conv_desc, algo, &
                workspace, workspace_size, beta, dx_desc, dx) bind(c, name='cudnnConvolutionBackwardData')
            import :: c_ptr, c_int, c_size_t
            type(c_ptr), value :: handle, alpha, w_desc, w, dy_desc, dy, conv_desc, dx_desc, dx, workspace, beta
            integer(c_int), value :: algo
            integer(c_size_t), value :: workspace_size
            integer(c_int) :: cudnnConvolutionBackwardData
        end function

        function cudnnConvolutionBackwardFilter(handle, alpha, x_desc, x, dy_desc, dy, conv_desc, algo, &
                workspace, workspace_size, beta, dw_desc, dw) bind(c, name='cudnnConvolutionBackwardFilter')
            import :: c_ptr, c_int, c_size_t
            type(c_ptr), value :: handle, alpha, x_desc, x, dy_desc, dy, conv_desc, dw_desc, dw, workspace, beta
            integer(c_int), value :: algo
            integer(c_size_t), value :: workspace_size
            integer(c_int) :: cudnnConvolutionBackwardFilter
        end function

        function cudnnConvolutionBackwardBias(handle, alpha, dy_desc, dy, beta, db_desc, db) &
                bind(c, name='cudnnConvolutionBackwardBias')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, alpha, dy_desc, dy, beta, db_desc, db
            integer(c_int) :: cudnnConvolutionBackwardBias
        end function

        function cudnnActivationBackward(handle, activation_desc, alpha, y_desc, y, dy_desc, dy, &
                x_desc, x, beta, dx_desc, dx) bind(c, name='cudnnActivationBackward')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, activation_desc, alpha, y_desc, y, dy_desc, dy, x_desc, x, beta, dx_desc, dx
            integer(c_int) :: cudnnActivationBackward
        end function

        function cudnnPoolingBackward(handle, pool_desc, alpha, y_desc, y, dy_desc, dy, x_desc, x, &
                beta, dx_desc, dx) bind(c, name='cudnnPoolingBackward')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, pool_desc, alpha, y_desc, y, dy_desc, dy, x_desc, x, beta, dx_desc, dx
            integer(c_int) :: cudnnPoolingBackward
        end function

        function cudnnBatchNormalizationBackward(handle, mode, alpha_data, beta_data, alpha_param, beta_param, &
                x_desc, x, dy_desc, dy, dx_desc, dx, bn_scale_bias_diff_desc, bn_scale, &
                result_bn_scale_diff, result_bn_bias_diff, epsilon, saved_mean, saved_inv_variance) &
                bind(c, name='cudnnBatchNormalizationBackward')
            import :: c_ptr, c_int, c_double
            type(c_ptr), value :: handle, alpha_data, beta_data, alpha_param, beta_param
            type(c_ptr), value :: x_desc, x, dy_desc, dy, dx_desc, dx, bn_scale_bias_diff_desc
            type(c_ptr), value :: bn_scale, result_bn_scale_diff, result_bn_bias_diff, saved_mean, saved_inv_variance
            integer(c_int), value :: mode
            real(c_double), value :: epsilon
            integer(c_int) :: cudnnBatchNormalizationBackward
        end function

        function cudnnSoftmaxBackward(handle, algo, mode, alpha, y_desc, y, dy_desc, dy, beta, dx_desc, dx) &
                bind(c, name='cudnnSoftmaxBackward')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle, alpha, y_desc, y, dy_desc, dy, beta, dx_desc, dx
            integer(c_int), value :: algo, mode
            integer(c_int) :: cudnnSoftmaxBackward
        end function

        ! DROPOUT FUNCTIONS
        function cudnnCreateDropoutDescriptor(dropout_desc) &
                bind(c, name='cudnnCreateDropoutDescriptor')
            import :: c_ptr, c_int
            type(c_ptr) :: dropout_desc
            integer(c_int) :: cudnnCreateDropoutDescriptor
        end function

        function cudnnDropoutGetStatesSize(handle, size_in_bytes) &
                bind(c, name='cudnnDropoutGetStatesSize')
            import :: c_ptr, c_int, c_size_t
            type(c_ptr), value :: handle
            integer(c_size_t) :: size_in_bytes
            integer(c_int) :: cudnnDropoutGetStatesSize
        end function

        function cudnnDropoutGetReserveSpaceSize(x_desc, size_in_bytes) &
                bind(c, name='cudnnDropoutGetReserveSpaceSize')
            import :: c_ptr, c_int, c_size_t
            type(c_ptr), value :: x_desc
            integer(c_size_t) :: size_in_bytes
            integer(c_int) :: cudnnDropoutGetReserveSpaceSize
        end function

        function cudnnSetDropoutDescriptor(dropout_desc, handle, dropout, states, &
                state_size_in_bytes, seed) &
                bind(c, name='cudnnSetDropoutDescriptor')
            import :: c_ptr, c_int, c_float, c_size_t, c_long_long
            type(c_ptr), value :: dropout_desc, handle, states
            real(c_float), value :: dropout
            integer(c_size_t), value :: state_size_in_bytes
            integer(c_long_long), value :: seed
            integer(c_int) :: cudnnSetDropoutDescriptor
        end function

        function cudnnDropoutForward(handle, dropout_desc, x_desc, x, y_desc, y, &
                reserve_space, reserve_space_size_in_bytes) &
                bind(c, name='cudnnDropoutForward')
            import :: c_ptr, c_int, c_size_t
            type(c_ptr), value :: handle, dropout_desc, x_desc, x, y_desc, y, reserve_space
            integer(c_size_t), value :: reserve_space_size_in_bytes
            integer(c_int) :: cudnnDropoutForward
        end function

        function cudnnDropoutBackward(handle, dropout_desc, dy_desc, dy, dx_desc, dx, &
                reserve_space, reserve_space_size_in_bytes) &
                bind(c, name='cudnnDropoutBackward')
            import :: c_ptr, c_int, c_size_t
            type(c_ptr), value :: handle, dropout_desc, dy_desc, dy, dx_desc, dx, reserve_space
            integer(c_size_t), value :: reserve_space_size_in_bytes
            integer(c_int) :: cudnnDropoutBackward
        end function

        function cudnnDestroyDropoutDescriptor(dropout_desc) &
                bind(c, name='cudnnDestroyDropoutDescriptor')
            import :: c_ptr, c_int
            type(c_ptr), value :: dropout_desc
            integer(c_int) :: cudnnDestroyDropoutDescriptor
        end function
    end interface

    ! cuBLAS interface for FC layers
    interface
        function cublasCreate_v2(handle) bind(c, name='cublasCreate_v2')
            import :: c_ptr, c_int
            type(c_ptr), intent(out) :: handle
            integer(c_int) :: cublasCreate_v2
        end function

        function cublasDestroy_v2(handle) bind(c, name='cublasDestroy_v2')
            import :: c_ptr, c_int
            type(c_ptr), value :: handle
            integer(c_int) :: cublasDestroy_v2
        end function

        function cublasSgemm_v2(handle, transa, transb, m, n, k, alpha, a, lda, b, ldb, &
                beta, c, ldc) bind(c, name='cublasSgemm_v2')
            import :: c_ptr, c_int, c_float
            type(c_ptr), value :: handle, alpha, a, b, beta, c
            integer(c_int), value :: transa, transb, m, n, k, lda, ldb, ldc
            integer(c_int) :: cublasSgemm_v2
        end function

        function cublasSgemv_v2(handle, trans, m, n, alpha, a, lda, x, incx, beta, y, incy) &
                bind(c, name='cublasSgemv_v2')
            import :: c_ptr, c_int, c_float
            type(c_ptr), value :: handle, alpha, a, x, beta, y
            integer(c_int), value :: trans, m, n, lda, incx, incy
            integer(c_int) :: cublasSgemv_v2
        end function
    end interface
contains

    ! ========================================================================
    ! LeakyReLU Custom Kernels (cuDNN 6 doesn't have native LeakyReLU)
    ! ========================================================================

    ! LeakyReLU forward for 4D tensors (conv layers)
    attributes(global) subroutine leaky_relu_forward_4d_kernel(input, output, n, slope)
        real(4), device :: input(*), output(*)
        integer, value :: n
        real(4), value :: slope
        integer :: idx
        real(4) :: val

        idx = (blockIdx%x - 1) * blockDim%x + threadIdx%x
        if (idx <= n) then
            val = input(idx)
            if (val > 0.0) then
                output(idx) = val
            else
                output(idx) = slope * val
            endif
        endif
    end subroutine leaky_relu_forward_4d_kernel

    ! LeakyReLU backward for 4D tensors
    attributes(global) subroutine leaky_relu_backward_4d_kernel(grad_output, input, grad_input, n, slope)
        real(4), device :: grad_output(*), input(*), grad_input(*)
        integer, value :: n
        real(4), value :: slope
        integer :: idx

        idx = (blockIdx%x - 1) * blockDim%x + threadIdx%x
        if (idx <= n) then
            if (input(idx) > 0.0) then
                grad_input(idx) = grad_output(idx)
            else
                grad_input(idx) = slope * grad_output(idx)
            endif
        endif
    end subroutine leaky_relu_backward_4d_kernel

    ! Wrapper for LeakyReLU forward (4D)
    subroutine apply_leaky_relu_4d(input, output, total_size, slope)
        real(4), device :: input(*), output(*)
        integer, intent(in) :: total_size
        real(4), intent(in) :: slope
        integer :: threads, blocks

        threads = 256
        blocks = (total_size + threads - 1) / threads
        call leaky_relu_forward_4d_kernel<<<blocks, threads>>>(input, output, total_size, slope)
    end subroutine apply_leaky_relu_4d

    ! Wrapper for LeakyReLU backward (4D)
    subroutine apply_leaky_relu_backward_4d(grad_output, input, grad_input, total_size, slope)
        real(4), device :: grad_output(*), input(*), grad_input(*)
        integer, intent(in) :: total_size
        real(4), intent(in) :: slope
        integer :: threads, blocks

        threads = 256
        blocks = (total_size + threads - 1) / threads
        call leaky_relu_backward_4d_kernel<<<blocks, threads>>>(grad_output, input, grad_input, total_size, slope)
    end subroutine apply_leaky_relu_backward_4d

    ! Wrapper for LeakyReLU forward (2D - FC layers)
    subroutine apply_leaky_relu_2d(input, output, total_size, slope)
        real(4), device :: input(*), output(*)
        integer, intent(in) :: total_size
        real(4), intent(in) :: slope

        ! Reuse 4D kernel (works the same for flattened data)
        call apply_leaky_relu_4d(input, output, total_size, slope)
    end subroutine apply_leaky_relu_2d

    ! Wrapper for LeakyReLU backward (2D - FC layers)
    subroutine apply_leaky_relu_backward_2d(grad_output, input, grad_input, total_size, slope)
        real(4), device :: grad_output(*), input(*), grad_input(*)
        integer, intent(in) :: total_size
        real(4), intent(in) :: slope

        ! Reuse 4D kernel (works the same for flattened data)
        call apply_leaky_relu_backward_4d(grad_output, input, grad_input, total_size, slope)
    end subroutine apply_leaky_relu_backward_2d

    ! ========================================================================
    ! CUSTOM 2D SOFTMAX KERNEL (Fortran column-major layout)
    ! ========================================================================
    ! Computes softmax for 2D arrays (batch, classes) in Fortran layout
    ! Each row (across classes) sums to 1.0
    attributes(global) subroutine softmax_2d_kernel(input, output, batch_size, num_classes)
        real(4), device :: input(:,:), output(:,:)
        integer, value :: batch_size, num_classes
        integer :: i, j
        real(4) :: max_val, sum_exp, val

        i = (blockIdx%x - 1) * blockDim%x + threadIdx%x  ! batch index

        if (i <= batch_size) then
            ! Find max for numerical stability
            max_val = input(i, 1)
            do j = 2, num_classes
                if (input(i, j) > max_val) max_val = input(i, j)
            end do

            ! Compute exp and sum
            sum_exp = 0.0
            do j = 1, num_classes
                val = exp(input(i, j) - max_val)
                output(i, j) = val
                sum_exp = sum_exp + val
            end do

            ! Normalize
            do j = 1, num_classes
                output(i, j) = output(i, j) / sum_exp
            end do
        endif
    end subroutine softmax_2d_kernel

    subroutine apply_softmax_2d(input, output, batch_size, num_classes)
        real(4), device, intent(in) :: input(:,:)
        real(4), device, intent(out) :: output(:,:)
        integer, intent(in) :: batch_size, num_classes
        integer :: threads, blocks

        threads = 128
        blocks = (batch_size + threads - 1) / threads

        call softmax_2d_kernel<<<blocks, threads>>>(input, output, batch_size, num_classes)
    end subroutine apply_softmax_2d

    ! ========================================================================
    ! Initialize cuDNN and cuBLAS
    ! ========================================================================
    subroutine init_cudnn_cublas()
        integer :: stat

        stat = cudnnCreate(cudnn_handle)
        if (stat /= CUDNN_STATUS_SUCCESS) then
            print *, "Failed to create cuDNN handle"
            stop
        end if

        stat = cublasCreate_v2(cublas_handle)
        if (stat /= 0) then
            print *, "Failed to create cuBLAS handle"
            stop
        end if

        print *, "‚úÖ cuDNN and cuBLAS initialized"
    end subroutine init_cudnn_cublas

    ! ========================================================================
    ! V26: Set tensor descriptors using hybrid (W,H,C,N) + CUDNN_TENSOR_NCHW
    ! ========================================================================
    ! This approach is VALIDATED by standalone test (variance = 0.1175)!
    !
    ! Arrays are stored as (W,H,C,N) in Fortran column-major
    ! cuDNN interprets them with CUDNN_TENSOR_NCHW format as (N,C,H,W)
    ! Memory layout is equivalent - NO transpose needed!
    !
    ! This is the same approach Julia cuDNN.jl uses successfully.
    ! ========================================================================
    subroutine set_fortran_tensor_desc(desc, batch, channels, height, width)
        type(c_ptr), intent(in) :: desc
        integer, intent(in) :: batch, channels, height, width
        integer(c_int) :: stat

        ! V26 HYBRID APPROACH:
        ! - Fortran array is (W,H,C,N) = (width, height, channels, batch)
        ! - Tell cuDNN it's (N,C,H,W) with CUDNN_TENSOR_NCHW format
        ! - cuDNN computes correct column-major strides automatically!
        stat = cudnnSetTensor4dDescriptor(desc, &
                                          CUDNN_TENSOR_NCHW, &
                                          CUDNN_DATA_FLOAT, &
                                          int(batch, c_int), &
                                          int(channels, c_int), &
                                          int(height, c_int), &
                                          int(width, c_int))
        if (stat /= CUDNN_STATUS_SUCCESS) then
            print *, "‚ùå Failed to set tensor descriptor with CUDNN_TENSOR_NCHW:", stat
            stop
        endif
    end subroutine set_fortran_tensor_desc

    ! ========================================================================
    ! Transpose conv weights from Fortran (K,C,H,W) column-major to C row-major
    ! ========================================================================
    subroutine transpose_conv_weights_to_c_order(fortran_weights, c_weights, K, C, H, W)
        ! Convert Fortran column-major (K,C,H,W) to C row-major memory layout
        ! In Fortran: element at (k,c,h,w) stored at offset: k + K*c + K*C*h + K*C*H*w
        ! In C:       element at (k,c,h,w) stored at offset: w + W*h + W*H*c + W*H*C*k
        real(4), intent(in) :: fortran_weights(:,:,:,:)  ! Fortran (K,C,H,W)
        real(4), intent(out) :: c_weights(W, H, C, K)    ! Reversed dims for C-order
        integer, intent(in) :: K, C, H, W
        integer :: ik, ic, ih, iw

        ! Copy element-by-element, reversing dimension order
        do ik = 1, K
            do ic = 1, C
                do ih = 1, H
                    do iw = 1, W
                        ! Fortran's (k,c,h,w) maps to C's position by reversing indices
                        c_weights(iw, ih, ic, ik) = fortran_weights(ik, ic, ih, iw)
                    end do
                end do
            end do
        end do
    end subroutine transpose_conv_weights_to_c_order

    ! ========================================================================
    ! Create and initialize model
    ! ========================================================================
    subroutine create_model(model, batch_size)
        type(cnn_model), intent(out) :: model
        integer, intent(in) :: batch_size
        integer :: stat
        integer(c_size_t) :: dropout_bytes
        real(4), allocatable :: temp(:,:,:,:)
        real(4) :: std_dev
        integer :: i, j, k, l
        real(4), parameter :: eps = 1.0e-5  ! ‚úÖ FIXED: Match PyTorch default (was 1e-4)

        print *, "üîß Creating SVHN CNN model..."

        ! ========================================================================
        ! CRITICAL: Hybrid Memory Layout Strategy
        ! ========================================================================
        ! Host arrays (Fortran):  (W,H,C,N) - natural column-major layout
        ! Device arrays (cuDNN):  CUDNN_TENSOR_NCHW - native cuDNN format
        !
        ! This hybrid approach allows:
        ! - Fortran to use its efficient column-major storage
        ! - cuDNN to operate in its optimized NCHW format
        ! - Direct memory copy without runtime transposition
        !
        ! The set_fortran_tensor_desc() function configures descriptors
        ! with CUDNN_TENSOR_NCHW format - letting cuDNN handle interpretation
        ! ========================================================================

        ! Create tensor descriptors with native cuDNN format
        stat = cudnnCreateTensorDescriptor(model%input_desc)
        call set_fortran_tensor_desc(model%input_desc, batch_size, 3, 32, 32)

        ! Conv1 descriptors
        stat = cudnnCreateTensorDescriptor(model%conv1_desc)
        call set_fortran_tensor_desc(model%conv1_desc, batch_size, CONV1_FILTERS, 32, 32)

        stat = cudnnCreateFilterDescriptor(model%conv1_filter_desc)
        stat = cudnnSetFilter4dDescriptor(model%conv1_filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, &
                                         CONV1_FILTERS, 3, 3, 3)

        stat = cudnnCreateTensorDescriptor(model%conv1_bias_desc)
        stat = cudnnSetTensor4dDescriptor(model%conv1_bias_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, &
                                         1, CONV1_FILTERS, 1, 1)

        stat = cudnnCreateConvolutionDescriptor(model%conv1_conv_desc)
        stat = cudnnSetConvolution2dDescriptor(model%conv1_conv_desc, 1, 1, 1, 1, 1, 1, &
                                              CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT)

        ! BN1 descriptor - ‚úÖ V18 FIX: Use standard NCHW, NOT Fortran strides!
        ! BatchNorm with CUDNN_BATCHNORM_SPATIAL expects standard NCHW layout for param tensor
        stat = cudnnCreateTensorDescriptor(model%bn1_desc)
        stat = cudnnSetTensor4dDescriptor(model%bn1_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, &
                                         1, CONV1_FILTERS, 1, 1)

        ! Pool1 descriptors
        stat = cudnnCreateTensorDescriptor(model%pool1_desc)
        call set_fortran_tensor_desc(model%pool1_desc, batch_size, CONV1_FILTERS, 16, 16)

        ! Conv2 descriptors
        stat = cudnnCreateTensorDescriptor(model%conv2_desc)
        call set_fortran_tensor_desc(model%conv2_desc, batch_size, CONV2_FILTERS, 16, 16)

        stat = cudnnCreateFilterDescriptor(model%conv2_filter_desc)
        stat = cudnnSetFilter4dDescriptor(model%conv2_filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, &
                                         CONV2_FILTERS, CONV1_FILTERS, 3, 3)

        stat = cudnnCreateTensorDescriptor(model%conv2_bias_desc)
        stat = cudnnSetTensor4dDescriptor(model%conv2_bias_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, &
                                         1, CONV2_FILTERS, 1, 1)

        stat = cudnnCreateConvolutionDescriptor(model%conv2_conv_desc)
        stat = cudnnSetConvolution2dDescriptor(model%conv2_conv_desc, 1, 1, 1, 1, 1, 1, &
                                              CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT)

        ! BN2 descriptor - ‚úÖ V18 FIX: Use standard NCHW, NOT Fortran strides!
        stat = cudnnCreateTensorDescriptor(model%bn2_desc)
        stat = cudnnSetTensor4dDescriptor(model%bn2_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, &
                                         1, CONV2_FILTERS, 1, 1)

        ! Pool2 descriptors
        stat = cudnnCreateTensorDescriptor(model%pool2_desc)
        call set_fortran_tensor_desc(model%pool2_desc, batch_size, CONV2_FILTERS, 8, 8)

        ! Conv3 descriptors
        stat = cudnnCreateTensorDescriptor(model%conv3_desc)
        call set_fortran_tensor_desc(model%conv3_desc, batch_size, CONV3_FILTERS, 8, 8)

        stat = cudnnCreateFilterDescriptor(model%conv3_filter_desc)
        stat = cudnnSetFilter4dDescriptor(model%conv3_filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, &
                                         CONV3_FILTERS, CONV2_FILTERS, 3, 3)

        stat = cudnnCreateTensorDescriptor(model%conv3_bias_desc)
        stat = cudnnSetTensor4dDescriptor(model%conv3_bias_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, &
                                         1, CONV3_FILTERS, 1, 1)

        stat = cudnnCreateConvolutionDescriptor(model%conv3_conv_desc)
        stat = cudnnSetConvolution2dDescriptor(model%conv3_conv_desc, 1, 1, 1, 1, 1, 1, &
                                              CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT)

        ! BN3 descriptor - ‚úÖ V18 FIX: Use standard NCHW, NOT Fortran strides!
        stat = cudnnCreateTensorDescriptor(model%bn3_desc)
        stat = cudnnSetTensor4dDescriptor(model%bn3_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, &
                                         1, CONV3_FILTERS, 1, 1)

        ! Pool3 descriptors
        stat = cudnnCreateTensorDescriptor(model%pool3_desc)
        call set_fortran_tensor_desc(model%pool3_desc, batch_size, CONV3_FILTERS, 4, 4)

        ! Pooling descriptor (shared for all pooling layers)
        stat = cudnnCreatePoolingDescriptor(model%pooling_desc)
        stat = cudnnSetPooling2dDescriptor(model%pooling_desc, CUDNN_POOLING_MAX, CUDNN_PROPAGATE_NAN, &
                                          2, 2, 0, 0, 2, 2)

        ! Activation descriptor (shared for all ReLU layers)
        stat = cudnnCreateActivationDescriptor(model%activation_desc)
        ! ‚úÖ LeakyReLU(0.01) to match Python reference implementation
        ! When using CUDNN_ACTIVATION_RELU with coef=0.01:
        ! f(x) = max(0.01*x, x) - this is LeakyReLU with negative slope 0.01
        ! Python reference achieves 70-80% accuracy with LeakyReLU(0.01)
        stat = cudnnSetActivationDescriptor(model%activation_desc, CUDNN_ACTIVATION_RELU, CUDNN_PROPAGATE_NAN, 0.01d0)

        ! FC1 descriptor (batch, 512, 1, 1)
        stat = cudnnCreateTensorDescriptor(model%fc1_desc)
        call set_fortran_tensor_desc(model%fc1_desc, batch_size, 512, 1, 1)

        ! FC2 descriptor (batch, 256, 1, 1)
        stat = cudnnCreateTensorDescriptor(model%fc2_desc)
        call set_fortran_tensor_desc(model%fc2_desc, batch_size, 256, 1, 1)

        ! FC3 descriptor (batch, 10, 1, 1)
        stat = cudnnCreateTensorDescriptor(model%fc3_desc)
        call set_fortran_tensor_desc(model%fc3_desc, batch_size, CNN_NUM_CLASSES, 1, 1)

        stat = cudnnCreateTensorDescriptor(model%output_desc)
        call set_fortran_tensor_desc(model%output_desc, batch_size, CNN_NUM_CLASSES, 1, 1)

        ! Allocate layer outputs - V26: (W,H,C,N) layout
        allocate(model%input(32, 32, 3, batch_size))                      ! (32,32,3,N)
        allocate(model%conv1_out(32, 32, CONV1_FILTERS, batch_size))      ! (32,32,32,N)
        allocate(model%bn1_out(32, 32, CONV1_FILTERS, batch_size))        ! (32,32,32,N)
        allocate(model%relu1_out(32, 32, CONV1_FILTERS, batch_size))      ! (32,32,32,N)
        allocate(model%pool1_out(16, 16, CONV1_FILTERS, batch_size))      ! (16,16,32,N)
        allocate(model%conv2_out(16, 16, CONV2_FILTERS, batch_size))      ! (16,16,64,N)
        allocate(model%bn2_out(16, 16, CONV2_FILTERS, batch_size))        ! (16,16,64,N)
        allocate(model%relu2_out(16, 16, CONV2_FILTERS, batch_size))      ! (16,16,64,N)
        allocate(model%pool2_out(8, 8, CONV2_FILTERS, batch_size))        ! (8,8,64,N)
        allocate(model%conv3_out(8, 8, CONV3_FILTERS, batch_size))        ! (8,8,128,N)
        allocate(model%bn3_out(8, 8, CONV3_FILTERS, batch_size))          ! (8,8,128,N)
        allocate(model%relu3_out(8, 8, CONV3_FILTERS, batch_size))        ! (8,8,128,N)
        allocate(model%pool3_out(4, 4, CONV3_FILTERS, batch_size))       ! (4,4,128,N)
        allocate(model%flatten(batch_size, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        allocate(model%fc1_out(batch_size, 512))
        allocate(model%fc1_relu(batch_size, 512))
        allocate(model%fc1_dropout(batch_size, 512))
        allocate(model%fc2_out(batch_size, 256))
        allocate(model%fc2_relu(batch_size, 256))
        allocate(model%fc2_dropout(batch_size, 256))
        allocate(model%fc3_out(batch_size, CNN_NUM_CLASSES))
        allocate(model%softmax_out(batch_size, CNN_NUM_CLASSES))

        ! Allocate weights and biases
        allocate(model%conv1_weights(CONV1_FILTERS, 3, 3, 3))
        allocate(model%conv1_bias(CONV1_FILTERS))
        allocate(model%conv2_weights(CONV2_FILTERS, CONV1_FILTERS, 3, 3))
        allocate(model%conv2_bias(CONV2_FILTERS))
        allocate(model%conv3_weights(CONV3_FILTERS, CONV2_FILTERS, 3, 3))
        allocate(model%conv3_bias(CONV3_FILTERS))

        allocate(model%fc1_weights(512, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        allocate(model%fc1_bias(512))
        allocate(model%fc2_weights(256, 512))
        allocate(model%fc2_bias(256))
        allocate(model%fc3_weights(CNN_NUM_CLASSES, 256))
        allocate(model%fc3_bias(CNN_NUM_CLASSES))

        ! ========================================================================
        ! CRITICAL: Batch Normalization Parameter Layout
        ! ========================================================================
        ! BN parameters are 1D arrays of size (num_channels)
        ! When passed to cuDNN, they're interpreted as (1, C, 1, 1) for SPATIAL mode
        ! This shape MUST match the channel dimension of the NCHW tensor descriptor
        !
        ! WRONG approaches that failed in V16-V25:
        ! - Shape (C) passed as 4D (1,1,C,1) - caused gradient explosions
        ! - Custom strides on BN descriptors - caused NaN values
        !
        ! CORRECT approach (V26):
        ! - Allocate as 1D (C) in Fortran
        ! - cuDNN interprets as (1,C,1,1) for CUDNN_BATCHNORM_SPATIAL
        ! - Matches channel dimension perfectly
        ! ========================================================================
        allocate(model%bn1_scale(CONV1_FILTERS))
        allocate(model%bn1_bias(CONV1_FILTERS))
        allocate(model%bn1_running_mean(CONV1_FILTERS))
        allocate(model%bn1_running_var(CONV1_FILTERS))
        allocate(model%bn1_saved_mean(CONV1_FILTERS))
        allocate(model%bn1_saved_inv_var(CONV1_FILTERS))

        allocate(model%bn2_scale(CONV2_FILTERS))
        allocate(model%bn2_bias(CONV2_FILTERS))
        allocate(model%bn2_running_mean(CONV2_FILTERS))
        allocate(model%bn2_running_var(CONV2_FILTERS))
        allocate(model%bn2_saved_mean(CONV2_FILTERS))
        allocate(model%bn2_saved_inv_var(CONV2_FILTERS))

        allocate(model%bn3_scale(CONV3_FILTERS))
        allocate(model%bn3_bias(CONV3_FILTERS))
        allocate(model%bn3_running_mean(CONV3_FILTERS))
        allocate(model%bn3_running_var(CONV3_FILTERS))
        allocate(model%bn3_saved_mean(CONV3_FILTERS))
        allocate(model%bn3_saved_inv_var(CONV3_FILTERS))

        ! ‚úÖ Use v5's proven Box-Muller weight initialization (works: 32-43% accuracy)
        ! Conv layers: He initialization, std = sqrt(2 / fan_in)
        ! FC layers: Xavier initialization, std = sqrt(2 / (fan_in + fan_out))
        block
            real(4), allocatable :: host_weights_conv1(:,:,:,:), host_bias_conv1(:)
            real(4), allocatable :: host_weights_conv2(:,:,:,:), host_bias_conv2(:)
            real(4), allocatable :: host_weights_conv3(:,:,:,:), host_bias_conv3(:)
            real(4), allocatable :: host_weights_fc1(:,:), host_weights_fc2(:,:), host_weights_fc3(:,:)
            real(4) :: std_dev
            integer :: stat

            print *, ""
            print *, "üé≤ Using cuRAND for weight initialization (seed=42)"
            print *, ""

            ! Conv1: fan_in = 3*3*3 = 27, std = sqrt(2/27) ‚âà 0.272
            ! ‚úÖ V18: Use cuRAND for proper Gaussian generation
            std_dev = sqrt(2.0 / (3 * 3 * 3))
            allocate(host_weights_conv1(CONV1_FILTERS, 3, 3, 3))
            allocate(host_bias_conv1(CONV1_FILTERS))

            ! Generate Gaussian random numbers directly on GPU, then copy to host for diagnostics
            block
                real(4), device, allocatable :: temp_device(:)
                real(4), allocatable :: temp_host(:)
                integer :: total_weights
                total_weights = CONV1_FILTERS * 3 * 3 * 3
                allocate(temp_device(total_weights))
                allocate(temp_host(total_weights))

                ! cuRAND generates directly into device memory with proper Gaussian distribution
                call generate_random_array_normal_single(temp_device, total_weights, 0.0, std_dev)

                ! Copy from device to host, then reshape
                temp_host = temp_device
                host_weights_conv1 = reshape(temp_host, [CONV1_FILTERS, 3, 3, 3])
                deallocate(temp_device, temp_host)
            end block
            host_bias_conv1 = 0.0

            ! üîç DEBUG: Check weights BEFORE transposition
            block
                real(4) :: before_mean, before_std, before_sum, before_sum_sq
                integer :: total_weights
                total_weights = CONV1_FILTERS * 3 * 3 * 3
                before_sum = sum(host_weights_conv1)
                before_mean = before_sum / total_weights
                before_sum_sq = sum((host_weights_conv1 - before_mean)**2)
                before_std = sqrt(before_sum_sq / total_weights)
                print *, "üîç Conv1 (cuRAND): mean=", before_mean, " std=", before_std
                print *, "   First 5 weights:", host_weights_conv1(1, 1, 1, 1:min(5,3))
                print *, "   Expected: mean‚âà0.0, std‚âà", sqrt(2.0/27.0)
            end block

            ! üîß V18: Transpose from Fortran (K,C,H,W) to C-order for cuDNN
            block
                real(4), allocatable :: temp_c_order(:,:,:,:)
                allocate(temp_c_order(3, 3, 3, CONV1_FILTERS))  ! (W,H,C,K) for C-order
                call transpose_conv_weights_to_c_order(host_weights_conv1, temp_c_order, CONV1_FILTERS, 3, 3, 3)
                model%conv1_weights = reshape(temp_c_order, [CONV1_FILTERS, 3, 3, 3])
                deallocate(temp_c_order)
            end block
            model%conv1_bias = host_bias_conv1
            print *, "‚úÖ Conv1 weights transposed to C-order for cuDNN"

            ! üîç DEBUG: Check weights AFTER transposition
            block
                real(4) :: after_mean, after_std, after_sum, after_sum_sq
                real(4), allocatable :: host_check(:,:,:,:)
                integer :: total_weights
                allocate(host_check(CONV1_FILTERS, 3, 3, 3))
                host_check = model%conv1_weights
                total_weights = CONV1_FILTERS * 3 * 3 * 3
                after_sum = sum(host_check)
                after_mean = after_sum / total_weights
                after_sum_sq = sum((host_check - after_mean)**2)
                after_std = sqrt(after_sum_sq / total_weights)
                print *, "üîç Conv1 AFTER transpose:  mean=", after_mean, " std=", after_std
                print *, "   First 5 weights:", host_check(1, 1, 1, 1:min(5,3))
                deallocate(host_check)
            end block

            deallocate(host_weights_conv1, host_bias_conv1)

            ! Conv2: fan_in = 32*3*3 = 288, std = sqrt(2/288) ‚âà 0.083
            std_dev = sqrt(2.0 / (CONV1_FILTERS * 3 * 3))
            allocate(host_weights_conv2(CONV2_FILTERS, CONV1_FILTERS, 3, 3))
            allocate(host_bias_conv2(CONV2_FILTERS))
            block
                real(4), device, allocatable :: temp_device(:)
                real(4), allocatable :: temp_host(:)
                integer :: total_weights
                total_weights = CONV2_FILTERS * CONV1_FILTERS * 3 * 3
                allocate(temp_device(total_weights))
                allocate(temp_host(total_weights))
                call generate_random_array_normal_single(temp_device, total_weights, 0.0, std_dev)
                temp_host = temp_device
                host_weights_conv2 = reshape(temp_host, [CONV2_FILTERS, CONV1_FILTERS, 3, 3])
                deallocate(temp_device, temp_host)
            end block
            host_bias_conv2 = 0.0

            ! Transpose Conv2 to C-order
            block
                real(4), allocatable :: temp_c_order(:,:,:,:)
                allocate(temp_c_order(3, 3, CONV1_FILTERS, CONV2_FILTERS))
                call transpose_conv_weights_to_c_order(host_weights_conv2, temp_c_order, CONV2_FILTERS, CONV1_FILTERS, 3, 3)
                model%conv2_weights = reshape(temp_c_order, [CONV2_FILTERS, CONV1_FILTERS, 3, 3])
                deallocate(temp_c_order)
            end block
            model%conv2_bias = host_bias_conv2
            deallocate(host_weights_conv2, host_bias_conv2)

            ! Conv3: fan_in = 64*3*3 = 576, std = sqrt(2/576) ‚âà 0.059
            std_dev = sqrt(2.0 / (CONV2_FILTERS * 3 * 3))
            allocate(host_weights_conv3(CONV3_FILTERS, CONV2_FILTERS, 3, 3))
            allocate(host_bias_conv3(CONV3_FILTERS))
            block
                real(4), device, allocatable :: temp_device(:)
                real(4), allocatable :: temp_host(:)
                integer :: total_weights
                total_weights = CONV3_FILTERS * CONV2_FILTERS * 3 * 3
                allocate(temp_device(total_weights))
                allocate(temp_host(total_weights))
                call generate_random_array_normal_single(temp_device, total_weights, 0.0, std_dev)
                temp_host = temp_device
                host_weights_conv3 = reshape(temp_host, [CONV3_FILTERS, CONV2_FILTERS, 3, 3])
                deallocate(temp_device, temp_host)
            end block
            host_bias_conv3 = 0.0

            ! Transpose Conv3 to C-order
            block
                real(4), allocatable :: temp_c_order(:,:,:,:)
                allocate(temp_c_order(3, 3, CONV2_FILTERS, CONV3_FILTERS))
                call transpose_conv_weights_to_c_order(host_weights_conv3, temp_c_order, CONV3_FILTERS, CONV2_FILTERS, 3, 3)
                model%conv3_weights = reshape(temp_c_order, [CONV3_FILTERS, CONV2_FILTERS, 3, 3])
                deallocate(temp_c_order)
            end block
            model%conv3_bias = host_bias_conv3
            deallocate(host_weights_conv3, host_bias_conv3)

            ! FC1: Xavier initialization, std = sqrt(2 / (2048 + 512))
            std_dev = sqrt(2.0 / real(CONV3_FILTERS*4*4 + 512))
            allocate(host_weights_fc1(512, CONV3_FILTERS*4*4))
            block
                real(4), device, allocatable :: temp_device(:)
                real(4), allocatable :: temp_host(:)
                integer :: total_weights
                total_weights = 512 * CONV3_FILTERS*4*4
                allocate(temp_device(total_weights))
                allocate(temp_host(total_weights))
                call generate_random_array_normal_single(temp_device, total_weights, 0.0, std_dev)
                temp_host = temp_device
                host_weights_fc1 = reshape(temp_host, [512, CONV3_FILTERS*4*4])
                deallocate(temp_device, temp_host)
            end block
            model%fc1_weights = host_weights_fc1
            model%fc1_bias = 0.0
            deallocate(host_weights_fc1)

            ! FC2: Xavier initialization, std = sqrt(2 / (512 + 256))
            std_dev = sqrt(2.0 / real(512 + 256))
            allocate(host_weights_fc2(256, 512))
            block
                real(4), device, allocatable :: temp_device(:)
                real(4), allocatable :: temp_host(:)
                integer :: total_weights
                total_weights = 256 * 512
                allocate(temp_device(total_weights))
                allocate(temp_host(total_weights))
                call generate_random_array_normal_single(temp_device, total_weights, 0.0, std_dev)
                temp_host = temp_device
                host_weights_fc2 = reshape(temp_host, [256, 512])
                deallocate(temp_device, temp_host)
            end block
            model%fc2_weights = host_weights_fc2
            model%fc2_bias = 0.0
            deallocate(host_weights_fc2)

            ! FC3: Xavier initialization, std = sqrt(2 / (256 + 10))
            std_dev = sqrt(2.0 / real(256 + 10))
            allocate(host_weights_fc3(10, 256))
            block
                real(4), device, allocatable :: temp_device(:)
                real(4), allocatable :: temp_host(:)
                integer :: total_weights
                total_weights = 10 * 256
                allocate(temp_device(total_weights))
                allocate(temp_host(total_weights))
                call generate_random_array_normal_single(temp_device, total_weights, 0.0, std_dev)
                temp_host = temp_device
                host_weights_fc3 = reshape(temp_host, [10, 256])
                deallocate(temp_device, temp_host)
            end block
            model%fc3_weights = host_weights_fc3
            model%fc3_bias = 0.0
            deallocate(host_weights_fc3)
        end block

        ! Add after FC weight initialization
        ! üîç DIAGNOSTIC: Check Conv1 filter weights for outliers
        block
            real(4) :: filter_mean, filter_std, filter_min, filter_max, filter_sum_sq
            integer :: filter_idx, total_weights

            print *, ""
            print *, "üîç Conv1 Weight Initialization Diagnostics:"

            ! Check filters 1, 13, 21, 30 (known variance outliers)
            do filter_idx = 1, min(5, CONV1_FILTERS)
                total_weights = 3 * 3 * 3
                filter_mean = sum(model%conv1_weights(filter_idx, :, :, :)) / total_weights
                filter_min = minval(model%conv1_weights(filter_idx, :, :, :))
                filter_max = maxval(model%conv1_weights(filter_idx, :, :, :))

                ! Compute std
                filter_sum_sq = sum((model%conv1_weights(filter_idx, :, :, :) - filter_mean)**2)
                filter_std = sqrt(filter_sum_sq / total_weights)

                print '(A,I2,A,F7.4,A,F7.4,A,F7.4,A,F7.4)', &
                    "   Filter ", filter_idx, ": mean=", filter_mean, &
                    " std=", filter_std, " min=", filter_min, " max=", filter_max
            end do

            ! Check specific outlier filters
            do filter_idx = 13, 13
                total_weights = 3 * 3 * 3
                filter_mean = sum(model%conv1_weights(filter_idx, :, :, :)) / total_weights
                filter_min = minval(model%conv1_weights(filter_idx, :, :, :))
                filter_max = maxval(model%conv1_weights(filter_idx, :, :, :))
                filter_sum_sq = sum((model%conv1_weights(filter_idx, :, :, :) - filter_mean)**2)
                filter_std = sqrt(filter_sum_sq / total_weights)

                print '(A,I2,A,F7.4,A,F7.4,A,F7.4,A,F7.4)', &
                    "   Filter ", filter_idx, " (OUTLIER ch13): mean=", filter_mean, &
                    " std=", filter_std, " min=", filter_min, " max=", filter_max
            end do

            print '(A,F7.4)', "   Expected std (He init): ", sqrt(2.0/27.0)
            print *, ""
        end block

        ! üîç DIAGNOSTIC: Check FC1 weight initialization
        block
            real(4) :: fc1_mean, fc1_std, fc1_min, fc1_max, fc1_sum, fc1_sum_sq
            real(4), allocatable :: fc1_host(:,:), fc1_sample(:)
            integer :: total_fc1_weights, i

            print *, "üîç FC1 Weight Initialization Diagnostics:"
            total_fc1_weights = 512 * CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)

            ! Copy FC1 weights to host for statistics
            allocate(fc1_host(512, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
            allocate(fc1_sample(10))
            fc1_host = model%fc1_weights
            fc1_sample = model%fc1_weights(1, 1:10)

            ! Compute statistics on host
            fc1_sum = sum(fc1_host)
            fc1_mean = fc1_sum / total_fc1_weights
            fc1_min = minval(fc1_host)
            fc1_max = maxval(fc1_host)
            fc1_sum_sq = sum((fc1_host - fc1_mean)**2)
            fc1_std = sqrt(fc1_sum_sq / total_fc1_weights)

            print '(A,F9.6)', "   FC1 weights: mean = ", fc1_mean
            print '(A,F9.6)', "   FC1 weights: std  = ", fc1_std
            print '(A,F9.6)', "   FC1 weights: min  = ", fc1_min
            print '(A,F9.6)', "   FC1 weights: max  = ", fc1_max
            print '(A,F9.6)', "   Expected std (Xavier): ", sqrt(2.0 / real(CONV3_FILTERS*4*4 + 512))
            print *, "   First 10 FC1 weights[1,1:10]:"
            print '(10F10.6)', (fc1_sample(i), i=1, 10)
            print *, ""

            deallocate(fc1_host, fc1_sample)
        end block

        ! Initialize batch norm parameters
        model%bn1_scale = 1.0
        model%bn1_bias = 0.0
        model%bn1_running_mean = 0.0
        model%bn1_running_var = 1.0  ! ‚úÖ FIXED: PyTorch initializes to 1.0, NOT 1.0+eps

        model%bn2_scale = 1.0
        model%bn2_bias = 0.0
        model%bn2_running_mean = 0.0
        model%bn2_running_var = 1.0  ! ‚úÖ FIXED: PyTorch initializes to 1.0, NOT 1.0+eps

        model%bn3_scale = 1.0
        model%bn3_bias = 0.0
        model%bn3_running_mean = 0.0
        model%bn3_running_var = 1.0  ! ‚úÖ FIXED: PyTorch initializes to 1.0, NOT 1.0+eps

        ! Allocate gradients - V26: (W,H,C,N) layout
        allocate(model%grad_input(32, 32, 3, batch_size))                 ! (32,32,3,N)
        allocate(model%grad_conv1(32, 32, CONV1_FILTERS, batch_size))     ! (32,32,32,N)
        allocate(model%grad_bn1(32, 32, CONV1_FILTERS, batch_size))       ! (32,32,32,N)
        allocate(model%grad_relu1(32, 32, CONV1_FILTERS, batch_size))     ! (32,32,32,N)
        allocate(model%grad_pool1(16, 16, CONV1_FILTERS, batch_size))     ! (16,16,32,N)
        allocate(model%grad_conv2(16, 16, CONV2_FILTERS, batch_size))     ! (16,16,64,N)
        allocate(model%grad_bn2(16, 16, CONV2_FILTERS, batch_size))       ! (16,16,64,N)
        allocate(model%grad_relu2(16, 16, CONV2_FILTERS, batch_size))     ! (16,16,64,N)
        allocate(model%grad_pool2(8, 8, CONV2_FILTERS, batch_size))       ! (8,8,64,N)
        allocate(model%grad_conv3(8, 8, CONV3_FILTERS, batch_size))       ! (8,8,128,N)
        allocate(model%grad_bn3(8, 8, CONV3_FILTERS, batch_size))         ! (8,8,128,N)
        allocate(model%grad_relu3(8, 8, CONV3_FILTERS, batch_size))       ! (8,8,128,N)
        allocate(model%grad_pool3(4, 4, CONV3_FILTERS, batch_size))       ! (4,4,128,N)
        allocate(model%grad_fc1(batch_size, 512))
        allocate(model%grad_fc2(batch_size, 256))
        allocate(model%grad_fc3(batch_size, CNN_NUM_CLASSES))

        allocate(model%grad_conv1_weights(CONV1_FILTERS, 3, 3, 3))
        allocate(model%grad_conv1_bias(CONV1_FILTERS))
        allocate(model%grad_conv2_weights(CONV2_FILTERS, CONV1_FILTERS, 3, 3))
        allocate(model%grad_conv2_bias(CONV2_FILTERS))
        allocate(model%grad_conv3_weights(CONV3_FILTERS, CONV2_FILTERS, 3, 3))
        allocate(model%grad_conv3_bias(CONV3_FILTERS))
        allocate(model%grad_fc1_weights(512, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        allocate(model%grad_fc1_bias(512))
        allocate(model%grad_fc2_weights(256, 512))
        allocate(model%grad_fc2_bias(256))
        allocate(model%grad_fc3_weights(CNN_NUM_CLASSES, 256))
        allocate(model%grad_fc3_bias(CNN_NUM_CLASSES))
        allocate(model%grad_bn1_scale(CONV1_FILTERS))
        allocate(model%grad_bn1_bias(CONV1_FILTERS))
        allocate(model%grad_bn2_scale(CONV2_FILTERS))
        allocate(model%grad_bn2_bias(CONV2_FILTERS))
        allocate(model%grad_bn3_scale(CONV3_FILTERS))
        allocate(model%grad_bn3_bias(CONV3_FILTERS))

        ! ========================================================================
        ! NOTE: FC WEIGHTS already allocated at lines 1617-1622
        ! DO NOT REALLOCATE - would destroy Box-Muller initialization!
        ! ========================================================================

        ! ========================================================================
        ! ‚úÖ ALLOCATE FC OUTPUTS (with intermediate states)
        ! ========================================================================
        allocate(model%flatten(batch_size, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        allocate(model%fc1_out(batch_size, 512))
        allocate(model%fc1_relu(batch_size, 512))         ! ‚úÖ NEW
        allocate(model%fc1_dropout(batch_size, 512))      ! ‚úÖ NEW
        allocate(model%fc2_out(batch_size, 256))
        allocate(model%fc2_relu(batch_size, 256))         ! ‚úÖ NEW
        allocate(model%fc2_dropout(batch_size, 256))      ! ‚úÖ NEW
        allocate(model%fc3_out(batch_size, CNN_NUM_CLASSES))  ! ‚úÖ NEW
        allocate(model%softmax_out(batch_size, CNN_NUM_CLASSES))

        ! ========================================================================
        ! ‚úÖ ALLOCATE FC GRADIENTS (3 layers)
        ! ========================================================================
        allocate(model%grad_fc1_weights(512, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        allocate(model%grad_fc1_bias(512))
        allocate(model%grad_fc2_weights(256, 512))
        allocate(model%grad_fc2_bias(256))
        allocate(model%grad_fc3_weights(CNN_NUM_CLASSES, 256))  ! ‚úÖ NEW
        allocate(model%grad_fc3_bias(CNN_NUM_CLASSES))          ! ‚úÖ NEW


        ! Allocate FC gradient intermediate states
        allocate(model%grad_fc1(batch_size, 512))
        allocate(model%grad_fc1_dropout(batch_size, 512))
        allocate(model%grad_fc1_relu(batch_size, 512))
        allocate(model%grad_fc2(batch_size, 256))
        allocate(model%grad_fc2_dropout(batch_size, 256))
        allocate(model%grad_fc2_relu(batch_size, 256))
        allocate(model%grad_fc3(batch_size, CNN_NUM_CLASSES))

        ! ========================================================================
        ! ALLOCATE ADAM OPTIMIZER STATE
        ! ========================================================================
        !print *, "üîß Initializing Adam optimizer state..."

        ! Conv layers - first moments
        allocate(model%m_conv1_weights(CONV1_FILTERS, 3, 3, 3))
        allocate(model%m_conv1_bias(CONV1_FILTERS))
        allocate(model%m_conv2_weights(CONV2_FILTERS, CONV1_FILTERS, 3, 3))
        allocate(model%m_conv2_bias(CONV2_FILTERS))
        allocate(model%m_conv3_weights(CONV3_FILTERS, CONV2_FILTERS, 3, 3))
        allocate(model%m_conv3_bias(CONV3_FILTERS))

        ! Conv layers - second moments
        allocate(model%v_conv1_weights(CONV1_FILTERS, 3, 3, 3))
        allocate(model%v_conv1_bias(CONV1_FILTERS))
        allocate(model%v_conv2_weights(CONV2_FILTERS, CONV1_FILTERS, 3, 3))
        allocate(model%v_conv2_bias(CONV2_FILTERS))
        allocate(model%v_conv3_weights(CONV3_FILTERS, CONV2_FILTERS, 3, 3))
        allocate(model%v_conv3_bias(CONV3_FILTERS))

        ! FC layers - first moments
        allocate(model%m_fc1_weights(512, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        allocate(model%m_fc1_bias(512))
        allocate(model%m_fc2_weights(256, 512))
        allocate(model%m_fc2_bias(256))
        allocate(model%m_fc3_weights(CNN_NUM_CLASSES, 256))
        allocate(model%m_fc3_bias(CNN_NUM_CLASSES))

        ! FC layers - second moments
        allocate(model%v_fc1_weights(512, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        allocate(model%v_fc1_bias(512))
        allocate(model%v_fc2_weights(256, 512))
        allocate(model%v_fc2_bias(256))
        allocate(model%v_fc3_weights(CNN_NUM_CLASSES, 256))
        allocate(model%v_fc3_bias(CNN_NUM_CLASSES))

        ! Batch norm - first moments
        allocate(model%m_bn1_scale(CONV1_FILTERS))
        allocate(model%m_bn1_bias(CONV1_FILTERS))
        allocate(model%m_bn2_scale(CONV2_FILTERS))
        allocate(model%m_bn2_bias(CONV2_FILTERS))
        allocate(model%m_bn3_scale(CONV3_FILTERS))
        allocate(model%m_bn3_bias(CONV3_FILTERS))

        ! Batch norm - second moments
        allocate(model%v_bn1_scale(CONV1_FILTERS))
        allocate(model%v_bn1_bias(CONV1_FILTERS))
        allocate(model%v_bn2_scale(CONV2_FILTERS))
        allocate(model%v_bn2_bias(CONV2_FILTERS))
        allocate(model%v_bn3_scale(CONV3_FILTERS))
        allocate(model%v_bn3_bias(CONV3_FILTERS))

        ! Initialize all moments to zero
        model%m_conv1_weights = 0.0; model%v_conv1_weights = 0.0
        model%m_conv1_bias = 0.0; model%v_conv1_bias = 0.0
        model%m_conv2_weights = 0.0; model%v_conv2_weights = 0.0
        model%m_conv2_bias = 0.0; model%v_conv2_bias = 0.0
        model%m_conv3_weights = 0.0; model%v_conv3_weights = 0.0
        model%m_conv3_bias = 0.0; model%v_conv3_bias = 0.0
        model%m_fc1_weights = 0.0; model%v_fc1_weights = 0.0
        model%m_fc1_bias = 0.0; model%v_fc1_bias = 0.0
        model%m_fc2_weights = 0.0; model%v_fc2_weights = 0.0
        model%m_fc2_bias = 0.0; model%v_fc2_bias = 0.0
        model%m_fc3_weights = 0.0; model%v_fc3_weights = 0.0
        model%m_fc3_bias = 0.0; model%v_fc3_bias = 0.0
        model%m_bn1_scale = 0.0; model%v_bn1_scale = 0.0
        model%m_bn1_bias = 0.0; model%v_bn1_bias = 0.0
        model%m_bn2_scale = 0.0; model%v_bn2_scale = 0.0
        model%m_bn2_bias = 0.0; model%v_bn2_bias = 0.0
        model%m_bn3_scale = 0.0; model%v_bn3_scale = 0.0
        model%m_bn3_bias = 0.0; model%v_bn3_bias = 0.0

        model%adam_timestep = 0

        !print *, "‚úÖ Adam optimizer initialized"

        ! ========================================================================
        ! NOTE: FC weights already initialized with Box-Muller at lines 1759-1817
        ! ========================================================================

        ! ========================================================================
        ! ‚úÖ SETUP DROPOUT (cuDNN requires dropout descriptor and state)
        ! ========================================================================
        ! Create dropout descriptor
        stat = cudnnCreateDropoutDescriptor(model%dropout_desc)
        if (stat /= CUDNN_STATUS_SUCCESS) then
            print *, "‚ùå Failed to create dropout descriptor:", stat
            return
        endif

        ! Get dropout state size
        stat = cudnnDropoutGetStatesSize(cudnn_handle, dropout_bytes)
        if (stat /= CUDNN_STATUS_SUCCESS) then
            print *, "‚ùå Failed to get dropout state size:", stat
            return
        endif

        model%dropout_state_size = dropout_bytes

        ! Allocate dropout states
        allocate(model%dropout_states(int(dropout_bytes / 4)))  ! Size in float32

        ! Initialize dropout descriptor (dropout rate = 0.5, seed = 1234)
        stat = cudnnSetDropoutDescriptor(model%dropout_desc, cudnn_handle, &
                0.5, c_loc(model%dropout_states), dropout_bytes, 1234_8)
        if (stat /= CUDNN_STATUS_SUCCESS) then
            print *, "‚ùå Failed to set dropout descriptor:", stat
            return
        endif

        ! Get reserve space size for FC1 dropout (batch_size, 512, 1, 1)
        stat = cudnnDropoutGetReserveSpaceSize(model%fc1_desc, model%fc1_reserve_size)
        if (stat /= CUDNN_STATUS_SUCCESS) then
            print *, "‚ùå Failed to get FC1 reserve space size:", stat
            return
        endif

        ! Get reserve space size for FC2 dropout (batch_size, 256, 1, 1)
        stat = cudnnDropoutGetReserveSpaceSize(model%fc2_desc, model%fc2_reserve_size)
        if (stat /= CUDNN_STATUS_SUCCESS) then
            print *, "‚ùå Failed to get FC2 reserve space size:", stat
            return
        endif

        ! Allocate reserve space buffers
        allocate(model%fc1_dropout_reserve(int(model%fc1_reserve_size / 4)))
        allocate(model%fc2_dropout_reserve(int(model%fc2_reserve_size / 4)))

        print *, "‚úÖ Dropout initialized: rate=0.5, FC1_reserve=", model%fc1_reserve_size, &
                 "bytes, FC2_reserve=", model%fc2_reserve_size, "bytes"

        ! Allocate workspace (64MB should be enough)
        model%workspace_size = 64 * 1024 * 1024
        allocate(model%workspace(model%workspace_size / 4))

        !print *, "‚úÖ Model created and initialized"
    end subroutine create_model

    subroutine clip_gradients(model, max_norm)
        type(cnn_model), intent(inout) :: model
        real(4), intent(in) :: max_norm
        real(4), device :: total_norm_device
        real(4) :: total_norm_host, clip_coef

        ! Initialize device variable
        total_norm_device = 0.0

        ! Compute squared norm on GPU using reduction kernels
        call compute_gradient_norm_squared(model, total_norm_device)

        ! Copy result to host and compute sqrt
        total_norm_host = sqrt(total_norm_device)

        ! Only clip if norm exceeds threshold
        if (total_norm_host > max_norm) then
            clip_coef = max_norm / (total_norm_host + 1e-6)
            print *, "‚ö†Ô∏è  Clipping gradients: norm =", total_norm_host, "‚Üí", max_norm

            ! Scale all gradients on GPU uniformly (this is correct for clipping)
            call scale_all_gradients_uniform(model, clip_coef)
        endif
    end subroutine clip_gradients

    ! New function: scales all gradients by the same factor (for clipping only)
    subroutine scale_all_gradients_uniform(model, scale)
        type(cnn_model), intent(inout) :: model
        real(4), intent(in) :: scale
        integer :: i, j, k, l

        ! Scale Conv1 gradients
        associate(grad => model%grad_conv1_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            grad(i,j,k,l) = grad(i,j,k,l) * scale
                        end do
                    end do
                end do
            end do
        end associate

        associate(grad => model%grad_conv1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale Conv2 gradients
        associate(grad => model%grad_conv2_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            grad(i,j,k,l) = grad(i,j,k,l) * scale
                        end do
                    end do
                end do
            end do
        end associate

        associate(grad => model%grad_conv2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale Conv3 gradients
        associate(grad => model%grad_conv3_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            grad(i,j,k,l) = grad(i,j,k,l) * scale
                        end do
                    end do
                end do
            end do
        end associate

        associate(grad => model%grad_conv3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale FC1 gradients
        associate(grad => model%grad_fc1_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    grad(i,j) = grad(i,j) * scale
                end do
            end do
        end associate

        associate(grad => model%grad_fc1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale FC2 gradients
        associate(grad => model%grad_fc2_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    grad(i,j) = grad(i,j) * scale
                end do
            end do
        end associate

        associate(grad => model%grad_fc2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale FC3 gradients
        associate(grad => model%grad_fc3_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    grad(i,j) = grad(i,j) * scale
                end do
            end do
        end associate

        associate(grad => model%grad_fc3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale BatchNorm gradients
        associate(grad => model%grad_bn1_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn2_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn3_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate
    end subroutine scale_all_gradients_uniform

    ! Compute gradient norm squared (all on GPU)
    subroutine compute_gradient_norm_squared(model, norm_sq)
        type(cnn_model), intent(in) :: model
        real(4), device, intent(inout) :: norm_sq
        integer :: i, j, k, l

        ! Conv1 weights contribution
        associate(grad => model%grad_conv1_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            norm_sq = norm_sq + grad(i,j,k,l)**2
                        end do
                    end do
                end do
            end do
        end associate

        ! Conv1 bias contribution
        associate(grad => model%grad_conv1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        ! Conv2 weights contribution
        associate(grad => model%grad_conv2_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            norm_sq = norm_sq + grad(i,j,k,l)**2
                        end do
                    end do
                end do
            end do
        end associate

        ! Conv2 bias contribution
        associate(grad => model%grad_conv2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        ! Conv3 weights contribution
        associate(grad => model%grad_conv3_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            norm_sq = norm_sq + grad(i,j,k,l)**2
                        end do
                    end do
                end do
            end do
        end associate

        ! Conv3 bias contribution
        associate(grad => model%grad_conv3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        ! FC1 weights contribution
        associate(grad => model%grad_fc1_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    norm_sq = norm_sq + grad(i,j)**2
                end do
            end do
        end associate

        ! FC1 bias contribution
        associate(grad => model%grad_fc1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        ! FC2 weights contribution
        associate(grad => model%grad_fc2_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    norm_sq = norm_sq + grad(i,j)**2
                end do
            end do
        end associate

        ! FC2 bias contribution
        associate(grad => model%grad_fc2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        ! Batch norm gradients
        associate(grad => model%grad_bn1_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        associate(grad => model%grad_bn1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        associate(grad => model%grad_bn2_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        associate(grad => model%grad_bn2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        associate(grad => model%grad_bn3_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate

        associate(grad => model%grad_bn3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                norm_sq = norm_sq + grad(i)**2
            end do
        end associate
    end subroutine compute_gradient_norm_squared

    subroutine scale_conv_gradients_by_spatial(model, batch_size)
        type(cnn_model), intent(inout) :: model
        integer, intent(in) :: batch_size
        integer :: i, j, k, l
        real(4) :: scale

        ! ‚úÖ FIXED: Only scale by batch_size, NOT spatial dimensions
        ! cuDNN already handles spatial summation correctly
        ! PyTorch-style: gradients = sum over batch / batch_size
        scale = 1.0 / real(batch_size)

        ! Scale Conv1 weights
        associate(grad => model%grad_conv1_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            grad(i,j,k,l) = grad(i,j,k,l) * scale
                        end do
                    end do
                end do
            end do
        end associate

        associate(grad => model%grad_conv1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale Conv2 weights
        associate(grad => model%grad_conv2_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            grad(i,j,k,l) = grad(i,j,k,l) * scale
                        end do
                    end do
                end do
            end do
        end associate

        associate(grad => model%grad_conv2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale Conv3 weights
        associate(grad => model%grad_conv3_weights)
            !$cuf kernel do(4)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    do k = 1, size(grad, 3)
                        do l = 1, size(grad, 4)
                            grad(i,j,k,l) = grad(i,j,k,l) * scale
                        end do
                    end do
                end do
            end do
        end associate

        associate(grad => model%grad_conv3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate
    end subroutine scale_conv_gradients_by_spatial

    subroutine scale_fc_and_bn_gradients(model, batch_size)
        type(cnn_model), intent(inout) :: model
        integer, intent(in) :: batch_size
        integer :: i, j
        real(4) :: scale

        ! FC and BatchNorm gradients only need batch size scaling
        scale = 1.0 / real(batch_size)

        ! Scale FC1 gradients
        associate(grad => model%grad_fc1_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    grad(i,j) = grad(i,j) * scale
                end do
            end do
        end associate

        associate(grad => model%grad_fc1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale FC2 gradients
        associate(grad => model%grad_fc2_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    grad(i,j) = grad(i,j) * scale
                end do
            end do
        end associate

        associate(grad => model%grad_fc2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale FC3 gradients
        associate(grad => model%grad_fc3_weights)
            !$cuf kernel do(2)
            do i = 1, size(grad, 1)
                do j = 1, size(grad, 2)
                    grad(i,j) = grad(i,j) * scale
                end do
            end do
        end associate

        associate(grad => model%grad_fc3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        ! Scale BatchNorm gradients
        associate(grad => model%grad_bn1_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn1_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn2_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn2_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn3_scale)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate

        associate(grad => model%grad_bn3_bias)
            !$cuf kernel do(1)
            do i = 1, size(grad)
                grad(i) = grad(i) * scale
            end do
        end associate
    end subroutine scale_fc_and_bn_gradients

    ! ============================================================================
    ! This version uses cudnnActivationForward instead of custom_leaky_relu_4d
    ! CRITICAL FIX: Added is_training parameter to use correct batch norm mode
    ! Training: Uses cudnnBatchNormalizationForwardTraining (updates running stats)
    ! Inference: Uses cudnnBatchNormalizationForwardInference (uses learned stats)
    ! ============================================================================

    subroutine forward_pass(model, input_batch, batch_size, is_training)
        type(cnn_model), intent(inout) :: model
        real(4), device, intent(in) :: input_batch(:,:)  ! (batch_size, 3072)
        integer, intent(in) :: batch_size
        logical, intent(in) :: is_training

        integer(c_int) :: stat, bn_mode
        real(c_float), target :: alpha = 1.0, beta = 0.0
        real(c_double) :: BN_MOMENTUM = 0.1d0, BN_EPSILON = 1.0d-5
        real(c_double), parameter :: eps = 1.0d-5  ! ‚úÖ FIXED: Match PyTorch default (was 1e-3)
        integer :: i, j, k, idx
        logical, save :: first_train = .true., first_eval = .true.

        ! üîç DIAGNOSTIC: Verify training/eval mode on first call
        if (is_training .and. first_train) then
            print *, "üîç FORWARD PASS: TRAINING mode (BatchNorm updates running stats)"
            first_train = .false.
        else if (.not. is_training .and. first_eval) then
            print *, "üîç FORWARD PASS: INFERENCE mode (BatchNorm uses running stats)"
            first_eval = .false.
        endif

        ! ====================================================================
        ! V26: RESHAPE INPUT: (batch, 3072) ‚Üí (W,H,C,N) = (32,32,3,batch)
        ! ====================================================================
        ! Input comes as (batch, 3072) where 3072 = 3*32*32 (C*H*W)
        ! Need to populate model%input which is (W,H,C,N)
        ! ====================================================================

        associate(input_array => model%input)
            !$cuf kernel do(4)
            do i = 1, batch_size          ! N (batch)
                do j = 1, 3               ! C (channel)
                    do k = 1, 32          ! H (height/row)
                        do idx = 1, 32    ! W (width/column)
                            ! V26: Store as (W,H,C,N) instead of (N,C,H,W)
                            input_array(idx, k, j, i) = input_batch(i, (j-1)*1024 + (k-1)*32 + idx)
                        end do
                    end do
                end do
            end do
        end associate


        ! ====================================================================
        ! CONV BLOCK 1: Conv1 ‚Üí Bias ‚Üí BN1 ‚Üí ELU ‚Üí Pool1
        ! ====================================================================

        ! Conv1: (batch, 3, 32, 32) ‚Üí (batch, 32, 32, 32)
        stat = cudnnConvolutionForward(cudnn_handle, c_loc(alpha), &
                model%input_desc, c_loc(model%input), &
                model%conv1_filter_desc, c_loc(model%conv1_weights), &
                model%conv1_conv_desc, CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%conv1_desc, c_loc(model%conv1_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Conv1 failed:", stat

        ! Add bias to Conv1
        stat = cudnnAddTensor(cudnn_handle, c_loc(alpha), &
                model%conv1_bias_desc, c_loc(model%conv1_bias), &
                c_loc(alpha), model%conv1_desc, c_loc(model%conv1_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Conv1 bias add failed:", stat

        ! BatchNorm1 with conditional mode (cuDNN - now with correct memory layout!)
        bn_mode = CUDNN_BATCHNORM_SPATIAL
        if (is_training) then
            stat = cudnnBatchNormalizationForwardTraining(cudnn_handle, bn_mode, &
                c_loc(alpha), c_loc(beta), &
                model%conv1_desc, c_loc(model%conv1_out), &
                model%conv1_desc, c_loc(model%bn1_out), &
                model%bn1_desc, c_loc(model%bn1_scale), c_loc(model%bn1_bias), &
                BN_MOMENTUM, c_loc(model%bn1_running_mean), c_loc(model%bn1_running_var), &
                BN_EPSILON, c_loc(model%bn1_saved_mean), c_loc(model%bn1_saved_inv_var))
        else
            stat = cudnnBatchNormalizationForwardInference(cudnn_handle, bn_mode, &
                c_loc(alpha), c_loc(beta), &
                model%conv1_desc, c_loc(model%conv1_out), &
                model%conv1_desc, c_loc(model%bn1_out), &
                model%bn1_desc, c_loc(model%bn1_scale), c_loc(model%bn1_bias), &
                c_loc(model%bn1_running_mean), c_loc(model%bn1_running_var), &
                BN_EPSILON)
        endif
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå BN1 forward failed:", stat

        if (debug_nan_checks) then
            block
                real(4) :: bn1_sample
                bn1_sample = model%bn1_out(1, 1, 1, 1)
                if (bn1_sample /= bn1_sample) then
                    print *, "‚ùå NaN in BN1"
                    stop
                endif
            end block
        endif

        ! üîç DIAGNOSTIC: Sample Conv1 and BN1 activations (first batch only)
        ! Avoid expensive GPU reductions - just copy small samples to host
        if (model%adam_timestep == 0 .and. is_training) then
            block
                real(4) :: conv1_samples(10), bn1_samples(10)
                integer :: channel, i

                print *, ""
                print *, "üî¨ First Batch Activation Samples (first 10 values from batch 1):"
                print *, ""

                ! Sample channel 1 (should be normal)
                channel = 1
                do i = 1, 10
                    conv1_samples(i) = model%conv1_out(1, channel, 1, i)
                    bn1_samples(i) = model%bn1_out(1, channel, 1, i)
                end do
                print *, "   Conv1 Ch 1:", conv1_samples
                print *, "   BN1 Ch 1:  ", bn1_samples
                print *, ""

                ! Sample channel 13 (outlier - variance 32x)
                channel = 13
                do i = 1, 10
                    conv1_samples(i) = model%conv1_out(1, channel, 1, i)
                    bn1_samples(i) = model%bn1_out(1, channel, 1, i)
                end do
                print *, "   Conv1 Ch 13 (OUTLIER):", conv1_samples
                print *, "   BN1 Ch 13 (OUTLIER):  ", bn1_samples
                print *, ""

                ! Sample channel 21 (outlier - variance 18x)
                channel = 21
                do i = 1, 10
                    conv1_samples(i) = model%conv1_out(1, channel, 1, i)
                    bn1_samples(i) = model%bn1_out(1, channel, 1, i)
                end do
                print *, "   Conv1 Ch 21 (OUTLIER):", conv1_samples
                print *, "   BN1 Ch 21 (OUTLIER):  ", bn1_samples
                print *, ""

                print *, "   Expected BN output: values around -2 to +2, mostly near 0"
                print *, ""
            end block
        endif

        ! LeakyReLU activation (slope=0.01 to match Python reference)
        call apply_leaky_relu_4d(model%bn1_out, model%relu1_out, batch_size*32*32*32, 0.01)


        ! Pool1: (batch, 32, 32, 32) ‚Üí (batch, 32, 16, 16)
        stat = cudnnPoolingForward(cudnn_handle, model%pooling_desc, &
                c_loc(alpha), model%conv1_desc, c_loc(model%relu1_out), &
                c_loc(beta), model%pool1_desc, c_loc(model%pool1_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Pool1 failed:", stat

        ! ====================================================================
        ! CONV BLOCK 2: Conv2 ‚Üí Bias ‚Üí BN2 ‚Üí ELU ‚Üí Pool2
        ! ====================================================================

        ! Conv2: (batch, 32, 16, 16) ‚Üí (batch, 64, 16, 16)
        stat = cudnnConvolutionForward(cudnn_handle, c_loc(alpha), &
                model%pool1_desc, c_loc(model%pool1_out), &
                model%conv2_filter_desc, c_loc(model%conv2_weights), &
                model%conv2_conv_desc, CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%conv2_desc, c_loc(model%conv2_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Conv2 failed:", stat

        ! Add bias to Conv2
        stat = cudnnAddTensor(cudnn_handle, c_loc(alpha), &
                model%conv2_bias_desc, c_loc(model%conv2_bias), &
                c_loc(alpha), model%conv2_desc, c_loc(model%conv2_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Conv2 bias add failed:", stat

        ! BatchNorm2 with conditional mode (cuDNN - now with correct memory layout!)
        if (is_training) then
            stat = cudnnBatchNormalizationForwardTraining(cudnn_handle, bn_mode, &
                c_loc(alpha), c_loc(beta), &
                model%conv2_desc, c_loc(model%conv2_out), &
                model%conv2_desc, c_loc(model%bn2_out), &
                model%bn2_desc, c_loc(model%bn2_scale), c_loc(model%bn2_bias), &
                BN_MOMENTUM, c_loc(model%bn2_running_mean), c_loc(model%bn2_running_var), &
                BN_EPSILON, c_loc(model%bn2_saved_mean), c_loc(model%bn2_saved_inv_var))
        else
            stat = cudnnBatchNormalizationForwardInference(cudnn_handle, bn_mode, &
                c_loc(alpha), c_loc(beta), &
                model%conv2_desc, c_loc(model%conv2_out), &
                model%conv2_desc, c_loc(model%bn2_out), &
                model%bn2_desc, c_loc(model%bn2_scale), c_loc(model%bn2_bias), &
                c_loc(model%bn2_running_mean), c_loc(model%bn2_running_var), &
                BN_EPSILON)
        endif
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå BN2 forward failed:", stat

        if (debug_nan_checks) then
            block
                real(4) :: bn2_sample
                bn2_sample = model%bn2_out(1, 1, 1, 1)
                if (bn2_sample /= bn2_sample) then
                    print *, "‚ùå NaN in BN2"
                    stop
                endif
            end block
        endif

        ! LeakyReLU activation (slope=0.01)
        call apply_leaky_relu_4d(model%bn2_out, model%relu2_out, batch_size*64*16*16, 0.01)

        ! Pool2: (batch, 64, 16, 16) ‚Üí (batch, 64, 8, 8)
        stat = cudnnPoolingForward(cudnn_handle, model%pooling_desc, &
                c_loc(alpha), model%conv2_desc, c_loc(model%relu2_out), &
                c_loc(beta), model%pool2_desc, c_loc(model%pool2_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Pool2 failed:", stat

        ! ====================================================================
        ! CONV BLOCK 3: Conv3 ‚Üí Bias ‚Üí BN3 ‚Üí ELU ‚Üí Pool3
        ! ====================================================================

        ! Conv3: (batch, 64, 8, 8) ‚Üí (batch, 128, 8, 8)
        stat = cudnnConvolutionForward(cudnn_handle, c_loc(alpha), &
                model%pool2_desc, c_loc(model%pool2_out), &
                model%conv3_filter_desc, c_loc(model%conv3_weights), &
                model%conv3_conv_desc, CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%conv3_desc, c_loc(model%conv3_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Conv3 failed:", stat

        ! Add bias to Conv3
        stat = cudnnAddTensor(cudnn_handle, c_loc(alpha), &
                model%conv3_bias_desc, c_loc(model%conv3_bias), &
                c_loc(alpha), model%conv3_desc, c_loc(model%conv3_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Conv3 bias add failed:", stat

        ! BatchNorm3 with conditional mode (cuDNN - now with correct memory layout!)
        if (is_training) then
            stat = cudnnBatchNormalizationForwardTraining(cudnn_handle, bn_mode, &
                c_loc(alpha), c_loc(beta), &
                model%conv3_desc, c_loc(model%conv3_out), &
                model%conv3_desc, c_loc(model%bn3_out), &
                model%bn3_desc, c_loc(model%bn3_scale), c_loc(model%bn3_bias), &
                BN_MOMENTUM, c_loc(model%bn3_running_mean), c_loc(model%bn3_running_var), &
                BN_EPSILON, c_loc(model%bn3_saved_mean), c_loc(model%bn3_saved_inv_var))
        else
            stat = cudnnBatchNormalizationForwardInference(cudnn_handle, bn_mode, &
                c_loc(alpha), c_loc(beta), &
                model%conv3_desc, c_loc(model%conv3_out), &
                model%conv3_desc, c_loc(model%bn3_out), &
                model%bn3_desc, c_loc(model%bn3_scale), c_loc(model%bn3_bias), &
                c_loc(model%bn3_running_mean), c_loc(model%bn3_running_var), &
                BN_EPSILON)
        endif
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå BN3 forward failed:", stat

        if (debug_nan_checks) then
            block
                real(4) :: bn3_sample
                bn3_sample = model%bn3_out(1, 1, 1, 1)
                if (bn3_sample /= bn3_sample) then
                    print *, "‚ùå NaN in BN3"
                    stop
                endif
            end block
        endif

        ! LeakyReLU activation (slope=0.01)
        call apply_leaky_relu_4d(model%bn3_out, model%relu3_out, batch_size*128*8*8, 0.01)

        ! Pool3: (batch, 128, 8, 8) ‚Üí (batch, 128, 4, 4)
        stat = cudnnPoolingForward(cudnn_handle, model%pooling_desc, &
                c_loc(alpha), model%conv3_desc, c_loc(model%relu3_out), &
                c_loc(beta), model%pool3_desc, c_loc(model%pool3_out))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå Pool3 failed:", stat

        ! ====================================================================
        ! FLATTEN: (batch, 128, 4, 4) ‚Üí (batch, 2048)
        ! ====================================================================
        ! V26: pool3_out is now (W,H,C,N) = (4,4,128,N)
        associate(pool3_array => model%pool3_out, flatten_array => model%flatten)
            !$cuf kernel do(2)
            do i = 1, batch_size
                do j = 1, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)
                    idx = j - 1
                    k = idx / (4 * 4)          ! Channel index (0-127)
                    idx = mod(idx, 4 * 4)      ! Spatial index within channel (0-15)
                    ! V26: Read from (W,H,C,N) instead of (N,C,H,W)
                    flatten_array(i, j) = pool3_array(mod(idx,4) + 1, idx/4 + 1, k+1, i)
                end do
            end do
        end associate

        ! ====================================================================
        ! FC1: (batch, 2048) ‚Üí (batch, 512)
        ! ====================================================================


        ! FC1 forward: Compute fc1_out(batch, 512) = flatten(batch, 2048) * fc1_weights(512, 2048)^T
        ! For Fortran column-major: C = A * B^T
        ! A is flatten(batch, 2048) with LD=batch
        ! B is fc1_weights(512, 2048), B^T is (2048, 512) with LD=512
        ! C is fc1_out(batch, 512) with LD=batch
        ! ‚úÖ CORRECT: transa=0 (no transpose A), transb=1 (transpose B)
        stat = cublasSgemm_v2(cublas_handle, 0, 1, &
                int(batch_size, c_int), int(512, c_int), int(CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2), c_int), &
                c_loc(alpha), c_loc(model%flatten), int(batch_size, c_int), &
                c_loc(model%fc1_weights), int(512, c_int), &
                c_loc(beta), c_loc(model%fc1_out), int(batch_size, c_int))


        ! Add bias to FC1
        associate(fc1_array => model%fc1_out, fc1_bias_array => model%fc1_bias)
            !$cuf kernel do(2)
            do i = 1, batch_size
                do j = 1, 512
                    fc1_array(i, j) = fc1_array(i, j) + fc1_bias_array(j)
                end do
            end do
        end associate

        ! LeakyReLU activation after FC1 (slope=0.01 to match Python)
        call apply_leaky_relu_2d(model%fc1_out, model%fc1_relu, batch_size*512, 0.01)


        ! Dropout after FC1 (dropout rate = 0.5)
        if (is_training) then
            stat = cudnnDropoutForward(cudnn_handle, model%dropout_desc, &
                    model%fc1_desc, c_loc(model%fc1_relu), &
                    model%fc1_desc, c_loc(model%fc1_dropout), &
                    c_loc(model%fc1_dropout_reserve), model%fc1_reserve_size)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå FC1 dropout forward failed:", stat
        else
            ! During testing, no dropout - just copy
            model%fc1_dropout = model%fc1_relu
        endif

        ! ====================================================================
        ! FC2: (batch, 512) ‚Üí (batch, 256)
        ! ====================================================================
        ! FC2 forward: Compute fc2_out(batch, 256) = fc1_dropout(batch, 512) * fc2_weights(256, 512)^T
        ! For Fortran column-major: C = A * B^T
        ! A is fc1_dropout(batch, 512) with LD=batch
        ! B is fc2_weights(256, 512), B^T is (512, 256) with LD=256
        ! C is fc2_out(batch, 256) with LD=batch
        ! ‚úÖ CORRECT: transa=0 (no transpose A), transb=1 (transpose B)
        stat = cublasSgemm_v2(cublas_handle, 0, 1, &
                int(batch_size, c_int), int(256, c_int), int(512, c_int), &
                c_loc(alpha), c_loc(model%fc1_dropout), int(batch_size, c_int), &
                c_loc(model%fc2_weights), int(256, c_int), &
                c_loc(beta), c_loc(model%fc2_out), int(batch_size, c_int))

        ! Add bias to FC2
        associate(fc2_array => model%fc2_out, fc2_bias_array => model%fc2_bias)
            !$cuf kernel do(2)
            do i = 1, batch_size
                do j = 1, 256
                    fc2_array(i, j) = fc2_array(i, j) + fc2_bias_array(j)
                end do
            end do
        end associate

        ! LeakyReLU activation after FC2 (slope=0.01 to match Python)
        call apply_leaky_relu_2d(model%fc2_out, model%fc2_relu, batch_size*256, 0.01)


        ! Dropout after FC2 (dropout rate = 0.5)
        if (is_training) then
            stat = cudnnDropoutForward(cudnn_handle, model%dropout_desc, &
                    model%fc2_desc, c_loc(model%fc2_relu), &
                    model%fc2_desc, c_loc(model%fc2_dropout), &
                    c_loc(model%fc2_dropout_reserve), model%fc2_reserve_size)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå FC2 dropout forward failed:", stat
        else
            ! During testing, no dropout - just copy
            model%fc2_dropout = model%fc2_relu
        endif

        ! ====================================================================
        ! FC3: (batch, 256) ‚Üí (batch, 10)
        ! ====================================================================
        ! FC3 forward: Compute fc3_out(batch, 10) = fc2_dropout(batch, 256) * fc3_weights(10, 256)^T
        ! For Fortran column-major: C = A * B^T
        ! A is fc2_dropout(batch, 256) with LD=batch
        ! B is fc3_weights(10, 256), B^T is (256, 10) with LD=10
        ! C is fc3_out(batch, 10) with LD=batch
        ! ‚úÖ CORRECT: transa=0 (no transpose A), transb=1 (transpose B)
        stat = cublasSgemm_v2(cublas_handle, 0, 1, &
                int(batch_size, c_int), int(CNN_NUM_CLASSES, c_int), int(256, c_int), &
                c_loc(alpha), c_loc(model%fc2_dropout), int(batch_size, c_int), &
                c_loc(model%fc3_weights), int(CNN_NUM_CLASSES, c_int), &
                c_loc(beta), c_loc(model%fc3_out), int(batch_size, c_int))

        ! Add bias to FC3
        associate(fc3_array => model%fc3_out, fc3_bias_array => model%fc3_bias)
            !$cuf kernel do(2)
            do i = 1, batch_size
                do j = 1, CNN_NUM_CLASSES
                    fc3_array(i, j) = fc3_array(i, j) + fc3_bias_array(j)
                end do
            end do
        end associate

        ! ====================================================================
        ! SOFTMAX: (batch, 10) ‚Üí (batch, 10)
        ! ‚úÖ FIXED: Use custom kernel instead of cuDNN to handle Fortran column-major layout
        ! cuDNN expects NCHW format but our 2D arrays are (batch, classes) in column-major
        ! ====================================================================
        call apply_softmax_2d(model%fc3_out, model%softmax_out, batch_size, CNN_NUM_CLASSES)

    end subroutine forward_pass

    ! ========================================================================
    ! Backward pass - pure cuDNN calls
    ! ========================================================================

    subroutine backward_pass(model, grad_output, batch_size, learning_rate, is_training)
        type(cnn_model), intent(inout) :: model
        real(4), device, intent(in) :: grad_output(:,:)
        integer, intent(in) :: batch_size
        real(4), intent(in) :: learning_rate
        logical, intent(in) :: is_training
        integer(c_int) :: stat, bn_mode
        real(c_float), target :: alpha = 1.0, beta = 0.0, beta_acc = 1.0
        real(c_double) :: BN_EPSILON = 1.0d-5
        real(c_double), parameter :: eps = 1.0d-5  ! ‚úÖ FIXED: Match PyTorch default (was 1e-3)
        integer :: i, j, k, l, idx
        real(4), device, allocatable, target :: ones_vector(:)
        real(4), device, allocatable, target :: grad_flatten_temp(:,:)

        logical, save :: first_call = .true.
        !if (first_call) then
        !    print *, "üîç Zeroing gradients at start of backward_pass"
        !    first_call = .false.
        !endif

        ! Zero out all gradients before backward pass
        model%grad_conv1_weights = 0.0
        model%grad_conv1_bias = 0.0
        model%grad_conv2_weights = 0.0
        model%grad_conv2_bias = 0.0
        model%grad_conv3_weights = 0.0
        model%grad_conv3_bias = 0.0
        model%grad_fc1_weights = 0.0
        model%grad_fc1_bias = 0.0
        model%grad_fc2_weights = 0.0
        model%grad_fc2_bias = 0.0
        model%grad_fc3_weights = 0.0
        model%grad_fc3_bias = 0.0
        model%grad_bn1_scale = 0.0
        model%grad_bn1_bias = 0.0
        model%grad_bn2_scale = 0.0
        model%grad_bn2_bias = 0.0
        model%grad_bn3_scale = 0.0
        model%grad_bn3_bias = 0.0

        allocate(ones_vector(batch_size))
        ones_vector = 1.0

        ! ========================================================================
        ! FC3 + Softmax Backward
        ! ========================================================================

        model%grad_fc3 = grad_output


        ! FC3 weight gradients
        ! Compute: grad_weights(10, 256) = grad_fc3(batch, 10)^T * fc2_dropout(batch, 256)
        ! For Fortran column-major: C = A^T * B
        ! A is grad_fc3(batch, 10), A^T is (10, batch) with LD=batch
        ! B is fc2_dropout(batch, 256) with LD=batch
        ! C is grad_fc3_weights(10, 256) with LD=10
        stat = cublasSgemm_v2(cublas_handle, 1, 0, &
                int(CNN_NUM_CLASSES, c_int), int(256, c_int), int(batch_size, c_int), &
                c_loc(alpha), c_loc(model%grad_fc3), int(batch_size, c_int), &
                c_loc(model%fc2_dropout), int(batch_size, c_int), &
                c_loc(beta), c_loc(model%grad_fc3_weights), int(CNN_NUM_CLASSES, c_int))


        ! FC3 bias gradients
        stat = cublasSgemv_v2(cublas_handle, 1, &
                int(batch_size, c_int), int(CNN_NUM_CLASSES, c_int), &
                c_loc(alpha), c_loc(model%grad_fc3), int(batch_size, c_int), &
                c_loc(ones_vector), 1, &
                c_loc(beta), c_loc(model%grad_fc3_bias), 1)

        ! FC3 input gradients
        ! Compute: grad_fc2(batch, 256) = grad_fc3(batch, 10) * fc3_weights(10, 256)
        ! For Fortran column-major: C = A * B
        ! A is grad_fc3(batch, 10) with LD=batch
        ! B is fc3_weights(10, 256) with LD=10
        ! C is grad_fc2(batch, 256) with LD=batch
        ! ‚úÖ CORRECT: No transpose needed for Fortran column-major
        stat = cublasSgemm_v2(cublas_handle, 0, 0, &
                int(batch_size, c_int), int(256, c_int), int(CNN_NUM_CLASSES, c_int), &
                c_loc(alpha), c_loc(model%grad_fc3), int(batch_size, c_int), &
                c_loc(model%fc3_weights), int(CNN_NUM_CLASSES, c_int), &
                c_loc(beta), c_loc(model%grad_fc2), int(batch_size, c_int))

        ! ========================================================================
        ! FC2 Backward
        ! ========================================================================

        ! Dropout backward for FC2
        if (is_training) then
            stat = cudnnDropoutBackward(cudnn_handle, model%dropout_desc, &
                    model%fc2_desc, c_loc(model%grad_fc2), &
                    model%fc2_desc, c_loc(model%grad_fc2_dropout), &
                    c_loc(model%fc2_dropout_reserve), model%fc2_reserve_size)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå FC2 dropout backward failed:", stat
        else
            ! During testing, no dropout - just copy
            model%grad_fc2_dropout = model%grad_fc2
        endif

        ! LeakyReLU backward (slope=0.01)
        call apply_leaky_relu_backward_2d(model%grad_fc2_dropout, model%fc2_out, &
                                          model%grad_fc2_relu, batch_size*256, 0.01)

        ! FC2 weight gradients
        ! Compute: grad_weights(256, 512) = grad_fc2_relu(batch, 256)^T * fc1_dropout(batch, 512)
        ! For Fortran column-major: C = A^T * B
        ! A is grad_fc2_relu(batch, 256), A^T is (256, batch) with LD=batch
        ! B is fc1_dropout(batch, 512) with LD=batch
        ! C is grad_fc2_weights(256, 512) with LD=256
        stat = cublasSgemm_v2(cublas_handle, 1, 0, &
                int(256, c_int), int(512, c_int), int(batch_size, c_int), &
                c_loc(alpha), c_loc(model%grad_fc2_relu), int(batch_size, c_int), &
                c_loc(model%fc1_dropout), int(batch_size, c_int), &
                c_loc(beta), c_loc(model%grad_fc2_weights), int(256, c_int))

        ! FC2 bias gradients
        stat = cublasSgemv_v2(cublas_handle, 1, &
                int(batch_size, c_int), int(256, c_int), &
                c_loc(alpha), c_loc(model%grad_fc2_relu), int(batch_size, c_int), &
                c_loc(ones_vector), 1, &
                c_loc(beta), c_loc(model%grad_fc2_bias), 1)

        ! FC2 input gradients
        ! Compute: grad_fc1(batch, 512) = grad_fc2_relu(batch, 256) * fc2_weights(256, 512)
        ! For Fortran column-major: C = A * B
        ! A is grad_fc2_relu(batch, 256) with LD=batch
        ! B is fc2_weights(256, 512) with LD=256
        ! C is grad_fc1(batch, 512) with LD=batch
        ! ‚úÖ CORRECT: No transpose needed for Fortran column-major
        stat = cublasSgemm_v2(cublas_handle, 0, 0, &
                int(batch_size, c_int), int(512, c_int), int(256, c_int), &
                c_loc(alpha), c_loc(model%grad_fc2_relu), int(batch_size, c_int), &
                c_loc(model%fc2_weights), int(256, c_int), &
                c_loc(beta), c_loc(model%grad_fc1), int(batch_size, c_int))

        ! ========================================================================
        ! FC1 Backward
        ! ========================================================================

        ! Dropout backward for FC1
        if (is_training) then
            stat = cudnnDropoutBackward(cudnn_handle, model%dropout_desc, &
                    model%fc1_desc, c_loc(model%grad_fc1), &
                    model%fc1_desc, c_loc(model%grad_fc1_dropout), &
                    c_loc(model%fc1_dropout_reserve), model%fc1_reserve_size)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå FC1 dropout backward failed:", stat
        else
            ! During testing, no dropout - just copy
            model%grad_fc1_dropout = model%grad_fc1
        endif

        ! LeakyReLU backward (slope=0.01)
        call apply_leaky_relu_backward_2d(model%grad_fc1_dropout, model%fc1_out, &
                                          model%grad_fc1_relu, batch_size*512, 0.01)

        ! FC1 weight gradients
        ! Compute: grad_weights(512, 2048) = grad_fc1_relu(batch, 512)^T * flatten(batch, 2048)
        ! For Fortran column-major: C = A^T * B
        ! A is grad_fc1_relu(batch, 512), A^T is (512, batch) with LD=batch
        ! B is flatten(batch, 2048) with LD=batch
        ! C is grad_fc1_weights(512, 2048) with LD=512
        stat = cublasSgemm_v2(cublas_handle, 1, 0, &
                int(512, c_int), int(CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2), c_int), int(batch_size, c_int), &
                c_loc(alpha), c_loc(model%grad_fc1_relu), int(batch_size, c_int), &
                c_loc(model%flatten), int(batch_size, c_int), &
                c_loc(beta), c_loc(model%grad_fc1_weights), int(512, c_int))

        ! FC1 bias gradients
        stat = cublasSgemv_v2(cublas_handle, 1, &
                int(batch_size, c_int), int(512, c_int), &
                c_loc(alpha), c_loc(model%grad_fc1_relu), int(batch_size, c_int), &
                c_loc(ones_vector), 1, &
                c_loc(beta), c_loc(model%grad_fc1_bias), 1)

        ! FC1 input gradients (to flatten)
        ! Compute: grad_flatten(batch, 2048) = grad_fc1_relu(batch, 512) * fc1_weights(512, 2048)
        ! For Fortran column-major: C = A * B
        ! A is grad_fc1_relu(batch, 512) with LD=batch
        ! B is fc1_weights(512, 2048) with LD=512
        ! C is grad_flatten(batch, 2048) with LD=batch
        ! ‚úÖ CORRECT: No transpose needed for Fortran column-major
        allocate(grad_flatten_temp(batch_size, CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2)))
        stat = cublasSgemm_v2(cublas_handle, 0, 0, &
                int(batch_size, c_int), int(CONV3_FILTERS * ((INPUT_HEIGHT/4)/2) * ((INPUT_WIDTH/4)/2), c_int), int(512, c_int), &
                c_loc(alpha), c_loc(model%grad_fc1_relu), int(batch_size, c_int), &
                c_loc(model%fc1_weights), int(512, c_int), &
                c_loc(beta), c_loc(grad_flatten_temp), int(batch_size, c_int))

        ! ========================================================================
        ! V26: UNFLATTEN GRADIENT (W,H,C,N) format
        ! ========================================================================
        associate(flatten_grad => grad_flatten_temp, pool3_grad => model%grad_pool3)
            !$cuf kernel do(4)
            do i = 1, batch_size        ! N
                do j = 1, CONV3_FILTERS  ! C
                    do k = 1, 4          ! H
                        do l = 1, 4      ! W
                            idx = (j-1)*16 + (k-1)*4 + l
                            ! V26: Write to (W,H,C,N) instead of (N,C,H,W)
                            pool3_grad(l, k, j, i) = flatten_grad(i, idx)
                            if (abs(pool3_grad(l, k, j, i)) > 10.0) then
                                pool3_grad(l, k, j, i) = sign(10.0, pool3_grad(l, k, j, i))
                            endif
                        end do
                    end do
                end do
            end do
        end associate

        ! ========================================================================
        ! CONV BLOCK 3 BACKWARD
        ! ========================================================================

        stat = cudnnPoolingBackward(cudnn_handle, model%pooling_desc, &
                c_loc(alpha), model%pool3_desc, c_loc(model%pool3_out), &
                model%pool3_desc, c_loc(model%grad_pool3), &
                model%conv3_desc, c_loc(model%relu3_out), &
                c_loc(beta), model%conv3_desc, c_loc(model%grad_relu3))

        ! LeakyReLU backward (slope=0.01)
        call apply_leaky_relu_backward_4d(model%grad_relu3, model%bn3_out, &
                                          model%grad_bn3, batch_size*128*8*8, 0.01)

        ! BatchNorm3 backward (cuDNN - now with correct memory layout!)
        bn_mode = CUDNN_BATCHNORM_SPATIAL
        stat = cudnnBatchNormalizationBackward(cudnn_handle, bn_mode, &
            c_loc(alpha), c_loc(beta), c_loc(alpha), c_loc(beta), &
            model%conv3_desc, c_loc(model%conv3_out), &
            model%conv3_desc, c_loc(model%grad_bn3), &
            model%conv3_desc, c_loc(model%grad_conv3), &
            model%bn3_desc, c_loc(model%bn3_scale), &
            c_loc(model%grad_bn3_scale), c_loc(model%grad_bn3_bias), &
            BN_EPSILON, c_loc(model%bn3_saved_mean), c_loc(model%bn3_saved_inv_var))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå BN3 backward failed:", stat

        stat = cudnnConvolutionBackwardBias(cudnn_handle, &
                c_loc(alpha), model%conv3_desc, c_loc(model%grad_conv3), &
                c_loc(beta), model%conv3_bias_desc, c_loc(model%grad_conv3_bias))

        stat = cudnnConvolutionBackwardFilter(cudnn_handle, &
                c_loc(alpha), model%pool2_desc, c_loc(model%pool2_out), &
                model%conv3_desc, c_loc(model%grad_conv3), &
                model%conv3_conv_desc, CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%conv3_filter_desc, c_loc(model%grad_conv3_weights))

        stat = cudnnConvolutionBackwardData(cudnn_handle, &
                c_loc(alpha), model%conv3_filter_desc, c_loc(model%conv3_weights), &
                model%conv3_desc, c_loc(model%grad_conv3), &
                model%conv3_conv_desc, CUDNN_CONVOLUTION_BWD_DATA_ALGO_1, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%pool2_desc, c_loc(model%grad_pool2))

        ! ========================================================================
        ! CONV BLOCK 2 BACKWARD
        ! ========================================================================

        stat = cudnnPoolingBackward(cudnn_handle, model%pooling_desc, &
                c_loc(alpha), model%pool2_desc, c_loc(model%pool2_out), &
                model%pool2_desc, c_loc(model%grad_pool2), &
                model%conv2_desc, c_loc(model%relu2_out), &
                c_loc(beta), model%conv2_desc, c_loc(model%grad_relu2))

        ! LeakyReLU backward (slope=0.01)
        call apply_leaky_relu_backward_4d(model%grad_relu2, model%bn2_out, &
                                          model%grad_bn2, batch_size*64*16*16, 0.01)

        ! BatchNorm2 backward (cuDNN - now with correct memory layout!)
        stat = cudnnBatchNormalizationBackward(cudnn_handle, bn_mode, &
            c_loc(alpha), c_loc(beta), c_loc(alpha), c_loc(beta), &
            model%conv2_desc, c_loc(model%conv2_out), &
            model%conv2_desc, c_loc(model%grad_bn2), &
            model%conv2_desc, c_loc(model%grad_conv2), &
            model%bn2_desc, c_loc(model%bn2_scale), &
            c_loc(model%grad_bn2_scale), c_loc(model%grad_bn2_bias), &
            BN_EPSILON, c_loc(model%bn2_saved_mean), c_loc(model%bn2_saved_inv_var))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå BN2 backward failed:", stat

        stat = cudnnConvolutionBackwardBias(cudnn_handle, &
                c_loc(alpha), model%conv2_desc, c_loc(model%grad_conv2), &
                c_loc(beta), model%conv2_bias_desc, c_loc(model%grad_conv2_bias))

        stat = cudnnConvolutionBackwardFilter(cudnn_handle, &
                c_loc(alpha), model%pool1_desc, c_loc(model%pool1_out), &
                model%conv2_desc, c_loc(model%grad_conv2), &
                model%conv2_conv_desc, CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%conv2_filter_desc, c_loc(model%grad_conv2_weights))

        stat = cudnnConvolutionBackwardData(cudnn_handle, &
                c_loc(alpha), model%conv2_filter_desc, c_loc(model%conv2_weights), &
                model%conv2_desc, c_loc(model%grad_conv2), &
                model%conv2_conv_desc, CUDNN_CONVOLUTION_BWD_DATA_ALGO_1, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%pool1_desc, c_loc(model%grad_pool1))

        ! ========================================================================
        ! CONV BLOCK 1 BACKWARD
        ! ========================================================================

        stat = cudnnPoolingBackward(cudnn_handle, model%pooling_desc, &
                c_loc(alpha), model%pool1_desc, c_loc(model%pool1_out), &
                model%pool1_desc, c_loc(model%grad_pool1), &
                model%conv1_desc, c_loc(model%relu1_out), &
                c_loc(beta), model%conv1_desc, c_loc(model%grad_relu1))

        ! LeakyReLU backward (slope=0.01)
        call apply_leaky_relu_backward_4d(model%grad_relu1, model%bn1_out, &
                                          model%grad_bn1, batch_size*32*32*32, 0.01)

        ! BatchNorm1 backward (cuDNN - now with correct memory layout!)
        stat = cudnnBatchNormalizationBackward(cudnn_handle, bn_mode, &
            c_loc(alpha), c_loc(beta), c_loc(alpha), c_loc(beta), &
            model%conv1_desc, c_loc(model%conv1_out), &
            model%conv1_desc, c_loc(model%grad_bn1), &
            model%conv1_desc, c_loc(model%grad_conv1), &
            model%bn1_desc, c_loc(model%bn1_scale), &
            c_loc(model%grad_bn1_scale), c_loc(model%grad_bn1_bias), &
            BN_EPSILON, c_loc(model%bn1_saved_mean), c_loc(model%bn1_saved_inv_var))
        if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ùå BN1 backward failed:", stat

        stat = cudnnConvolutionBackwardBias(cudnn_handle, &
                c_loc(alpha), model%conv1_desc, c_loc(model%grad_conv1), &
                c_loc(beta), model%conv1_bias_desc, c_loc(model%grad_conv1_bias))

        stat = cudnnConvolutionBackwardFilter(cudnn_handle, &
                c_loc(alpha), model%input_desc, c_loc(model%input), &
                model%conv1_desc, c_loc(model%grad_conv1), &
                model%conv1_conv_desc, CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1, &
                c_loc(model%workspace), model%workspace_size, &
                c_loc(beta), model%conv1_filter_desc, c_loc(model%grad_conv1_weights))

        block
            real(4) :: grad_check
            logical :: has_nan

            grad_check = model%grad_fc3_weights(1, 1)
            has_nan = .false.
            if (grad_check /= grad_check) has_nan = .true.

            grad_check = model%grad_conv1_weights(1, 1, 1, 1)
            if (grad_check /= grad_check) has_nan = .true.

            if (has_nan) then
                print *, "‚ö†Ô∏è  NaN detected in gradients! Skipping weight update"
            endif
        end block

        ! ‚úÖ Re-enabled: Gradient scaling is NOT the issue (tested and confirmed)
        ! Removing these made no significant difference (62.53% ‚Üí 62.14%)
        call scale_conv_gradients_by_spatial(model, batch_size)
        call scale_fc_and_bn_gradients(model, batch_size)


        call update_weights(model, learning_rate)

        deallocate(ones_vector)
        if (allocated(grad_flatten_temp)) deallocate(grad_flatten_temp)
    end subroutine backward_pass

    ! ========================================================================
    ! ADAM OPTIMIZER UPDATE (matching PyTorch)
    ! ========================================================================
    subroutine update_weights(model, learning_rate)
        type(cnn_model), intent(inout) :: model
        real(4), intent(in) :: learning_rate
        real(4) :: bias_correction1, bias_correction2, corrected_lr

        ! Increment timestep
        model%adam_timestep = model%adam_timestep + 1


        ! Compute bias corrections
        bias_correction1 = 1.0 - adam_beta1**model%adam_timestep
        bias_correction2 = 1.0 - adam_beta2**model%adam_timestep

        ! Update all parameters with Adam
        call adam_update_4d(model%conv1_weights, model%grad_conv1_weights, &
                           model%m_conv1_weights, model%v_conv1_weights, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%conv1_bias, model%grad_conv1_bias, &
                           model%m_conv1_bias, model%v_conv1_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_4d(model%conv2_weights, model%grad_conv2_weights, &
                           model%m_conv2_weights, model%v_conv2_weights, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%conv2_bias, model%grad_conv2_bias, &
                           model%m_conv2_bias, model%v_conv2_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_4d(model%conv3_weights, model%grad_conv3_weights, &
                           model%m_conv3_weights, model%v_conv3_weights, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%conv3_bias, model%grad_conv3_bias, &
                           model%m_conv3_bias, model%v_conv3_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_2d(model%fc1_weights, model%grad_fc1_weights, &
                           model%m_fc1_weights, model%v_fc1_weights, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%fc1_bias, model%grad_fc1_bias, &
                           model%m_fc1_bias, model%v_fc1_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_2d(model%fc2_weights, model%grad_fc2_weights, &
                           model%m_fc2_weights, model%v_fc2_weights, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%fc2_bias, model%grad_fc2_bias, &
                           model%m_fc2_bias, model%v_fc2_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_2d(model%fc3_weights, model%grad_fc3_weights, &
                           model%m_fc3_weights, model%v_fc3_weights, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%fc3_bias, model%grad_fc3_bias, &
                           model%m_fc3_bias, model%v_fc3_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_1d(model%bn1_scale, model%grad_bn1_scale, &
                           model%m_bn1_scale, model%v_bn1_scale, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%bn1_bias, model%grad_bn1_bias, &
                           model%m_bn1_bias, model%v_bn1_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_1d(model%bn2_scale, model%grad_bn2_scale, &
                           model%m_bn2_scale, model%v_bn2_scale, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%bn2_bias, model%grad_bn2_bias, &
                           model%m_bn2_bias, model%v_bn2_bias, &
                           learning_rate, bias_correction1, bias_correction2)

        call adam_update_1d(model%bn3_scale, model%grad_bn3_scale, &
                           model%m_bn3_scale, model%v_bn3_scale, &
                           learning_rate, bias_correction1, bias_correction2)
        call adam_update_1d(model%bn3_bias, model%grad_bn3_bias, &
                           model%m_bn3_bias, model%v_bn3_bias, &
                           learning_rate, bias_correction1, bias_correction2)

    end subroutine update_weights

    ! ========================================================================
    ! Adam optimizer functions are now provided by apex_adam_kernels module
    ! Using NVIDIA Apex FusedAdam reference implementation
    ! ========================================================================

    ! ========================================================================
    ! Compute loss and accuracy
    ! ========================================================================
    subroutine compute_metrics(model, labels, batch_size, loss, accuracy)
        type(cnn_model), intent(in) :: model
        integer, device, intent(in) :: labels(:)
        integer, intent(in) :: batch_size
        real(4), intent(out) :: loss, accuracy
        real(4), allocatable :: host_probs(:,:)
        integer, allocatable :: host_labels(:)
        integer :: i, j, pred_class, correct
        real(4) :: max_prob

        allocate(host_probs(batch_size, CNN_NUM_CLASSES))
        allocate(host_labels(batch_size))

        host_probs = model%softmax_out(1:batch_size, :)
        host_labels = labels(1:batch_size)

        loss = 0.0
        correct = 0

        do i = 1, batch_size
            ! Cross-entropy loss
            loss = loss - log(max(host_probs(i, host_labels(i) + 1), 1e-7))

            ! Find predicted class
            max_prob = -1.0
            pred_class = 0
            do j = 1, CNN_NUM_CLASSES
                if (host_probs(i, j) > max_prob) then
                    max_prob = host_probs(i, j)
                    pred_class = j - 1
                end if
            end do

            if (pred_class == host_labels(i)) correct = correct + 1
        end do

        loss = loss / batch_size
        accuracy = real(correct) / real(batch_size) * 100.0

        deallocate(host_probs, host_labels)
    end subroutine compute_metrics

    ! ============================================================================
    ! FIX #3: Complete cleanup_model implementation
    ! ============================================================================
    ! INSTRUCTIONS: Replace the entire cleanup_model subroutine with this version
    ! This version properly destroys all descriptors and deallocates all arrays
    ! ============================================================================

    subroutine cleanup_model(model)
        type(cnn_model), intent(inout) :: model
        integer(c_int) :: stat

        print *, "üßπ Cleaning up model..."

        ! ========================================================================
        ! DESTROY ALL CUDNN DESCRIPTORS
        ! ========================================================================

        ! Tensor descriptors
        if (c_associated(model%input_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%input_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy input_desc"
        endif

        if (c_associated(model%conv1_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%conv1_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv1_desc"
        endif

        if (c_associated(model%pool1_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%pool1_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy pool1_desc"
        endif

        if (c_associated(model%conv2_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%conv2_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv2_desc"
        endif

        if (c_associated(model%pool2_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%pool2_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy pool2_desc"
        endif

        if (c_associated(model%conv3_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%conv3_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv3_desc"
        endif

        if (c_associated(model%pool3_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%pool3_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy pool3_desc"
        endif

        if (c_associated(model%fc1_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%fc1_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy fc1_desc"
        endif

        if (c_associated(model%fc2_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%fc2_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy fc2_desc"
        endif

        if (c_associated(model%output_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%output_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy output_desc"
        endif

        ! Filter descriptors
        if (c_associated(model%conv1_filter_desc)) then
            stat = cudnnDestroyFilterDescriptor(model%conv1_filter_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv1_filter_desc"
        endif

        if (c_associated(model%conv2_filter_desc)) then
            stat = cudnnDestroyFilterDescriptor(model%conv2_filter_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv2_filter_desc"
        endif

        if (c_associated(model%conv3_filter_desc)) then
            stat = cudnnDestroyFilterDescriptor(model%conv3_filter_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv3_filter_desc"
        endif

        ! Bias descriptors
        if (c_associated(model%conv1_bias_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%conv1_bias_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv1_bias_desc"
        endif

        if (c_associated(model%conv2_bias_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%conv2_bias_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv2_bias_desc"
        endif

        if (c_associated(model%conv3_bias_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%conv3_bias_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv3_bias_desc"
        endif

        ! Convolution descriptors
        if (c_associated(model%conv1_conv_desc)) then
            stat = cudnnDestroyConvolutionDescriptor(model%conv1_conv_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv1_conv_desc"
        endif

        if (c_associated(model%conv2_conv_desc)) then
            stat = cudnnDestroyConvolutionDescriptor(model%conv2_conv_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv2_conv_desc"
        endif

        if (c_associated(model%conv3_conv_desc)) then
            stat = cudnnDestroyConvolutionDescriptor(model%conv3_conv_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy conv3_conv_desc"
        endif

        ! Pooling descriptor (shared)
        if (c_associated(model%pooling_desc)) then
            stat = cudnnDestroyPoolingDescriptor(model%pooling_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy pooling_desc"
        endif

        ! Activation descriptor (shared)
        if (c_associated(model%activation_desc)) then
            stat = cudnnDestroyActivationDescriptor(model%activation_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy activation_desc"
        endif

        ! Batch normalization descriptors
        if (c_associated(model%bn1_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%bn1_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy bn1_desc"
        endif

        if (c_associated(model%bn2_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%bn2_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy bn2_desc"
        endif

        if (c_associated(model%bn3_desc)) then
            stat = cudnnDestroyTensorDescriptor(model%bn3_desc)
            if (stat /= CUDNN_STATUS_SUCCESS) print *, "‚ö†Ô∏è  Failed to destroy bn3_desc"
        endif

        ! ========================================================================
        ! DEALLOCATE ALL WEIGHT ARRAYS
        ! ========================================================================

        ! Convolution weights and biases
        if (allocated(model%conv1_weights)) deallocate(model%conv1_weights)
        if (allocated(model%conv1_bias)) deallocate(model%conv1_bias)
        if (allocated(model%conv2_weights)) deallocate(model%conv2_weights)
        if (allocated(model%conv2_bias)) deallocate(model%conv2_bias)
        if (allocated(model%conv3_weights)) deallocate(model%conv3_weights)
        if (allocated(model%conv3_bias)) deallocate(model%conv3_bias)

        ! Batch normalization parameters
        if (allocated(model%bn1_scale)) deallocate(model%bn1_scale)
        if (allocated(model%bn1_bias)) deallocate(model%bn1_bias)
        if (allocated(model%bn1_running_mean)) deallocate(model%bn1_running_mean)
        if (allocated(model%bn1_running_var)) deallocate(model%bn1_running_var)
        if (allocated(model%bn1_saved_mean)) deallocate(model%bn1_saved_mean)
        if (allocated(model%bn1_saved_inv_var)) deallocate(model%bn1_saved_inv_var)

        if (allocated(model%bn2_scale)) deallocate(model%bn2_scale)
        if (allocated(model%bn2_bias)) deallocate(model%bn2_bias)
        if (allocated(model%bn2_running_mean)) deallocate(model%bn2_running_mean)
        if (allocated(model%bn2_running_var)) deallocate(model%bn2_running_var)
        if (allocated(model%bn2_saved_mean)) deallocate(model%bn2_saved_mean)
        if (allocated(model%bn2_saved_inv_var)) deallocate(model%bn2_saved_inv_var)

        if (allocated(model%bn3_scale)) deallocate(model%bn3_scale)
        if (allocated(model%bn3_bias)) deallocate(model%bn3_bias)
        if (allocated(model%bn3_running_mean)) deallocate(model%bn3_running_mean)
        if (allocated(model%bn3_running_var)) deallocate(model%bn3_running_var)
        if (allocated(model%bn3_saved_mean)) deallocate(model%bn3_saved_mean)
        if (allocated(model%bn3_saved_inv_var)) deallocate(model%bn3_saved_inv_var)

        ! Fully connected weights and biases
        if (allocated(model%fc1_weights)) deallocate(model%fc1_weights)
        if (allocated(model%fc1_bias)) deallocate(model%fc1_bias)
        if (allocated(model%fc2_weights)) deallocate(model%fc2_weights)
        if (allocated(model%fc2_bias)) deallocate(model%fc2_bias)

        ! ========================================================================
        ! DEALLOCATE ALL INTERMEDIATE OUTPUT ARRAYS
        ! ========================================================================

        if (allocated(model%input)) deallocate(model%input)
        if (allocated(model%conv1_out)) deallocate(model%conv1_out)
        if (allocated(model%bn1_out)) deallocate(model%bn1_out)
        if (allocated(model%relu1_out)) deallocate(model%relu1_out)
        if (allocated(model%pool1_out)) deallocate(model%pool1_out)
        if (allocated(model%conv2_out)) deallocate(model%conv2_out)
        if (allocated(model%bn2_out)) deallocate(model%bn2_out)
        if (allocated(model%relu2_out)) deallocate(model%relu2_out)
        if (allocated(model%pool2_out)) deallocate(model%pool2_out)
        if (allocated(model%conv3_out)) deallocate(model%conv3_out)
        if (allocated(model%bn3_out)) deallocate(model%bn3_out)
        if (allocated(model%relu3_out)) deallocate(model%relu3_out)
        if (allocated(model%pool3_out)) deallocate(model%pool3_out)
        if (allocated(model%flatten)) deallocate(model%flatten)
        if (allocated(model%fc1_out)) deallocate(model%fc1_out)
        if (allocated(model%fc2_out)) deallocate(model%fc2_out)
        if (allocated(model%softmax_out)) deallocate(model%softmax_out)

        ! ========================================================================
        ! DEALLOCATE ALL GRADIENT ARRAYS
        ! ========================================================================

        ! Conv gradient arrays
        if (allocated(model%grad_input)) deallocate(model%grad_input)
        if (allocated(model%grad_conv1)) deallocate(model%grad_conv1)
        if (allocated(model%grad_bn1)) deallocate(model%grad_bn1)
        if (allocated(model%grad_relu1)) deallocate(model%grad_relu1)
        if (allocated(model%grad_pool1)) deallocate(model%grad_pool1)
        if (allocated(model%grad_conv2)) deallocate(model%grad_conv2)
        if (allocated(model%grad_bn2)) deallocate(model%grad_bn2)
        if (allocated(model%grad_relu2)) deallocate(model%grad_relu2)
        if (allocated(model%grad_pool2)) deallocate(model%grad_pool2)
        if (allocated(model%grad_conv3)) deallocate(model%grad_conv3)
        if (allocated(model%grad_bn3)) deallocate(model%grad_bn3)
        if (allocated(model%grad_relu3)) deallocate(model%grad_relu3)
        if (allocated(model%grad_pool3)) deallocate(model%grad_pool3)

        ! FC gradient arrays
        if (allocated(model%grad_fc1)) deallocate(model%grad_fc1)
        if (allocated(model%grad_fc1_dropout)) deallocate(model%grad_fc1_dropout)
        if (allocated(model%grad_fc1_relu)) deallocate(model%grad_fc1_relu)
        if (allocated(model%grad_fc2)) deallocate(model%grad_fc2)
        if (allocated(model%grad_fc2_dropout)) deallocate(model%grad_fc2_dropout)
        if (allocated(model%grad_fc2_relu)) deallocate(model%grad_fc2_relu)
        if (allocated(model%grad_fc3)) deallocate(model%grad_fc3)

        ! Weight gradient arrays
        if (allocated(model%grad_conv1_weights)) deallocate(model%grad_conv1_weights)
        if (allocated(model%grad_conv1_bias)) deallocate(model%grad_conv1_bias)
        if (allocated(model%grad_conv2_weights)) deallocate(model%grad_conv2_weights)
        if (allocated(model%grad_conv2_bias)) deallocate(model%grad_conv2_bias)
        if (allocated(model%grad_conv3_weights)) deallocate(model%grad_conv3_weights)
        if (allocated(model%grad_conv3_bias)) deallocate(model%grad_conv3_bias)
        if (allocated(model%grad_fc1_weights)) deallocate(model%grad_fc1_weights)
        if (allocated(model%grad_fc1_bias)) deallocate(model%grad_fc1_bias)
        if (allocated(model%grad_fc2_weights)) deallocate(model%grad_fc2_weights)
        if (allocated(model%grad_fc2_bias)) deallocate(model%grad_fc2_bias)
        if (allocated(model%grad_fc3_weights)) deallocate(model%grad_fc3_weights)
        if (allocated(model%grad_fc3_bias)) deallocate(model%grad_fc3_bias)

        ! Batch norm gradient arrays
        if (allocated(model%grad_bn1_scale)) deallocate(model%grad_bn1_scale)
        if (allocated(model%grad_bn1_bias)) deallocate(model%grad_bn1_bias)
        if (allocated(model%grad_bn2_scale)) deallocate(model%grad_bn2_scale)
        if (allocated(model%grad_bn2_bias)) deallocate(model%grad_bn2_bias)
        if (allocated(model%grad_bn3_scale)) deallocate(model%grad_bn3_scale)
        if (allocated(model%grad_bn3_bias)) deallocate(model%grad_bn3_bias)

        print *, "‚úÖ Gradient arrays cleaned up"

        ! ========================================================================
        ! DEALLOCATE ADAM OPTIMIZER STATE
        ! ========================================================================

        ! Conv layers - first moments
        if (allocated(model%m_conv1_weights)) deallocate(model%m_conv1_weights)
        if (allocated(model%m_conv1_bias)) deallocate(model%m_conv1_bias)
        if (allocated(model%m_conv2_weights)) deallocate(model%m_conv2_weights)
        if (allocated(model%m_conv2_bias)) deallocate(model%m_conv2_bias)
        if (allocated(model%m_conv3_weights)) deallocate(model%m_conv3_weights)
        if (allocated(model%m_conv3_bias)) deallocate(model%m_conv3_bias)

        ! Conv layers - second moments
        if (allocated(model%v_conv1_weights)) deallocate(model%v_conv1_weights)
        if (allocated(model%v_conv1_bias)) deallocate(model%v_conv1_bias)
        if (allocated(model%v_conv2_weights)) deallocate(model%v_conv2_weights)
        if (allocated(model%v_conv2_bias)) deallocate(model%v_conv2_bias)
        if (allocated(model%v_conv3_weights)) deallocate(model%v_conv3_weights)
        if (allocated(model%v_conv3_bias)) deallocate(model%v_conv3_bias)

        ! FC layers - first moments
        if (allocated(model%m_fc1_weights)) deallocate(model%m_fc1_weights)
        if (allocated(model%m_fc1_bias)) deallocate(model%m_fc1_bias)
        if (allocated(model%m_fc2_weights)) deallocate(model%m_fc2_weights)
        if (allocated(model%m_fc2_bias)) deallocate(model%m_fc2_bias)
        if (allocated(model%m_fc3_weights)) deallocate(model%m_fc3_weights)
        if (allocated(model%m_fc3_bias)) deallocate(model%m_fc3_bias)

        ! FC layers - second moments
        if (allocated(model%v_fc1_weights)) deallocate(model%v_fc1_weights)
        if (allocated(model%v_fc1_bias)) deallocate(model%v_fc1_bias)
        if (allocated(model%v_fc2_weights)) deallocate(model%v_fc2_weights)
        if (allocated(model%v_fc2_bias)) deallocate(model%v_fc2_bias)
        if (allocated(model%v_fc3_weights)) deallocate(model%v_fc3_weights)
        if (allocated(model%v_fc3_bias)) deallocate(model%v_fc3_bias)

        ! Batch norm - first moments
        if (allocated(model%m_bn1_scale)) deallocate(model%m_bn1_scale)
        if (allocated(model%m_bn1_bias)) deallocate(model%m_bn1_bias)
        if (allocated(model%m_bn2_scale)) deallocate(model%m_bn2_scale)
        if (allocated(model%m_bn2_bias)) deallocate(model%m_bn2_bias)
        if (allocated(model%m_bn3_scale)) deallocate(model%m_bn3_scale)
        if (allocated(model%m_bn3_bias)) deallocate(model%m_bn3_bias)

        ! Batch norm - second moments
        if (allocated(model%v_bn1_scale)) deallocate(model%v_bn1_scale)
        if (allocated(model%v_bn1_bias)) deallocate(model%v_bn1_bias)
        if (allocated(model%v_bn2_scale)) deallocate(model%v_bn2_scale)
        if (allocated(model%v_bn2_bias)) deallocate(model%v_bn2_bias)
        if (allocated(model%v_bn3_scale)) deallocate(model%v_bn3_scale)
        if (allocated(model%v_bn3_bias)) deallocate(model%v_bn3_bias)

        print *, "‚úÖ Adam optimizer state cleaned up"

        ! ‚úÖ Cleanup FC3
        if (allocated(model%fc3_weights)) deallocate(model%fc3_weights)
        if (allocated(model%fc3_bias)) deallocate(model%fc3_bias)
        if (allocated(model%fc3_out)) deallocate(model%fc3_out)
        if (allocated(model%grad_fc3_weights)) deallocate(model%grad_fc3_weights)
        if (allocated(model%grad_fc3_bias)) deallocate(model%grad_fc3_bias)

        ! ‚úÖ Cleanup intermediate FC states
        if (allocated(model%fc1_relu)) deallocate(model%fc1_relu)
        if (allocated(model%fc1_dropout)) deallocate(model%fc1_dropout)
        if (allocated(model%fc2_relu)) deallocate(model%fc2_relu)
        if (allocated(model%fc2_dropout)) deallocate(model%fc2_dropout)

        ! ‚úÖ Cleanup dropout
        if (allocated(model%dropout_states)) deallocate(model%dropout_states)
        if (allocated(model%fc1_dropout_reserve)) deallocate(model%fc1_dropout_reserve)
        if (allocated(model%fc2_dropout_reserve)) deallocate(model%fc2_dropout_reserve)
        if (c_associated(model%dropout_desc)) then
            stat = cudnnDestroyDropoutDescriptor(model%dropout_desc)
        endif

        print *, "‚úÖ Model cleanup completed successfully"
    end subroutine cleanup_model

    subroutine cleanup_cudnn_cublas()
        integer :: stat

        stat = cudnnDestroy(cudnn_handle)
        stat = cublasDestroy_v2(cublas_handle)

        print *, "‚úÖ cuDNN and cuBLAS cleaned up"
    end subroutine cleanup_cudnn_cublas
end module cudnn_cifar10

program cifar10_cudnn10_apex_training
    use cudafor
    use cudnn_cifar10
    use svhn_data_module
    use curand_wrapper_module
    use apex_adam_kernels  ! NVIDIA Apex FusedAdam reference implementation
    use cuda_batch_state, only: set_scheduling_mode  ! v28: Blocking synchronization
    use gpu_batch_extraction  ! v28: GPU-only batch extraction
    use model_export  ! v28: Model export functionality
    implicit none

    type(cnn_model) :: model
    real(4), device, allocatable :: batch_data(:,:)
    integer, device, allocatable :: batch_labels(:)
    real(4), device, allocatable :: grad_output(:,:)

    ! Training parameters
    real(4) :: learning_rate, initial_lr
    integer :: num_epochs, epoch, batch, num_batches
    integer :: batch_start, batch_end
    integer :: i  ! Loop variable for initialization

    ! Metrics
    real(4) :: train_loss, train_acc, test_loss, test_acc, best_test_acc
    real(4) :: epoch_time, total_time
    integer(8) :: start_time, end_time, time_freq
    logical :: success
    integer(8) :: dummy_count, dummy_max

    ! StepLR scheduler parameters (matching Python reference)
    integer, parameter :: step_size = 10      ! Reduce LR every 10 epochs
    real(4), parameter :: gamma = 0.5         ! Multiply LR by 0.5
    real(4), parameter :: min_lr = 1e-6       ! Minimum LR threshold

    ! Configuration
    num_epochs = 15
    ! Configuration matches Python reference
    ! Python reference achieves ~70-80% with LR=0.001 and LeakyReLU(0.01)
    initial_lr = 0.001
    learning_rate = initial_lr
    best_test_acc = 0.0
    total_time = 0.0

    ! ========================================================================
    ! INITIALIZATION
    ! ========================================================================
    print *, ""
    print *, "üöÄ SVHN CNN Training with cuDNN"
    print *, "======================================"
    print *, "üìä Configuration:"
    print *, "   Epochs:", num_epochs
    print *, "   Batch size:", BATCH_SIZE
    print *, "   Learning rate:", learning_rate
    print *, "   Optimizer: Adam (beta1=0.9, beta2=0.999, decay=1e-4)"
    print *, "   Activation: LeakyReLU(0.01)"
    print *, "   LR Scheduler: StepLR (step_size=10, gamma=0.5)"
    print *, "   Data Shuffle: Enabled (every epoch)"
    print *, ""

    call init_cudnn_cublas()
    call initialize_curand_wrapper(42_8)  ! Initialize cuRAND with seed=42
    call load_svhn_data()
    ! v28: Initialize GPU-resident shuffle indices (eliminates host shuffle)
    call initialize_shuffle_indices(train_samples)
    call create_model(model, BATCH_SIZE)

    ! Allocate batch arrays
    allocate(batch_data(BATCH_SIZE, input_size))
    allocate(batch_labels(BATCH_SIZE))
    allocate(grad_output(BATCH_SIZE, CNN_NUM_CLASSES))

    num_batches = train_samples / BATCH_SIZE
    call system_clock(dummy_count, time_freq, dummy_max)

    if (time_freq == 0) then
        print *, "‚ö†Ô∏è  WARNING: system_clock frequency is zero, using fallback"
        time_freq = 1000  ! 1000 ticks/second fallback
    else
        !print *, "‚è±Ô∏è  System clock frequency:", time_freq, "ticks/second"
    endif

    ! ========================================================================
    ! MAIN TRAINING LOOP
    ! ========================================================================
    do epoch = 1, num_epochs
        ! Print epoch header (matching Python format)
        print *, ""
        print '(A,I2,A,I2)', "üìà EPOCH ", epoch, "/", num_epochs
        print *, "------------------------------------------------------------"

        call system_clock(start_time)

        ! v28: Shuffle GPU-resident indices (no host involvement, matching Python shuffle=True)
        call shuffle_indices(train_samples)

        ! ====================================================================
        ! TRAINING PHASE
        ! ====================================================================
        call train_epoch(model, batch_data, batch_labels, grad_output, &
                        learning_rate, num_batches, train_loss, train_acc, success)

        if (.not. success) then
            print *, "‚ùå Training failed at epoch", epoch
            stop
        endif

        ! ====================================================================
        ! EVALUATION PHASE
        ! ====================================================================
        call evaluate_epoch(model, batch_data, batch_labels, &
                           test_loss, test_acc, success)

        if (.not. success) then
            print *, "‚ùå Evaluation failed at epoch", epoch
            stop
        endif

        ! ====================================================================
        ! METRICS AND LOGGING
        ! ====================================================================
        call system_clock(end_time)
        epoch_time = real(end_time - start_time) / real(time_freq)
        total_time = total_time + epoch_time

        ! Print test results (matching Python format)
        print '(A,F6.2,A)', "   Test Accuracy: ", test_acc, "%"
        print '(A,F6.4)', "   Test Loss: ", test_loss

        ! Update best accuracy
        if (test_acc > best_test_acc) then
            best_test_acc = test_acc
            print '(A,F6.2,A)', "üíæ New best accuracy: ", test_acc, "%"
        endif

        ! Print learning rate (matching Python format)
        print '(A,F9.6)', "üìâ Learning rate: ", learning_rate

        ! ====================================================================
        ! BATCHNORM DIAGNOSTICS (monitoring running statistics)
        ! ====================================================================
        ! Print BN1 running statistics to detect if they're being updated
        block
            real(4), allocatable :: host_bn_mean(:), host_bn_var(:), host_bn_scale(:)
            allocate(host_bn_mean(32), host_bn_var(32), host_bn_scale(32))

            ! Copy BN1 running stats to host
            host_bn_mean = model%bn1_running_mean
            host_bn_var = model%bn1_running_var
            host_bn_scale = model%bn1_scale

            print '(A,3F8.4)', "üî¨ BN1 running_mean[1:3]: ", host_bn_mean(1:3)
            print '(A,3F8.4)', "üî¨ BN1 running_var[1:3]:  ", host_bn_var(1:3)
            print '(A,3F8.4)', "üî¨ BN1 running_var[13,21,30] (OUTLIERS): ", &
                host_bn_var(13), host_bn_var(21), host_bn_var(30)
            print '(A,3F8.4)', "üî¨ BN1 scale[13,21,30] (gamma): ", &
                host_bn_scale(13), host_bn_scale(21), host_bn_scale(30)

            ! üîç DETAILED DIAGNOSTIC: After epoch 1, print full BN1 stats for comparison with Python
            if (epoch == 1) then
                print *, ""
                print *, "üî¨ DETAILED BatchNorm Diagnostics (Epoch 1):"
                print *, "   BN1 running_mean (all 32 channels):"
                print '(8F9.4)', host_bn_mean
                print *, "   BN1 running_var (all 32 channels):"
                print '(8F9.4)', host_bn_var
                print *, "   Expected: mean ‚âà 0.0, var ‚âà 0.9-1.1 for most channels"
                print *, ""
            endif

            deallocate(host_bn_mean, host_bn_var, host_bn_scale)
        end block

        print *, "------------------------------------------------------------"

        ! ====================================================================
        ! STEP LR SCHEDULER (matching Python reference)
        ! ====================================================================
        ! Reduce learning rate every 'step_size' epochs
        if (mod(epoch, step_size) == 0 .and. learning_rate > min_lr) then
            learning_rate = learning_rate * gamma
        endif
    end do

    ! ========================================================================
    ! FINAL SUMMARY
    ! ========================================================================
    print *, ""
    print *, "üéâ TRAINING COMPLETED!"
    print *, "======================"
    print '(A,F6.2,A)', "üèÜ Best Test Accuracy: ", best_test_acc, "%"
    print '(A,F6.2,A)', "üìä Final Train Accuracy: ", train_acc, "%"
    print '(A,F6.2,A)', "üìä Final Test Accuracy: ", test_acc, "%"
    print '(A,F7.1,A)', "‚è±Ô∏è  Total Time: ", total_time, "s"
    print '(A,F6.1,A)', "‚è±Ô∏è  Avg Time/Epoch: ", total_time/num_epochs, "s"
    print *, ""

    ! Performance evaluation
    print *, "üìä Performance Analysis:"
    print *, "   Expected (Python ref): ~70-80%"
    print '(A,F6.2,A)', "   Achieved (cuDNN): ", best_test_acc, "%"

    if (best_test_acc >= 70.0) then
        print *, "‚úÖ EXCELLENT! Matches Python reference"
    else if (best_test_acc >= 50.0) then
        print *, "üìà GOOD! Model is learning - may need more epochs"
    else
        print *, "‚ö†Ô∏è  Needs improvement - check hyperparameters"
    endif
    print *, ""

    ! ========================================================================
    ! EXPORT MODEL FOR INFERENCE
    ! ========================================================================
    call create_export_directory("saved_models/svhn/", &
                                 "SVHN", &
                                 best_test_acc, &
                                 num_epochs, &
                                 "2025-11-17")

    call export_model_generic("saved_models/svhn/", &
        model%conv1_weights, model%conv1_bias, &
        model%conv2_weights, model%conv2_bias, &
        model%conv3_weights, model%conv3_bias, &
        model%fc1_weights, model%fc1_bias, &
        model%fc2_weights, model%fc2_bias, &
        model%fc3_weights, model%fc3_bias, &
        model%bn1_scale, model%bn1_bias, model%bn1_running_mean, model%bn1_running_var, &
        model%bn2_scale, model%bn2_bias, model%bn2_running_mean, model%bn2_running_var, &
        model%bn3_scale, model%bn3_bias, model%bn3_running_mean, model%bn3_running_var)

    ! Cleanup
    call cleanup_model(model)
    call cleanup_cudnn_cublas()
    deallocate(batch_data, batch_labels, grad_output)
contains
    ! ========================================================================
    ! SHUFFLE ARRAY (Fisher-Yates algorithm)
    ! Matches Python DataLoader shuffle=True behavior
    ! ========================================================================
    subroutine shuffle_array(array, n)
        integer, intent(inout) :: array(:)
        integer, intent(in) :: n
        integer :: i, j, temp
        real(4) :: r

        ! Fisher-Yates shuffle algorithm
        do i = n, 2, -1
            ! Generate random integer j in range [1, i]
            call random_number(r)
            j = 1 + int(r * real(i))

            ! Swap array(i) and array(j)
            temp = array(i)
            array(i) = array(j)
            array(j) = temp
        end do
    end subroutine shuffle_array

    ! ========================================================================
    ! COMPUTE LOSS GRADIENT (Softmax + Cross-Entropy)
    ! ========================================================================
    ! Fix for compute_loss_gradient
    subroutine compute_loss_gradient(probs, labels, grad, batch_size)
        real(4), device, intent(in) :: probs(:,:)
        integer, device, intent(in) :: labels(:)
        real(4), device, intent(out) :: grad(:,:)
        integer, intent(in) :: batch_size
        integer :: i, j

        ! Remove scaling - cross entropy loss already normalizes by batch size
        !$cuf kernel do(2)
        do i = 1, batch_size
            do j = 1, CNN_NUM_CLASSES
                if (j == labels(i) + 1) then
                    grad(i, j) = probs(i, j) - 1.0  ! For correct class
                else
                    grad(i, j) = probs(i, j)        ! For incorrect classes
                end if
            end do
        end do
    end subroutine

    ! ========================================================================
    ! TRAIN ONE EPOCH
    ! ========================================================================
    subroutine train_epoch(model, batch_data, batch_labels, grad_output, &
                          lr, num_batches, epoch_loss, epoch_acc, success)
        type(cnn_model), intent(inout) :: model
        real(4), device, intent(inout) :: batch_data(:,:)
        integer, device, intent(inout) :: batch_labels(:)
        real(4), device, intent(inout) :: grad_output(:,:)
        real(4), intent(in) :: lr
        integer, intent(in) :: num_batches
        real(4), intent(out) :: epoch_loss, epoch_acc
        logical, intent(out) :: success

        integer :: batch
        real(4) :: batch_loss, batch_accuracy
        real(4) :: loss_sum
        integer :: correct_total, total_samples

        success = .false.
        loss_sum = 0.0
        correct_total = 0
        total_samples = 0

        do batch = 1, num_batches
            ! v28: GPU-only batch extraction (no D2H/H2D transfers!)
            ! This eliminates 600MB of transfers per epoch
            call extract_training_batch_gpu(gpu_train_data, gpu_train_labels, &
                                           batch_data, batch_labels, &
                                           batch, BATCH_SIZE, train_samples, input_size)

            ! ‚úÖ UPDATED: Forward pass in TRAINING mode
            call forward_pass(model, batch_data, BATCH_SIZE, .true.)

            ! Compute gradients
            call compute_loss_gradient(model%softmax_out, batch_labels, grad_output, BATCH_SIZE)

            ! Backward pass and update
            call backward_pass(model, grad_output, BATCH_SIZE, lr, .true.)  ! Training mode

            ! In train_epoch, after backward_pass on first batch
            !if (epoch == 1 .and. batch == 1) then
            !    block
            !        real(4) :: fc3_grad_check(5), conv1_grad_check(5)
            !        real(4) :: fc3_grad_norm, conv1_grad_norm

            !        fc3_grad_check = model%grad_fc3_weights(1, 1:5)
            !        conv1_grad_check = model%grad_conv1_weights(1, 1, 1, 1:5)

            !        print *, "üîç Gradient diagnostics:"
            !        print *, "   FC3 weight grads:", fc3_grad_check
            !        print *, "   Conv1 weight grads:", conv1_grad_check

            !        ! Compute approximate gradient norms
            !        fc3_grad_norm = sqrt(sum(fc3_grad_check**2))
            !        conv1_grad_norm = sqrt(sum(conv1_grad_check**2))

            !        print *, "   FC3 grad norm:", fc3_grad_norm
            !        print *, "   Conv1 grad norm:", conv1_grad_norm

            !        if (fc3_grad_norm < 1e-6) then
            !            print *, "‚ùå FC3 gradients too small!"
            !        endif
            !    end block
            !endif
            ! Note: Weight updates are verified in the detailed Adam output above
            ! The actual_delta shows weights ARE changing correctly

            ! Compute batch metrics
            call compute_metrics(model, batch_labels, BATCH_SIZE, batch_loss, batch_accuracy)

            ! Accumulate
            loss_sum = loss_sum + batch_loss * BATCH_SIZE
            correct_total = correct_total + int(batch_accuracy * BATCH_SIZE / 100.0)
            total_samples = total_samples + BATCH_SIZE

            ! Per-batch logging (matching Python format: every 100 batches + first batch)
            if (batch == 1 .or. mod(batch, 100) == 0) then
                ! Compute cumulative accuracy up to this batch
                print '(A,I3,A,I3,A,F8.6,A,F6.3,A)', &
                    "   Batch ", batch-1, "/", num_batches, &
                    " Loss: ", batch_loss, &
                    " Acc: ", batch_accuracy, "%"
            endif
        end do

        ! Compute epoch averages
        epoch_loss = loss_sum / real(total_samples)
        epoch_acc = real(correct_total) / real(total_samples) * 100.0

        success = .true.
    end subroutine train_epoch

    ! ========================================================================
    ! EVALUATE ON TEST SET
    ! ========================================================================
    subroutine evaluate_epoch(model, batch_data, batch_labels, &
                             epoch_loss, epoch_acc, success)
        type(cnn_model), intent(inout) :: model
        real(4), device, intent(inout) :: batch_data(:,:)
        integer, device, intent(inout) :: batch_labels(:)
        real(4), intent(out) :: epoch_loss, epoch_acc
        logical, intent(out) :: success

        integer :: batch, num_test_batches, batch_start, batch_end, actual_batch_size
        real(4) :: batch_loss, batch_accuracy
        real(4) :: loss_sum
        integer :: correct_total, total_samples

        ! Per-class accuracy tracking (with proper D2H copy)
        integer :: class_correct(10), class_total(10)
        integer :: i, j, predicted_class, true_class
        real(4), allocatable :: host_softmax(:,:)
        integer, allocatable :: host_labels(:)
        real(4) :: max_prob
        character(len=8) :: class_names(10)

        ! SVHN class names
        data class_names /'plane', 'car', 'bird', 'cat', 'deer', &
                          'dog', 'frog', 'horse', 'ship', 'truck'/

        success = .false.
        loss_sum = 0.0
        correct_total = 0
        total_samples = 0
        class_correct = 0
        class_total = 0

        ! Allocate host arrays for per-class tracking
        allocate(host_softmax(BATCH_SIZE, 10))
        allocate(host_labels(BATCH_SIZE))

        num_test_batches = (test_samples + BATCH_SIZE - 1) / BATCH_SIZE

        do batch = 1, num_test_batches
            ! v28: GPU-only test batch extraction (no shuffling for test data)
            call extract_test_batch_gpu(gpu_test_data, gpu_test_labels, &
                                       batch_data, batch_labels, &
                                       batch, BATCH_SIZE, test_samples, actual_batch_size)

            ! ‚úÖ UPDATED: Forward pass in INFERENCE mode (uses learned running stats)
            call forward_pass(model, batch_data, actual_batch_size, .false.)

            ! Compute batch metrics
            call compute_metrics(model, batch_labels, actual_batch_size, batch_loss, batch_accuracy)

            ! Copy device arrays to host for per-class tracking (CRITICAL: copy entire arrays at once!)
            host_softmax(1:actual_batch_size, :) = model%softmax_out(1:actual_batch_size, :)
            host_labels(1:actual_batch_size) = batch_labels(1:actual_batch_size)

            ! Track per-class accuracy on HOST
            do i = 1, actual_batch_size
                true_class = host_labels(i) + 1  ! Convert 0-based to 1-based

                ! Find predicted class
                max_prob = host_softmax(i, 1)
                predicted_class = 1
                do j = 2, 10
                    if (host_softmax(i, j) > max_prob) then
                        max_prob = host_softmax(i, j)
                        predicted_class = j
                    endif
                end do

                ! Update per-class counts
                class_total(true_class) = class_total(true_class) + 1
                if (predicted_class == true_class) then
                    class_correct(true_class) = class_correct(true_class) + 1
                endif
            end do

            ! Accumulate
            loss_sum = loss_sum + batch_loss * actual_batch_size
            correct_total = correct_total + int(batch_accuracy * actual_batch_size / 100.0)
            total_samples = total_samples + actual_batch_size
        end do

        ! Compute epoch averages
        epoch_loss = loss_sum / real(total_samples)
        epoch_acc = real(correct_total) / real(total_samples) * 100.0

        ! Print per-class accuracy (matching Python format)
        do i = 1, 10
            if (class_total(i) > 0) then
                print '(A,A8,A,F6.2,A)', &
                    "    ", class_names(i), ":  ", &
                    100.0 * real(class_correct(i)) / real(class_total(i)), "%"
            endif
        end do

        ! Cleanup
        deallocate(host_softmax, host_labels)

        success = .true.
    end subroutine evaluate_epoch

    subroutine cleanup_resources()
        call cleanup_curand_wrapper()
        ! Add other cleanup here if needed
    end subroutine cleanup_resources
end program cifar10_cudnn10_apex_training
! nvfortran -cuda -O3 cifar10_cudnn26.cuf -o cifar10_cudnn26 -lcublas -lcudart -lcudnn -lcurand
! nvfortran -cuda -O3 cifar10_cudnn26.cuf -o cifar10_cudnn26 -gpu=cc86 -lcublas -lcudart -lcudnn -L/var/home/fraser/nvidia/hpc_sdk/Linux_x86_64/25.7/cuda/12.9/targets/x86_64-linux/lib
! Version 8: Added per-batch logging and weight initialization diagnostics
! Version 9: Added per-class accuracy logging
! Version 10: Added reference Apex adam implementation
! Version 14: fixing row/column major order bugs (fixed outlier issue, improved performance).
! Version 26: REFERENCE: fixed the batch norm transposition errors plaguing previous versions with Julia inspired structure that
! uses cuDNN transposition without requiring costly manual transposition.
