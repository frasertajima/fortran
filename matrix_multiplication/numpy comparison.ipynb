{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy (CPU), CuPy, pytorch (both GPU) and scikit-learn versions. Compare against CUDA Fortran matrix multiplication (which started at 350Gflops and hit 3,000Gflops). Numpy is hitting 266Gflops max, pytorch is hitting 107Gflops max on RTX 4060!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Configuration:\n",
      "  Version: 2.0.2\n",
      "Build Dependencies:\n",
      "  blas:\n",
      "    detection method: pkgconfig\n",
      "    found: true\n",
      "    include directory: /opt/_internal/cpython-3.12.2/lib/python3.12/site-packages/scipy_openblas64/include\n",
      "    lib directory: /opt/_internal/cpython-3.12.2/lib/python3.12/site-packages/scipy_openblas64/lib\n",
      "    name: scipy-openblas\n",
      "    openblas configuration: OpenBLAS 0.3.27  USE64BITINT DYNAMIC_ARCH NO_AFFINITY\n",
      "      Zen MAX_THREADS=64\n",
      "    pc file directory: /project/.openblas\n",
      "    version: 0.3.27\n",
      "  lapack:\n",
      "    detection method: pkgconfig\n",
      "    found: true\n",
      "    include directory: /opt/_internal/cpython-3.12.2/lib/python3.12/site-packages/scipy_openblas64/include\n",
      "    lib directory: /opt/_internal/cpython-3.12.2/lib/python3.12/site-packages/scipy_openblas64/lib\n",
      "    name: scipy-openblas\n",
      "    openblas configuration: OpenBLAS 0.3.27  USE64BITINT DYNAMIC_ARCH NO_AFFINITY\n",
      "      Zen MAX_THREADS=64\n",
      "    pc file directory: /project/.openblas\n",
      "    version: 0.3.27\n",
      "Compilers:\n",
      "  c:\n",
      "    commands: cc\n",
      "    linker: ld.bfd\n",
      "    name: gcc\n",
      "    version: 10.2.1\n",
      "  c++:\n",
      "    commands: c++\n",
      "    linker: ld.bfd\n",
      "    name: gcc\n",
      "    version: 10.2.1\n",
      "  cython:\n",
      "    commands: cython\n",
      "    linker: cython\n",
      "    name: cython\n",
      "    version: 3.0.11\n",
      "Machine Information:\n",
      "  build:\n",
      "    cpu: x86_64\n",
      "    endian: little\n",
      "    family: x86_64\n",
      "    system: linux\n",
      "  host:\n",
      "    cpu: x86_64\n",
      "    endian: little\n",
      "    family: x86_64\n",
      "    system: linux\n",
      "Python Information:\n",
      "  path: /tmp/build-env-8744k94k/bin/python\n",
      "  version: '3.12'\n",
      "SIMD Extensions:\n",
      "  baseline:\n",
      "  - SSE\n",
      "  - SSE2\n",
      "  - SSE3\n",
      "  found:\n",
      "  - SSSE3\n",
      "  - SSE41\n",
      "  - POPCNT\n",
      "  - SSE42\n",
      "  - AVX\n",
      "  - F16C\n",
      "  - FMA3\n",
      "  - AVX2\n",
      "  not found:\n",
      "  - AVX512F\n",
      "  - AVX512CD\n",
      "  - AVX512_KNL\n",
      "  - AVX512_KNM\n",
      "  - AVX512_SKX\n",
      "  - AVX512_CLX\n",
      "  - AVX512_CNL\n",
      "  - AVX512_ICL\n",
      "\n",
      "  BLAS Info: None\n",
      "\n",
      "Performing warmup runs...\n",
      "Performing timing runs...\n",
      "Run  1 - Time:  1271.56 ms, Performance:   211.11 GFLOPS\n",
      "Run  2 - Time:  1202.47 ms, Performance:   223.24 GFLOPS\n",
      "Run  3 - Time:  1241.98 ms, Performance:   216.14 GFLOPS\n",
      "Run  4 - Time:  1101.57 ms, Performance:   243.68 GFLOPS\n",
      "Run  5 - Time:  1240.68 ms, Performance:   216.36 GFLOPS\n",
      "Run  6 - Time:  1393.39 ms, Performance:   192.65 GFLOPS\n",
      "Run  7 - Time:  1101.60 ms, Performance:   243.68 GFLOPS\n",
      "Run  8 - Time:  1189.49 ms, Performance:   225.67 GFLOPS\n",
      "Run  9 - Time:  1177.44 ms, Performance:   227.98 GFLOPS\n",
      "Run 10 - Time:  1150.93 ms, Performance:   233.23 GFLOPS\n",
      "\n",
      "Performance Results (10 runs):\n",
      "  Minimum:     192.65 GFLOPS\n",
      "  Maximum:     243.68 GFLOPS\n",
      "  Average:     223.37 GFLOPS\n",
      "  Std Dev:      14.64 GFLOPS\n",
      "\n",
      "Average execution time: 1207.11 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_gflops(M, N, K, time_seconds):\n",
    "    \"\"\"Calculate GFLOPS (billion floating point operations per second)\"\"\"\n",
    "    # Same formula as CUDA version: 2 * M * N * K operations (multiply-add)\n",
    "    flops = 2.0 * float(M) * float(N) * float(K)\n",
    "    gflops = (flops / 1e9) / time_seconds\n",
    "    return gflops\n",
    "\n",
    "def benchmark_matmul(M=5120, N=5120, K=5120, num_runs=10, num_warmup=5):\n",
    "    \"\"\"Benchmark matrix multiplication using NumPy\"\"\"\n",
    "    \n",
    "    # Initialize matrices with random values (same as CUDA version)\n",
    "    A = np.random.random((M, K)).astype(np.float64)  # Using float64 to match CUDA double precision\n",
    "    B = np.random.random((K, N)).astype(np.float64)\n",
    "    \n",
    "    # Warmup runs\n",
    "    print(\"Performing warmup runs...\")\n",
    "    for _ in range(num_warmup):\n",
    "        C = np.matmul(A, B)\n",
    "    \n",
    "    # Performance measurement runs\n",
    "    print(\"Performing timing runs...\")\n",
    "    times = []\n",
    "    gflops_array = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        # Time the matrix multiplication\n",
    "        start_time = time.perf_counter()\n",
    "        C = np.matmul(A, B)\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        # Calculate timing and performance\n",
    "        exec_time = end_time - start_time\n",
    "        gflops = calculate_gflops(M, N, K, exec_time)\n",
    "        \n",
    "        times.append(exec_time)\n",
    "        gflops_array.append(gflops)\n",
    "        \n",
    "        print(f\"Run {run + 1:2d} - Time: {exec_time*1000:8.2f} ms, Performance: {gflops:8.2f} GFLOPS\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    min_gflops = min(gflops_array)\n",
    "    max_gflops = max(gflops_array)\n",
    "    avg_gflops = sum(gflops_array) / len(gflops_array)\n",
    "    std_gflops = np.std(gflops_array)\n",
    "    \n",
    "    # Print results in similar format to CUDA version\n",
    "    print(\"\\nPerformance Results ({:d} runs):\".format(num_runs))\n",
    "    print(f\"  Minimum: {min_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Maximum: {max_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Average: {avg_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Std Dev: {std_gflops:10.2f} GFLOPS\")\n",
    "    \n",
    "    # Print average time in milliseconds\n",
    "    avg_time_ms = np.mean(times) * 1000\n",
    "    print(f\"\\nAverage execution time: {avg_time_ms:.2f} ms\")\n",
    "    \n",
    "    return {\n",
    "        'min_gflops': min_gflops,\n",
    "        'max_gflops': max_gflops,\n",
    "        'avg_gflops': avg_gflops,\n",
    "        'std_gflops': std_gflops,\n",
    "        'times_ms': np.array(times) * 1000\n",
    "    }\n",
    "\n",
    "# Run the benchmark\n",
    "if __name__ == \"__main__\":\n",
    "    # Print NumPy configuration\n",
    "    print(\"NumPy Configuration:\")\n",
    "    print(f\"  Version: {np.__version__}\")\n",
    "    print(f\"  BLAS Info: {np.__config__.show()}\")\n",
    "    print()\n",
    "    \n",
    "    # Run benchmark\n",
    "    results = benchmark_matmul(\n",
    "        M=5120, \n",
    "        N=5120, \n",
    "        K=5120, \n",
    "        num_runs=10, \n",
    "        num_warmup=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy GPU Configuration:\n",
      "  Device: NVIDIA GeForce RTX 4060\n",
      "  Memory: 8.2 GB\n",
      "  Matrix Size: 5120x5120\n",
      "\n",
      "Initializing matrices...\n",
      "Performing warmup runs...\n",
      "\n",
      "Performing timing runs...\n",
      "Run  1 - Time:  1304.91 ms, Performance:   205.71 GFLOPS\n",
      "Run  2 - Time:  1311.88 ms, Performance:   204.62 GFLOPS\n",
      "Run  3 - Time:  1297.96 ms, Performance:   206.81 GFLOPS\n",
      "Run  4 - Time:  1305.07 ms, Performance:   205.69 GFLOPS\n",
      "Run  5 - Time:  1290.61 ms, Performance:   207.99 GFLOPS\n",
      "Run  6 - Time:  1282.92 ms, Performance:   209.24 GFLOPS\n",
      "Run  7 - Time:  1277.91 ms, Performance:   210.06 GFLOPS\n",
      "Run  8 - Time:  1281.27 ms, Performance:   209.51 GFLOPS\n",
      "Run  9 - Time:  1230.59 ms, Performance:   218.13 GFLOPS\n",
      "Run 10 - Time:  1258.79 ms, Performance:   213.25 GFLOPS\n",
      "\n",
      "Performance Results (10 runs):\n",
      "  Minimum:     204.62 GFLOPS\n",
      "  Maximum:     218.13 GFLOPS\n",
      "  Average:     209.10 GFLOPS\n",
      "  Std Dev:       3.87 GFLOPS\n",
      "\n",
      "Average execution time: 1284.19 ms\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_gflops(M, N, K, time_seconds):\n",
    "    \"\"\"Calculate GFLOPS (billion floating point operations per second)\"\"\"\n",
    "    flops = 2.0 * float(M) * float(N) * float(K)\n",
    "    gflops = (flops / 1e9) / time_seconds\n",
    "    return gflops\n",
    "\n",
    "def benchmark_matmul_gpu():\n",
    "    # Matrix dimensions\n",
    "    M = N = K = 5120\n",
    "    NUM_RUNS = 10\n",
    "    NUM_WARMUP = 5\n",
    "    \n",
    "    print(\"CuPy GPU Configuration:\")\n",
    "    print(f\"  Device: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}\")\n",
    "    print(f\"  Memory: {cp.cuda.runtime.memGetInfo()[1] / 1e9:.1f} GB\")\n",
    "    print(f\"  Matrix Size: {M}x{M}\")\n",
    "    print()\n",
    "    \n",
    "    # Initialize matrices on CPU then transfer to GPU\n",
    "    print(\"Initializing matrices...\")\n",
    "    A_cpu = np.random.random((M, K)).astype(np.float64)\n",
    "    B_cpu = np.random.random((K, N)).astype(np.float64)\n",
    "    \n",
    "    # Transfer to GPU\n",
    "    A = cp.array(A_cpu)\n",
    "    B = cp.array(B_cpu)\n",
    "    \n",
    "    # Warmup runs\n",
    "    print(\"Performing warmup runs...\")\n",
    "    for i in range(NUM_WARMUP):\n",
    "        C = cp.matmul(A, B)\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "    \n",
    "    # Performance measurement runs\n",
    "    print(\"\\nPerforming timing runs...\")\n",
    "    times = []\n",
    "    gflops_array = []\n",
    "    \n",
    "    for run in range(NUM_RUNS):\n",
    "        # Create CUDA events for timing\n",
    "        start_event = cp.cuda.Event()\n",
    "        end_event = cp.cuda.Event()\n",
    "        \n",
    "        # Record start event\n",
    "        start_event.record()\n",
    "        \n",
    "        # Perform matrix multiplication\n",
    "        C = cp.matmul(A, B)\n",
    "        \n",
    "        # Record end event and synchronize\n",
    "        end_event.record()\n",
    "        end_event.synchronize()\n",
    "        \n",
    "        # Calculate elapsed time in milliseconds\n",
    "        elapsed_time_ms = cp.cuda.get_elapsed_time(start_event, end_event)\n",
    "        elapsed_time_s = elapsed_time_ms / 1000.0  # Convert to seconds\n",
    "        \n",
    "        # Calculate GFLOPS\n",
    "        gflops = calculate_gflops(M, N, K, elapsed_time_s)\n",
    "        \n",
    "        times.append(elapsed_time_ms)\n",
    "        gflops_array = np.append(gflops_array if len(gflops_array) > 0 else [], gflops)\n",
    "        \n",
    "        print(f\"Run {run + 1:2d} - Time: {elapsed_time_ms:8.2f} ms, Performance: {gflops:8.2f} GFLOPS\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    min_gflops = np.min(gflops_array)\n",
    "    max_gflops = np.max(gflops_array)\n",
    "    avg_gflops = np.mean(gflops_array)\n",
    "    std_gflops = np.std(gflops_array)\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"\\nPerformance Results ({:d} runs):\".format(NUM_RUNS))\n",
    "    print(f\"  Minimum: {min_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Maximum: {max_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Average: {avg_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Std Dev: {std_gflops:10.2f} GFLOPS\")\n",
    "    \n",
    "    # Print average time\n",
    "    avg_time_ms = np.mean(times)\n",
    "    print(f\"\\nAverage execution time: {avg_time_ms:.2f} ms\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    del A, B, C\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    \n",
    "    return {\n",
    "        'min_gflops': min_gflops,\n",
    "        'max_gflops': max_gflops,\n",
    "        'avg_gflops': avg_gflops,\n",
    "        'std_gflops': std_gflops,\n",
    "        'times_ms': times\n",
    "    }\n",
    "\n",
    "# Run the benchmark\n",
    "if __name__ == \"__main__\":\n",
    "    results = benchmark_matmul_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Running on GPU.\n",
      "\n",
      "PyTorch Configuration:\n",
      "  PyTorch Version: 2.5.1+cu124\n",
      "  Device: NVIDIA GeForce RTX 4060\n",
      "  CUDA Version: 12.4\n",
      "  Matrix Size: 5120x5120\n",
      "\n",
      "Initializing matrices...\n",
      "Performing warmup runs...\n",
      "\n",
      "Performing timing runs...\n",
      "Run  1 - Time:  1295.15 ms, Performance:   207.26 GFLOPS\n",
      "Run  2 - Time:  1312.47 ms, Performance:   204.53 GFLOPS\n",
      "Run  3 - Time:  1309.67 ms, Performance:   204.96 GFLOPS\n",
      "Run  4 - Time:  1306.22 ms, Performance:   205.50 GFLOPS\n",
      "Run  5 - Time:  1297.24 ms, Performance:   206.93 GFLOPS\n",
      "Run  6 - Time:  1294.98 ms, Performance:   207.29 GFLOPS\n",
      "Run  7 - Time:  1297.62 ms, Performance:   206.87 GFLOPS\n",
      "Run  8 - Time:  1289.60 ms, Performance:   208.15 GFLOPS\n",
      "Run  9 - Time:  1291.38 ms, Performance:   207.87 GFLOPS\n",
      "Run 10 - Time:  1260.45 ms, Performance:   212.97 GFLOPS\n",
      "\n",
      "Performance Results (10 runs):\n",
      "  Minimum:     204.53 GFLOPS\n",
      "  Maximum:     212.97 GFLOPS\n",
      "  Average:     207.23 GFLOPS\n",
      "  Std Dev:       2.23 GFLOPS\n",
      "\n",
      "Average execution time: 1295.48 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_gflops(M, N, K, time_seconds):\n",
    "    \"\"\"Calculate GFLOPS (billion floating point operations per second)\"\"\"\n",
    "    flops = 2.0 * float(M) * float(N) * float(K)\n",
    "    gflops = (flops / 1e9) / time_seconds\n",
    "    return gflops\n",
    "\n",
    "def benchmark_matmul_gpu():\n",
    "    # Matrix dimensions\n",
    "    M = N = K = 5120\n",
    "    NUM_RUNS = 10\n",
    "    NUM_WARMUP = 5\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA is not available. Running on CPU instead.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"CUDA is available. Running on GPU.\")\n",
    "    \n",
    "    print(\"\\nPyTorch Configuration:\")\n",
    "    print(f\"  PyTorch Version: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  Matrix Size: {M}x{M}\")\n",
    "    print()\n",
    "    \n",
    "    # Initialize matrices on CPU then transfer to GPU\n",
    "    print(\"Initializing matrices...\")\n",
    "    A = torch.randn(M, K, dtype=torch.float64, device=device)\n",
    "    B = torch.randn(K, N, dtype=torch.float64, device=device)\n",
    "    \n",
    "    # Warmup runs\n",
    "    print(\"Performing warmup runs...\")\n",
    "    for i in range(NUM_WARMUP):\n",
    "        with torch.no_grad():\n",
    "            C = torch.matmul(A, B)\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Performance measurement runs\n",
    "    print(\"\\nPerforming timing runs...\")\n",
    "    times = []\n",
    "    gflops_array = []\n",
    "    \n",
    "    for run in range(NUM_RUNS):\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            C = torch.matmul(A, B)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        # Calculate elapsed time in milliseconds\n",
    "        elapsed_time_ms = (end_time - start_time) * 1000\n",
    "        elapsed_time_s = elapsed_time_ms / 1000.0\n",
    "        \n",
    "        # Calculate GFLOPS\n",
    "        gflops = calculate_gflops(M, N, K, elapsed_time_s)\n",
    "        \n",
    "        times.append(elapsed_time_ms)\n",
    "        gflops_array = np.append(gflops_array if len(gflops_array) > 0 else [], gflops)\n",
    "        \n",
    "        print(f\"Run {run + 1:2d} - Time: {elapsed_time_ms:8.2f} ms, Performance: {gflops:8.2f} GFLOPS\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    min_gflops = np.min(gflops_array)\n",
    "    max_gflops = np.max(gflops_array)\n",
    "    avg_gflops = np.mean(gflops_array)\n",
    "    std_gflops = np.std(gflops_array)\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"\\nPerformance Results ({:d} runs):\".format(NUM_RUNS))\n",
    "    print(f\"  Minimum: {min_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Maximum: {max_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Average: {avg_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Std Dev: {std_gflops:10.2f} GFLOPS\")\n",
    "    \n",
    "    # Print average time\n",
    "    avg_time_ms = np.mean(times)\n",
    "    print(f\"\\nAverage execution time: {avg_time_ms:.2f} ms\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    del A, B, C\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\n",
    "        'min_gflops': min_gflops,\n",
    "        'max_gflops': max_gflops,\n",
    "        'avg_gflops': avg_gflops,\n",
    "        'std_gflops': std_gflops,\n",
    "        'times_ms': times\n",
    "    }\n",
    "\n",
    "# Run the benchmark\n",
    "if __name__ == \"__main__\":\n",
    "    results = benchmark_matmul_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn Configuration:\n",
      "  Version: 1.5.2\n",
      "\n",
      "Performing warmup runs...\n",
      "Performing timing runs...\n",
      "Run  1 - Time:  1134.61 ms, Performance:   236.59 GFLOPS\n",
      "Run  2 - Time:  1195.37 ms, Performance:   224.56 GFLOPS\n",
      "Run  3 - Time:  1251.86 ms, Performance:   214.43 GFLOPS\n",
      "Run  4 - Time:  1079.56 ms, Performance:   248.65 GFLOPS\n",
      "Run  5 - Time:  1134.50 ms, Performance:   236.61 GFLOPS\n",
      "Run  6 - Time:  1094.22 ms, Performance:   245.32 GFLOPS\n",
      "Run  7 - Time:  1174.98 ms, Performance:   228.46 GFLOPS\n",
      "Run  8 - Time:  1225.04 ms, Performance:   219.12 GFLOPS\n",
      "Run  9 - Time:  1082.35 ms, Performance:   248.01 GFLOPS\n",
      "Run 10 - Time:  1100.02 ms, Performance:   244.03 GFLOPS\n",
      "\n",
      "Performance Results (10 runs):\n",
      "  Minimum:     214.43 GFLOPS\n",
      "  Maximum:     248.65 GFLOPS\n",
      "  Average:     234.58 GFLOPS\n",
      "  Std Dev:      11.72 GFLOPS\n",
      "\n",
      "Average execution time: 1147.25 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_gflops_sklearn(M, N, K, time_seconds):\n",
    "    \"\"\"Calculate GFLOPS (billion floating point operations per second)\"\"\"\n",
    "    # Same formula as other versions: 2 * M * N * K operations (multiply-add)\n",
    "    flops = 2.0 * float(M) * float(N) * float(K)\n",
    "    gflops = (flops / 1e9) / time_seconds\n",
    "    return gflops\n",
    "\n",
    "def benchmark_matmul_sklearn(M=5120, N=5120, K=5120, num_runs=10, num_warmup=5):\n",
    "    \"\"\"Benchmark matrix multiplication using scikit-learn's safe_sparse_dot\"\"\"\n",
    "    \n",
    "    # Initialize matrices with random values (same as other versions)\n",
    "    A = np.random.random((M, K)).astype(np.float64)\n",
    "    B = np.random.random((K, N)).astype(np.float64)\n",
    "    \n",
    "    # Warmup runs\n",
    "    print(\"Performing warmup runs...\")\n",
    "    for _ in range(num_warmup):\n",
    "        C = safe_sparse_dot(A, B)\n",
    "    \n",
    "    # Performance measurement runs\n",
    "    print(\"Performing timing runs...\")\n",
    "    times = []\n",
    "    gflops_array = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        # Time the matrix multiplication\n",
    "        start_time = time.perf_counter()\n",
    "        C = safe_sparse_dot(A, B)\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        # Calculate timing and performance\n",
    "        exec_time = end_time - start_time\n",
    "        gflops = calculate_gflops_sklearn(M, N, K, exec_time)\n",
    "        \n",
    "        times.append(exec_time)\n",
    "        gflops_array.append(gflops)\n",
    "        \n",
    "        print(f\"Run {run + 1:2d} - Time: {exec_time*1000:8.2f} ms, Performance: {gflops:8.2f} GFLOPS\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    min_gflops = min(gflops_array)\n",
    "    max_gflops = max(gflops_array)\n",
    "    avg_gflops = sum(gflops_array) / len(gflops_array)\n",
    "    std_gflops = np.std(gflops_array)\n",
    "    \n",
    "    # Print results in similar format to other versions\n",
    "    print(\"\\nPerformance Results ({:d} runs):\".format(num_runs))\n",
    "    print(f\"  Minimum: {min_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Maximum: {max_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Average: {avg_gflops:10.2f} GFLOPS\")\n",
    "    print(f\"  Std Dev: {std_gflops:10.2f} GFLOPS\")\n",
    "    \n",
    "    # Print average time in milliseconds\n",
    "    avg_time_ms = np.mean(times) * 1000\n",
    "    print(f\"\\nAverage execution time: {avg_time_ms:.2f} ms\")\n",
    "    \n",
    "    return {\n",
    "        'min_gflops': min_gflops,\n",
    "        'max_gflops': max_gflops,\n",
    "        'avg_gflops': avg_gflops,\n",
    "        'std_gflops': std_gflops,\n",
    "        'times_ms': np.array(times) * 1000\n",
    "    }\n",
    "\n",
    "# Print scikit-learn configuration\n",
    "import sklearn\n",
    "print(\"scikit-learn Configuration:\")\n",
    "print(f\"  Version: {sklearn.__version__}\")\n",
    "print()\n",
    "\n",
    "# Run benchmark\n",
    "results_sklearn = benchmark_matmul_sklearn()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
