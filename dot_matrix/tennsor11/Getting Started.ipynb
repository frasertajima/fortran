{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to GPU Tensor Core Matrix Operations\n",
    "\n",
    "This notebook introduces our high-performance matrix operations library that leverages NVIDIA Tensor Cores for maximum computational \n",
    "efficiency. The library provides optimized implementations of common matrix operations using double-precision split techniques to \n",
    "maintain accuracy while benefiting from tensor core acceleration.\n",
    "\n",
    "## Setup and Installation\n",
    "\n",
    "First, let's import the required libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CUDA...\n",
      "CUDA initialization complete\n",
      "Loaded library: ./cuda_matlib.so\n",
      "Function signatures configured\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from tensor_matrix_ops import TensorMatrixOps\n",
    "\n",
    "# Initialize the tensor core operations library  \n",
    "# (ensure cuda_matlib.so and tensor_matrix_ops.py are in the same directory as this notebook)\n",
    "tensor_ops = TensorMatrixOps()\n",
    "\n",
    "\n",
    "# the following is only for this notebook and is not required generally\n",
    "# Optional: Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "cp.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Matrix-Matrix Multiplication (matmul)\n",
    "\n",
    "Matrix multiplication is a fundamental operation in linear algebra and deep learning. Our implementation optimizes for performance while maintaining numerical precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiplication (A×B):\n",
      "Tensor Core result (first 5 elements): [0.25248319 0.23801261 0.25244898 0.25019878 0.24522987]\n",
      "CuPy result (first 5 elements):        [0.25248071 0.23801127 0.25244621 0.25019609 0.24522916]\n"
     ]
    }
   ],
   "source": [
    "# Define matrix dimensions\n",
    "M, K, N = 1024, 1024, 1024  # A is (M x K), B is (K x N), C is (M x N)\n",
    "\n",
    "# Create random matrices with proper scaling\n",
    "a = cp.random.random((M, K), dtype=cp.float64)\n",
    "b = cp.random.random((K, N), dtype=cp.float64)\n",
    "\n",
    "# Scale inputs to prevent overflow\n",
    "a /= cp.sqrt(K)\n",
    "b /= cp.sqrt(K)\n",
    "\n",
    "\n",
    "# Run matrix multiplication using Tensor Cores\n",
    "c_tensor = tensor_ops.matmul(a, b)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "c_cupy = cp.matmul(a, b)\n",
    "\n",
    "# Print sample results\n",
    "print(\"Matrix Multiplication (A×B):\")\n",
    "print(\"Tensor Core result (first 5 elements):\", c_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", c_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Matrix Power (A^n)\n",
    "\n",
    "Computing matrix powers efficiently is essential for many algorithms like Markov chains and graph analytics. Our implementation uses tensor cores to accelerate these computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Power (A^4):\n",
      "Tensor Core result (first 5 elements): [21.84820557 22.37931252 21.33176041 21.0262146  21.53623581]\n",
      "CuPy result (first 5 elements):        [21.84799909 22.38001368 21.33145314 21.02625034 21.53599366]\n"
     ]
    }
   ],
   "source": [
    "# Create a square matrix\n",
    "n = 512\n",
    "a = cp.random.random((n, n), dtype=cp.float64)\n",
    "\n",
    "# Scale to prevent overflow during powers\n",
    "a /= (cp.sqrt(n) * 1.1)\n",
    "\n",
    "# Define the power\n",
    "power = 4\n",
    "\n",
    "# Compute matrix power using Tensor Cores\n",
    "a_power_tensor = tensor_ops.matrix_power(a, power)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "a_power_cupy = cp.linalg.matrix_power(a, power)\n",
    "\n",
    "# Print sample results\n",
    "print(f\"Matrix Power (A^{power}):\")\n",
    "print(\"Tensor Core result (first 5 elements):\", a_power_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", a_power_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batched Matrix Multiplication\n",
    "\n",
    "Batched matrix multiplication performs the same operation on multiple matrix pairs simultaneously, which is common in deep learning when processing batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched Matrix Multiplication:\n",
      "Tensor Core result (first 5 elements): [0.24708433 0.24681014 0.24933796 0.2704584  0.24725303]\n",
      "CuPy result (first 5 elements):        [0.25764366 0.23845166 0.24916795 0.24741405 0.26051707]\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and dimensions\n",
    "batch_size = 32\n",
    "M, K, N = 128, 512, 512\n",
    "\n",
    "# Create batched random matrices\n",
    "a_batch = cp.random.random((batch_size, M, K), dtype=cp.float64)\n",
    "b_batch = cp.random.random((batch_size, K, N), dtype=cp.float64)\n",
    "\n",
    "# Scale inputs\n",
    "a_batch /= cp.sqrt(K)\n",
    "b_batch /= cp.sqrt(K)\n",
    "\n",
    "# Compute batched matrix multiplication using Tensor Cores\n",
    "c_batch_tensor = tensor_ops.batched_matmul(a_batch, b_batch)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "c_batch_cupy = cp.matmul(a_batch, b_batch)\n",
    "\n",
    "# Print sample results\n",
    "print(\"Batched Matrix Multiplication:\")\n",
    "print(\"Tensor Core result (first 5 elements):\", c_batch_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", c_batch_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vector-Matrix Multiplication (v×A)\n",
    "\n",
    "Vector-matrix multiplication is a special case that computes the product of a vector and a matrix, used in many operations including neural network forward passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector-Matrix Multiplication (v×A):\n",
      "Tensor Core result (first 5 elements): [0.2469551  0.24752763 0.24533175 0.25095335 0.25167346]\n",
      "CuPy result (first 5 elements):        [0.2469551  0.24752763 0.24533173 0.25095336 0.25167343]\n"
     ]
    }
   ],
   "source": [
    "# Create a vector and a matrix\n",
    "n = 4096\n",
    "v = cp.random.random(n, dtype=cp.float64)\n",
    "a = cp.random.random((n, n), dtype=cp.float64)\n",
    "\n",
    "# Scale inputs\n",
    "v /= cp.sqrt(n)\n",
    "a /= cp.sqrt(n)\n",
    "\n",
    "# Compute vector-matrix multiplication using Tensor Cores\n",
    "result_tensor = tensor_ops.vector_matmul(v, a)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "result_cupy = v @ a\n",
    "\n",
    "# Print sample results\n",
    "print(\"Vector-Matrix Multiplication (v×A):\")\n",
    "print(\"Tensor Core result (first 5 elements):\", result_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", result_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Matrix-Vector Multiplication (A×v)\n",
    "\n",
    "Matrix-vector multiplication computes the product of a matrix and a vector, common in many scientific computing and machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix-Vector Multiplication (A×v):\n",
      "Tensor Core result (first 5 elements): [0.25579202 0.25863317 0.25647345 0.26250604 0.25792497]\n",
      "CuPy result (first 5 elements):        [0.25579201 0.25863317 0.25647348 0.26250603 0.25792499]\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix and a vector\n",
    "n = 1024\n",
    "a = cp.random.random((n, n), dtype=cp.float64)\n",
    "v = cp.random.random(n, dtype=cp.float64)\n",
    "\n",
    "# Scale inputs\n",
    "a /= cp.sqrt(n)\n",
    "v /= cp.sqrt(n)\n",
    "\n",
    "# Compute matrix-vector multiplication using Tensor Cores\n",
    "result_tensor = tensor_ops.matmul_vector(a, v)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "result_cupy = a @ v\n",
    "\n",
    "# Print sample results\n",
    "print(\"Matrix-Vector Multiplication (A×v):\")\n",
    "print(\"Tensor Core result (first 5 elements):\", result_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", result_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batched Vector Multiplication\n",
    "\n",
    "This operation applies the same matrix to multiple vectors in parallel, which is useful for processing multiple inputs simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched Vector Multiplication:\n",
      "Tensor Core result (first 5 elements): [0.25338036 0.25158006 0.25674474 0.25279993 0.25193566]\n",
      "CuPy result (first 5 elements):        [0.24548769 0.25240293 0.25115439 0.25377019 0.24899413]\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix and a batch of vectors\n",
    "n = 4096\n",
    "batch_size = 32\n",
    "a = cp.random.random((n, n), dtype=cp.float64)\n",
    "v_batch = cp.random.random((n, batch_size), dtype=cp.float64)\n",
    "\n",
    "# Scale inputs\n",
    "a /= cp.sqrt(n)\n",
    "v_batch /= cp.sqrt(n)\n",
    "\n",
    "# Compute batched vector multiplication using Tensor Cores\n",
    "result_tensor = tensor_ops.batched_vector_matmul(v_batch, a)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "result_cupy = cp.empty((batch_size, n), dtype=cp.float64)\n",
    "for i in range(batch_size):\n",
    "    result_cupy[i] = a @ v_batch[:,i]\n",
    "\n",
    "# Print sample results\n",
    "print(\"Batched Vector Multiplication:\")\n",
    "print(\"Tensor Core result (first 5 elements):\", result_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", result_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Strided Batch Matrix Multiplication\n",
    "\n",
    "Strided batch matrix multiplication operates on matrices stored contiguously in memory with a fixed stride between them, which can be more memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strided Batch Matrix Multiplication:\n",
      "Tensor Core result (first 5 elements): [0.23895994 0.24422252 0.24787512 0.23367743 0.24973069]\n",
      "CuPy result (first 5 elements):        [0.23286825 0.22940109 0.25613556 0.22756938 0.24376466]\n"
     ]
    }
   ],
   "source": [
    "# Define dimensions\n",
    "batch_size = 32\n",
    "M, K, N = 128, 128, 128\n",
    "\n",
    "# Create batched matrices\n",
    "a_batch = cp.random.random((batch_size, M, K), dtype=cp.float64)\n",
    "b_batch = cp.random.random((batch_size, K, N), dtype=cp.float64)\n",
    "\n",
    "# Scale inputs\n",
    "a_batch /= cp.sqrt(K)\n",
    "b_batch /= cp.sqrt(K)\n",
    "\n",
    "# Compute strided batch matrix multiplication using Tensor Cores\n",
    "result_tensor = tensor_ops.strided_batch_matmul(M, K, N, batch_size, a_batch, b_batch)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "result_cupy = cp.matmul(a_batch, b_batch)\n",
    "\n",
    "# Print sample results\n",
    "print(\"Strided Batch Matrix Multiplication:\")\n",
    "print(\"Tensor Core result (first 5 elements):\", result_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", result_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 4D Tensor Matrix Multiplication\n",
    "\n",
    "4D tensor multiplication extends matrix operations to higher-dimensional arrays, which is common in convolutional neural networks and other deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4D Tensor Matrix Multiplication:\n",
      "Tensor Core result (first 5 elements): [0.268554   0.25216904 0.22979662 0.23863836 0.27084583]\n",
      "CuPy result (first 5 elements):        [0.26855174 0.25216689 0.22979669 0.23863848 0.27084709]\n"
     ]
    }
   ],
   "source": [
    "# Define dimensions\n",
    "batch1, batch2, M, N = 4, 4, 128, 128\n",
    "\n",
    "# Create 4D tensors\n",
    "a_tensor = cp.random.random((batch1, batch2, M, N), dtype=cp.float64)\n",
    "b_tensor = cp.random.random((batch1, batch2, N, N), dtype=cp.float64)\n",
    "\n",
    "# Scale inputs\n",
    "a_tensor /= cp.sqrt(N)\n",
    "b_tensor /= cp.sqrt(N)\n",
    "\n",
    "# Compute 4D tensor matrix multiplication using Tensor Cores\n",
    "result_tensor = tensor_ops.tensor_4d_matmul(a_tensor, b_tensor)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "result_cupy = cp.matmul(a_tensor, b_tensor)\n",
    "\n",
    "# Print sample results\n",
    "print(\"4D Tensor Matrix Multiplication:\")\n",
    "print(\"Tensor Core result (first 5 elements):\", result_tensor.flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", result_cupy.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 5D Tensor Matrix Multiplication\n",
    "\n",
    "5D tensor multiplication handles even higher-dimensional data, useful for 3D convolutions and video processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5D Tensor Matrix Multiplication:\n",
      "Tensor Core result (first 5 elements): [0.22260779 0.24218149 0.22158685 0.21666944 0.25543442]\n",
      "CuPy result (first 5 elements):        [0.22261135 0.23759576 0.26438895 0.22105957 0.20184577]\n"
     ]
    }
   ],
   "source": [
    "# Define dimensions\n",
    "batch, channels, depth, height, width = 2, 3, 4, 64, 64\n",
    "\n",
    "# Create 5D tensors\n",
    "a_tensor = cp.random.random((batch, channels, depth, height, width), dtype=cp.float64)\n",
    "b_tensor = cp.random.random((batch, channels, depth, width, width), dtype=cp.float64)\n",
    "\n",
    "# Scale inputs\n",
    "a_tensor /= cp.sqrt(width)\n",
    "b_tensor /= cp.sqrt(width)\n",
    "\n",
    "# Compute 5D tensor matrix multiplication using Tensor Cores\n",
    "result_tensor = tensor_ops.tensor_5d_matmul(a_tensor, b_tensor)\n",
    "\n",
    "# Compare with standard CuPy implementation\n",
    "result_cupy = cp.zeros((batch, channels, depth, height, width), dtype=cp.float64)\n",
    "for b_idx in range(batch):\n",
    "    for c in range(channels):\n",
    "        for d in range(depth):\n",
    "            result_cupy[b_idx,c,d] = a_tensor[b_idx,c,d] @ b_tensor[b_idx,c,d]\n",
    "\n",
    "# Print sample results\n",
    "print(\"5D Tensor Matrix Multiplication:\")\n",
    "print(\"Tensor Core result (first 5 elements):\", result_tensor[0,0,0].flatten()[:5])\n",
    "print(\"CuPy result (first 5 elements):       \", result_cupy[0,0,0].flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By following the nine examples for using the tensor core engine it would be relatively straight forward to replace CuPy in notebooks where you need significant acceleration in speed (for the trade-off of some accuracy). For operations which are not memory bound, you should see significant performance improvements over standard CuPy implementations, especially for larger matrices and higher batch sizes (see benchmark notebook for some sample runs).\n",
    "\n",
    "Key takeaways:\n",
    "1. Tensor Core operations can provide substantial speedups for large matrices\n",
    "2. Double-precision splitting technique maintains high accuracy\n",
    "3. The library handles various formats from simple matrices to 5D tensors\n",
    "4. Performance benefits increase with problem size\n",
    "\n",
    "For more details, check the library documentation, samples, or explore the python wrapper to understand the implementation details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
